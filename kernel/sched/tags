!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
ACTIVE_NODE_FRACTION	fair.c	1275;"	d	file:
BW_SHIFT	sched.h	1626;"	d
BW_UNIT	sched.h	1627;"	d
CFLAGS_REMOVE_clock.o	Makefile	/^CFLAGS_REMOVE_clock.o = $(CC_FLAGS_FTRACE)$/;"	m
CFLAGS_core.o	Makefile	/^CFLAGS_core.o := $(PROFILING) -fno-omit-frame-pointer$/;"	m
COMPAT_SYSCALL_DEFINE2	core.c	/^COMPAT_SYSCALL_DEFINE2(sched_rr_get_interval,$/;"	f
CPUACCT_STAT_NSTATS	cpuacct.c	/^	CPUACCT_STAT_NSTATS,$/;"	e	enum:cpuacct_stat_index	file:
CPUACCT_STAT_SYSTEM	cpuacct.c	/^	CPUACCT_STAT_SYSTEM,	\/* ... kernel mode *\/$/;"	e	enum:cpuacct_stat_index	file:
CPUACCT_STAT_USER	cpuacct.c	/^	CPUACCT_STAT_USER,	\/* ... user mode *\/$/;"	e	enum:cpuacct_stat_index	file:
CPUPRI_IDLE	cpupri.h	6;"	d
CPUPRI_INVALID	cpupri.h	5;"	d
CPUPRI_NORMAL	cpupri.h	7;"	d
CPUPRI_NR_PRIORITIES	cpupri.h	3;"	d
CPU_LOAD_IDX_MAX	sched.h	769;"	d
CREATE_TRACE_POINTS	core.c	20;"	d	file:
CREATE_TRACE_POINTS	core.c	7083;"	d	file:
DEGRADE_SHIFT	fair.c	5550;"	d	file:
DEQUEUE_MOVE	sched.h	1460;"	d
DEQUEUE_NOCLOCK	sched.h	1461;"	d
DEQUEUE_SAVE	sched.h	1459;"	d
DEQUEUE_SLEEP	sched.h	1458;"	d
DL_MAX_TRIES	deadline.c	1818;"	d	file:
DL_SCALE	sched.h	148;"	d
DO_ATTACH	fair.c	3823;"	d	file:
DO_ATTACH	fair.c	4050;"	d	file:
ENQUEUE_HEAD	sched.h	1468;"	d
ENQUEUE_MIGRATED	sched.h	1471;"	d
ENQUEUE_MIGRATED	sched.h	1473;"	d
ENQUEUE_MOVE	sched.h	1465;"	d
ENQUEUE_NOCLOCK	sched.h	1466;"	d
ENQUEUE_REPLENISH	sched.h	1469;"	d
ENQUEUE_RESTORE	sched.h	1464;"	d
ENQUEUE_WAKEUP	sched.h	1463;"	d
HAVE_RT_PUSH_IPI	sched.h	578;"	d
IDX_INVALID	cpudeadline.h	3;"	d
KCOV_INSTRUMENT	Makefile	/^KCOV_INSTRUMENT := n$/;"	m
LBF_ALL_PINNED	fair.c	7241;"	d	file:
LBF_DST_PINNED	fair.c	7243;"	d	file:
LBF_NEED_BREAK	fair.c	7242;"	d	file:
LBF_NOHZ_AGAIN	fair.c	7246;"	d	file:
LBF_NOHZ_STATS	fair.c	7245;"	d	file:
LBF_SOME_PINNED	fair.c	7244;"	d	file:
LOAD_AVG_MAX	sched-pelt.h	14;"	d
LOAD_AVG_PERIOD	sched-pelt.h	13;"	d
MAX_PINNED_INTERVAL	fair.c	8753;"	d	file:
MAX_SCAN_WINDOW	fair.c	1084;"	d	file:
MAX_SHARES	sched.h	408;"	d
MEMBARRIER_CMD_BITMASK	membarrier.c	30;"	d	file:
MEMBARRIER_PRIVATE_EXPEDITED_SYNC_CORE_BITMASK	membarrier.c	23;"	d	file:
MEMBARRIER_PRIVATE_EXPEDITED_SYNC_CORE_BITMASK	membarrier.c	27;"	d	file:
MIN_SHARES	sched.h	407;"	d
NICE_0_LOAD	sched.h	141;"	d
NICE_0_LOAD_SHIFT	sched.h	123;"	d
NICE_0_LOAD_SHIFT	sched.h	127;"	d
NOHZ_BALANCE_KICK	sched.h	2066;"	d
NOHZ_BALANCE_KICK_BIT	sched.h	2063;"	d
NOHZ_KICK_MASK	sched.h	2069;"	d
NOHZ_STATS_KICK	sched.h	2067;"	d
NOHZ_STATS_KICK_BIT	sched.h	2064;"	d
NR_NUMA_HINT_FAULT_BUCKETS	fair.c	1204;"	d	file:
NR_NUMA_HINT_FAULT_STATS	fair.c	1201;"	d	file:
NR_NUMA_HINT_FAULT_TYPES	fair.c	1198;"	d	file:
NS_TO_JIFFIES	sched.h	106;"	d
NUMA_BACKPLANE	sched.h	/^	NUMA_BACKPLANE,$/;"	e	enum:numa_topology_type
NUMA_CPU	sched.h	/^	NUMA_CPU,$/;"	e	enum:numa_faults_stats
NUMA_CPUBUF	sched.h	/^	NUMA_CPUBUF$/;"	e	enum:numa_faults_stats
NUMA_DIRECT	sched.h	/^	NUMA_DIRECT,$/;"	e	enum:numa_topology_type
NUMA_GLUELESS_MESH	sched.h	/^	NUMA_GLUELESS_MESH,$/;"	e	enum:numa_topology_type
NUMA_MEM	sched.h	/^	NUMA_MEM = 0,$/;"	e	enum:numa_faults_stats
NUMA_MEMBUF	sched.h	/^	NUMA_MEMBUF,$/;"	e	enum:numa_faults_stats
NUMA_PERIOD_SLOTS	fair.c	1951;"	d	file:
NUMA_PERIOD_THRESHOLD	fair.c	1952;"	d	file:
P	debug.c	391;"	d	file:
P	debug.c	427;"	d	file:
P	debug.c	583;"	d	file:
P	debug.c	600;"	d	file:
P	debug.c	644;"	d	file:
P	debug.c	670;"	d	file:
P	debug.c	680;"	d	file:
P	debug.c	688;"	d	file:
P	debug.c	722;"	d	file:
P	debug.c	734;"	d	file:
P	debug.c	739;"	d	file:
P	debug.c	749;"	d	file:
P	debug.c	836;"	d	file:
P	debug.c	889;"	d	file:
P	debug.c	986;"	d	file:
P64	debug.c	674;"	d	file:
P64	debug.c	677;"	d	file:
PN	debug.c	393;"	d	file:
PN	debug.c	425;"	d	file:
PN	debug.c	587;"	d	file:
PN	debug.c	598;"	d	file:
PN	debug.c	652;"	d	file:
PN	debug.c	671;"	d	file:
PN	debug.c	724;"	d	file:
PN	debug.c	733;"	d	file:
PN	debug.c	741;"	d	file:
PN	debug.c	748;"	d	file:
PN	debug.c	838;"	d	file:
PN	debug.c	895;"	d	file:
PN	debug.c	983;"	d	file:
PN_SCHEDSTAT	debug.c	394;"	d	file:
PN_SCHEDSTAT	debug.c	424;"	d	file:
PN_SCHEDSTAT	debug.c	897;"	d	file:
PN_SCHEDSTAT	debug.c	982;"	d	file:
PU	debug.c	585;"	d	file:
PU	debug.c	599;"	d	file:
PU	debug.c	610;"	d	file:
PU	debug.c	623;"	d	file:
P_SCHEDSTAT	debug.c	392;"	d	file:
P_SCHEDSTAT	debug.c	426;"	d	file:
P_SCHEDSTAT	debug.c	891;"	d	file:
P_SCHEDSTAT	debug.c	985;"	d	file:
RATIO_SHIFT	sched.h	1628;"	d
RETRY_TASK	sched.h	1476;"	d
ROOT_TASK_GROUP_LOAD	sched.h	397;"	d
RQCF_ACT_SKIP	sched.h	960;"	d
RQCF_REQ_SKIP	sched.h	959;"	d
RQCF_UPDATED	sched.h	961;"	d
RT_MAX_TRIES	rt.c	1599;"	d	file:
RUNTIME_INF	sched.h	153;"	d
SCHEDSTAT_VERSION	stats.c	13;"	d	file:
SCHED_FEAT	core.c	33;"	d	file:
SCHED_FEAT	core.c	38;"	d	file:
SCHED_FEAT	debug.c	53;"	d	file:
SCHED_FEAT	debug.c	60;"	d	file:
SCHED_FEAT	debug.c	81;"	d	file:
SCHED_FEAT	debug.c	88;"	d	file:
SCHED_FEAT	sched.h	1329;"	d
SCHED_FEAT	sched.h	1337;"	d
SCHED_FEAT	sched.h	1347;"	d
SCHED_FEAT	sched.h	1354;"	d
SCHED_FEAT	sched.h	1366;"	d
SCHED_FEAT	sched.h	1371;"	d
SCHED_FLAG_SUGOV	sched.h	203;"	d
SCHED_WARN_ON	sched.h	77;"	d
SCHED_WARN_ON	sched.h	79;"	d
SEQ_printf	debug.c	20;"	d	file:
SETPARAM_POLICY	core.c	4078;"	d	file:
SET_SYSCTL	fair.c	173;"	d	file:
SET_SYSCTL	fair.c	178;"	d	file:
SKIP_AGE_LOAD	fair.c	3822;"	d	file:
SKIP_AGE_LOAD	fair.c	4049;"	d	file:
SPLIT_NS	debug.c	51;"	d	file:
SYSCALL_DEFINE0	core.c	/^SYSCALL_DEFINE0(sched_yield)$/;"	f
SYSCALL_DEFINE1	core.c	/^SYSCALL_DEFINE1(nice, int, increment)$/;"	f
SYSCALL_DEFINE1	core.c	/^SYSCALL_DEFINE1(sched_get_priority_max, int, policy)$/;"	f
SYSCALL_DEFINE1	core.c	/^SYSCALL_DEFINE1(sched_get_priority_min, int, policy)$/;"	f
SYSCALL_DEFINE1	core.c	/^SYSCALL_DEFINE1(sched_getscheduler, pid_t, pid)$/;"	f
SYSCALL_DEFINE2	core.c	/^SYSCALL_DEFINE2(sched_getparam, pid_t, pid, struct sched_param __user *, param)$/;"	f
SYSCALL_DEFINE2	core.c	/^SYSCALL_DEFINE2(sched_rr_get_interval, pid_t, pid,$/;"	f
SYSCALL_DEFINE2	core.c	/^SYSCALL_DEFINE2(sched_setparam, pid_t, pid, struct sched_param __user *, param)$/;"	f
SYSCALL_DEFINE2	membarrier.c	/^SYSCALL_DEFINE2(membarrier, int, cmd, int, flags)$/;"	f
SYSCALL_DEFINE3	core.c	/^SYSCALL_DEFINE3(sched_getaffinity, pid_t, pid, unsigned int, len,$/;"	f
SYSCALL_DEFINE3	core.c	/^SYSCALL_DEFINE3(sched_setaffinity, pid_t, pid, unsigned int, len,$/;"	f
SYSCALL_DEFINE3	core.c	/^SYSCALL_DEFINE3(sched_setattr, pid_t, pid, struct sched_attr __user *, uattr,$/;"	f
SYSCALL_DEFINE3	core.c	/^SYSCALL_DEFINE3(sched_setscheduler, pid_t, pid, int, policy, struct sched_param __user *, param)$/;"	f
SYSCALL_DEFINE4	core.c	/^SYSCALL_DEFINE4(sched_getattr, pid_t, pid, struct sched_attr __user *, uattr,$/;"	f
TASK_MOVE_GROUP	sched.h	1535;"	d
TASK_ON_RQ_MIGRATING	sched.h	87;"	d
TASK_ON_RQ_QUEUED	sched.h	86;"	d
TASK_SET_GROUP	sched.h	1534;"	d
TOPOLOGY_SD_FLAGS	topology.c	1071;"	d	file:
UPDATE_TG	fair.c	3821;"	d	file:
UPDATE_TG	fair.c	4048;"	d	file:
UTIL_AVG_UNCHANGED	fair.c	3283;"	d	file:
WAITQUEUE_WALK_BREAK_CNT	wait.c	54;"	d	file:
WAIT_TABLE_BITS	wait_bit.c	6;"	d	file:
WAIT_TABLE_SIZE	wait_bit.c	7;"	d	file:
WEIGHT_IDLEPRIO	sched.h	1433;"	d
WF_FORK	sched.h	1421;"	d
WF_MIGRATED	sched.h	1422;"	d
WF_SYNC	sched.h	1420;"	d
WMULT_CONST	fair.c	186;"	d	file:
WMULT_IDLEPRIO	sched.h	1434;"	d
WMULT_SHIFT	fair.c	187;"	d	file:
WRT_SYSCTL	fair.c	618;"	d	file:
WRT_SYSCTL	fair.c	623;"	d	file:
__P	debug.c	835;"	d	file:
__P	debug.c	887;"	d	file:
__P	debug.c	987;"	d	file:
__PN	debug.c	837;"	d	file:
__PN	debug.c	893;"	d	file:
__PN	debug.c	984;"	d	file:
__SCHED_FEAT_NR	sched.h	/^	__SCHED_FEAT_NR,$/;"	e	enum:__anon5
____cacheline_aligned	fair.c	/^} nohz ____cacheline_aligned;$/;"	v	typeref:struct:__anon1	file:
____cacheline_aligned	sched.h	/^		raw_spinlock_t	lock ____cacheline_aligned;$/;"	m	struct:cfs_rq::__anon2
____cacheline_aligned	sched.h	/^	atomic_long_t		load_avg ____cacheline_aligned;$/;"	m	struct:task_group
___might_sleep	core.c	/^EXPORT_SYMBOL(___might_sleep);$/;"	v
___might_sleep	core.c	/^void ___might_sleep(const char *file, int line, int preempt_offset)$/;"	f
___update_load_avg	fair.c	/^___update_load_avg(struct sched_avg *sa, unsigned long load, unsigned long runnable)$/;"	f	file:
___update_load_sum	fair.c	/^___update_load_sum(u64 now, int cpu, struct sched_avg *sa,$/;"	f	file:
__account_cfs_rq_runtime	fair.c	/^static void __account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec)$/;"	f	file:
__accumulate_pelt_segments	fair.c	/^static u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)$/;"	f	file:
__add_rq_bw	deadline.c	/^void __add_rq_bw(u64 dl_bw, struct dl_rq *dl_rq)$/;"	f	file:
__add_running_bw	deadline.c	/^void __add_running_bw(u64 dl_bw, struct dl_rq *dl_rq)$/;"	f	file:
__balance_callback	core.c	/^static void __balance_callback(struct rq *rq)$/;"	f	file:
__cacheline_aligned	wait_bit.c	/^static wait_queue_head_t bit_wait_table[WAIT_TABLE_SIZE] __cacheline_aligned;$/;"	v	file:
__calc_delta	fair.c	/^static u64 __calc_delta(u64 delta_exec, unsigned long weight, struct load_weight *lw)$/;"	f	file:
__cfs_bandwidth_used	fair.c	/^static struct static_key __cfs_bandwidth_used;$/;"	v	typeref:struct:static_key	file:
__cfs_schedulable	core.c	/^static int __cfs_schedulable(struct task_group *tg, u64 period, u64 quota)$/;"	f	file:
__checkparam_dl	deadline.c	/^bool __checkparam_dl(const struct sched_attr *attr)$/;"	f
__clear_buddies_last	fair.c	/^static void __clear_buddies_last(struct sched_entity *se)$/;"	f	file:
__clear_buddies_next	fair.c	/^static void __clear_buddies_next(struct sched_entity *se)$/;"	f	file:
__clear_buddies_skip	fair.c	/^static void __clear_buddies_skip(struct sched_entity *se)$/;"	f	file:
__clear_sched_clock_stable	clock.c	/^static void __clear_sched_clock_stable(void)$/;"	f	file:
__cond_resched_lock	core.c	/^EXPORT_SYMBOL(__cond_resched_lock);$/;"	v
__cond_resched_lock	core.c	/^int __cond_resched_lock(spinlock_t *lock)$/;"	f
__cpuacct_percpu_seq_show	cpuacct.c	/^static int __cpuacct_percpu_seq_show(struct seq_file *m,$/;"	f	file:
__cpuusage_read	cpuacct.c	/^static u64 __cpuusage_read(struct cgroup_subsys_state *css,$/;"	f	file:
__delist_rt_entity	rt.c	/^static void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)$/;"	f	file:
__dequeue_dl_entity	deadline.c	/^static void __dequeue_dl_entity(struct sched_dl_entity *dl_se)$/;"	f	file:
__dequeue_entity	fair.c	/^static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
__dequeue_rt_entity	rt.c	/^static void __dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)$/;"	f	file:
__dequeue_task_dl	deadline.c	/^static void __dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
__disable_runtime	rt.c	/^static void __disable_runtime(struct rq *rq)$/;"	f	file:
__dl_add	sched.h	/^void __dl_add(struct dl_bw *dl_b, u64 tsk_bw, int cpus)$/;"	f
__dl_clear_params	deadline.c	/^void __dl_clear_params(struct task_struct *p)$/;"	f
__dl_overflow	sched.h	/^bool __dl_overflow(struct dl_bw *dl_b, int cpus, u64 old_bw, u64 new_bw)$/;"	f
__dl_sub	sched.h	/^void __dl_sub(struct dl_bw *dl_b, u64 tsk_bw, int cpus)$/;"	f
__dl_update	sched.h	/^void __dl_update(struct dl_bw *dl_b, s64 bw)$/;"	f
__enable_runtime	rt.c	/^static void __enable_runtime(struct rq *rq)$/;"	f	file:
__enqueue_dl_entity	deadline.c	/^static void __enqueue_dl_entity(struct sched_dl_entity *dl_se)$/;"	f	file:
__enqueue_entity	fair.c	/^static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
__enqueue_rt_entity	rt.c	/^static void __enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)$/;"	f	file:
__finish_swait	swait.c	/^void __finish_swait(struct swait_queue_head *q, struct swait_queue *wait)$/;"	f
__fire_sched_in_preempt_notifiers	core.c	/^static void __fire_sched_in_preempt_notifiers(struct task_struct *curr)$/;"	f	file:
__fire_sched_out_preempt_notifiers	core.c	/^__fire_sched_out_preempt_notifiers(struct task_struct *curr,$/;"	f	file:
__free_domain_allocs	topology.c	/^static void __free_domain_allocs(struct s_data *d, enum s_alloc what,$/;"	f	file:
__getparam_dl	deadline.c	/^void __getparam_dl(struct task_struct *p, struct sched_attr *attr)$/;"	f
__gtod_offset	clock.c	/^static __read_mostly u64 __gtod_offset;$/;"	v	file:
__hrtick_restart	core.c	/^static void __hrtick_restart(struct rq *rq)$/;"	f	file:
__hrtick_start	core.c	/^static void __hrtick_start(void *arg)$/;"	f	file:
__init_swait_queue_head	swait.c	/^EXPORT_SYMBOL(__init_swait_queue_head);$/;"	v
__init_swait_queue_head	swait.c	/^void __init_swait_queue_head(struct swait_queue_head *q, const char *name,$/;"	f
__init_waitqueue_head	wait.c	/^EXPORT_SYMBOL(__init_waitqueue_head);$/;"	v
__init_waitqueue_head	wait.c	/^void __init_waitqueue_head(struct wait_queue_head *wq_head, const char *name, struct lock_class_key *key)$/;"	f
__might_sleep	core.c	/^EXPORT_SYMBOL(__might_sleep);$/;"	v
__might_sleep	core.c	/^void __might_sleep(const char *file, int line, int preempt_offset)$/;"	f
__migrate_swap_task	core.c	/^static void __migrate_swap_task(struct task_struct *p, int cpu)$/;"	f	file:
__migrate_task	core.c	/^static struct rq *__migrate_task(struct rq *rq, struct rq_flags *rf,$/;"	f	file:
__normal_prio	core.c	/^static inline int __normal_prio(struct task_struct *p)$/;"	f	file:
__pick_first_entity	fair.c	/^struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq)$/;"	f
__pick_last_entity	fair.c	/^struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq)$/;"	f
__pick_next_entity	fair.c	/^static struct sched_entity *__pick_next_entity(struct sched_entity *se)$/;"	f	file:
__prepare_to_swait	swait.c	/^void __prepare_to_swait(struct swait_queue_head *q, struct swait_queue *wait)$/;"	f
__read_mostly	core.c	/^bool sched_smp_initialized __read_mostly;$/;"	v
__read_mostly	core.c	/^static struct kmem_cache *task_group_cache __read_mostly;$/;"	v	typeref:struct:task_group_cache	file:
__read_mostly	fair.c	/^unsigned int sysctl_sched_child_runs_first __read_mostly;$/;"	v
__refill_cfs_bandwidth_runtime	fair.c	/^void __refill_cfs_bandwidth_runtime(struct cfs_bandwidth *cfs_b)$/;"	f
__return_cfs_rq_runtime	fair.c	/^static void __return_cfs_rq_runtime(struct cfs_rq *cfs_rq)$/;"	f	file:
__rq_clock_broken	sched.h	/^static inline u64 __rq_clock_broken(struct rq *rq)$/;"	f
__rt_effective_prio	core.c	/^static inline int __rt_effective_prio(struct task_struct *pi_task, int prio)$/;"	f	file:
__rt_schedulable	rt.c	/^static int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)$/;"	f	file:
__scd_stamp	clock.c	/^static void __scd_stamp(struct sched_clock_data *scd)$/;"	f	file:
__sched_clock_offset	clock.c	/^__read_mostly u64 __sched_clock_offset;$/;"	v
__sched_clock_stable_early	clock.c	/^static int __sched_clock_stable_early = 1;$/;"	v	file:
__sched_clock_work	clock.c	/^static void __sched_clock_work(struct work_struct *work)$/;"	f	file:
__sched_fork	core.c	/^static void __sched_fork(unsigned long clone_flags, struct task_struct *p)$/;"	f	file:
__sched_info_switch	stats.h	/^__sched_info_switch(struct rq *rq, struct task_struct *prev, struct task_struct *next)$/;"	f
__sched_period	fair.c	/^static u64 __sched_period(unsigned long nr_running)$/;"	f	file:
__sched_schedstats	core.c	/^static bool __initdata __sched_schedstats = false;$/;"	v	file:
__sched_setscheduler	core.c	/^static int __sched_setscheduler(struct task_struct *p,$/;"	f	file:
__schedstat_add	stats.h	36;"	d
__schedstat_add	stats.h	50;"	d
__schedstat_inc	stats.h	34;"	d
__schedstat_inc	stats.h	48;"	d
__schedstat_set	stats.h	38;"	d
__schedstat_set	stats.h	52;"	d
__schedule	core.c	/^static void __sched notrace __schedule(bool preempt)$/;"	f	file:
__schedule_bug	core.c	/^static noinline void __schedule_bug(struct task_struct *prev)$/;"	f	file:
__sdt_alloc	topology.c	/^static int __sdt_alloc(const struct cpumask *cpu_map)$/;"	f	file:
__sdt_free	topology.c	/^static void __sdt_free(const struct cpumask *cpu_map)$/;"	f	file:
__set_cpus_allowed_ptr	core.c	/^static inline int __set_cpus_allowed_ptr(struct task_struct *p,$/;"	f	file:
__set_cpus_allowed_ptr	core.c	/^static int __set_cpus_allowed_ptr(struct task_struct *p,$/;"	f	file:
__set_sched_clock_stable	clock.c	/^static void __set_sched_clock_stable(void)$/;"	f	file:
__set_task_cpu	sched.h	/^static inline void __set_task_cpu(struct task_struct *p, unsigned int cpu)$/;"	f
__setparam_dl	deadline.c	/^void __setparam_dl(struct task_struct *p, const struct sched_attr *attr)$/;"	f
__setscheduler	core.c	/^static void __setscheduler(struct rq *rq, struct task_struct *p,$/;"	f	file:
__setscheduler_params	core.c	/^static void __setscheduler_params(struct task_struct *p,$/;"	f	file:
__sub_rq_bw	deadline.c	/^void __sub_rq_bw(u64 dl_bw, struct dl_rq *dl_rq)$/;"	f	file:
__sub_running_bw	deadline.c	/^void __sub_running_bw(u64 dl_bw, struct dl_rq *dl_rq)$/;"	f	file:
__update_idle_core	fair.c	/^void __update_idle_core(struct rq *rq)$/;"	f
__update_inv_weight	fair.c	/^static void __update_inv_weight(struct load_weight *lw)$/;"	f	file:
__update_load_avg_blocked_se	fair.c	/^__update_load_avg_blocked_se(u64 now, int cpu, struct sched_entity *se)$/;"	f	file:
__update_load_avg_cfs_rq	fair.c	/^__update_load_avg_cfs_rq(u64 now, int cpu, struct cfs_rq *cfs_rq)$/;"	f	file:
__update_load_avg_se	fair.c	/^__update_load_avg_se(u64 now, int cpu, struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
__var_waitqueue	wait_bit.c	/^EXPORT_SYMBOL(__var_waitqueue);$/;"	v
__var_waitqueue	wait_bit.c	/^wait_queue_head_t *__var_waitqueue(void *p)$/;"	f
__visit_domain_allocation_hell	topology.c	/^__visit_domain_allocation_hell(struct s_data *d, const struct cpumask *cpu_map)$/;"	f	file:
__vtime_account_system	cputime.c	/^static void __vtime_account_system(struct task_struct *tsk,$/;"	f	file:
__wait_for_common	completion.c	/^__wait_for_common(struct completion *x,$/;"	f	file:
__wait_on_bit	wait_bit.c	/^EXPORT_SYMBOL(__wait_on_bit);$/;"	v
__wait_on_bit	wait_bit.c	/^__wait_on_bit(struct wait_queue_head *wq_head, struct wait_bit_queue_entry *wbq_entry,$/;"	f
__wait_on_bit_lock	wait_bit.c	/^EXPORT_SYMBOL(__wait_on_bit_lock);$/;"	v
__wait_on_bit_lock	wait_bit.c	/^__wait_on_bit_lock(struct wait_queue_head *wq_head, struct wait_bit_queue_entry *wbq_entry,$/;"	f
__wake_up	wait.c	/^EXPORT_SYMBOL(__wake_up);$/;"	v
__wake_up	wait.c	/^void __wake_up(struct wait_queue_head *wq_head, unsigned int mode,$/;"	f
__wake_up_bit	wait_bit.c	/^EXPORT_SYMBOL(__wake_up_bit);$/;"	v
__wake_up_bit	wait_bit.c	/^void __wake_up_bit(struct wait_queue_head *wq_head, void *word, int bit)$/;"	f
__wake_up_common	wait.c	/^static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode,$/;"	f	file:
__wake_up_common_lock	wait.c	/^static void __wake_up_common_lock(struct wait_queue_head *wq_head, unsigned int mode,$/;"	f	file:
__wake_up_locked	wait.c	/^EXPORT_SYMBOL_GPL(__wake_up_locked);$/;"	v
__wake_up_locked	wait.c	/^void __wake_up_locked(struct wait_queue_head *wq_head, unsigned int mode, int nr)$/;"	f
__wake_up_locked_key	wait.c	/^EXPORT_SYMBOL_GPL(__wake_up_locked_key);$/;"	v
__wake_up_locked_key	wait.c	/^void __wake_up_locked_key(struct wait_queue_head *wq_head, unsigned int mode, void *key)$/;"	f
__wake_up_locked_key_bookmark	wait.c	/^EXPORT_SYMBOL_GPL(__wake_up_locked_key_bookmark);$/;"	v
__wake_up_locked_key_bookmark	wait.c	/^void __wake_up_locked_key_bookmark(struct wait_queue_head *wq_head,$/;"	f
__wake_up_sync	wait.c	/^EXPORT_SYMBOL_GPL(__wake_up_sync);	\/* For internal use only *\/$/;"	v
__wake_up_sync	wait.c	/^void __wake_up_sync(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive)$/;"	f
__wake_up_sync_key	wait.c	/^EXPORT_SYMBOL_GPL(__wake_up_sync_key);$/;"	v
__wake_up_sync_key	wait.c	/^void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode,$/;"	f
_cond_resched	core.c	/^EXPORT_SYMBOL(_cond_resched);$/;"	v
_cond_resched	core.c	/^int __sched _cond_resched(void)$/;"	f
_nohz_idle_balance	fair.c	/^static bool _nohz_idle_balance(struct rq *this_rq, unsigned int flags,$/;"	f	file:
_pick_next_task_rt	rt.c	/^static struct task_struct *_pick_next_task_rt(struct rq *rq)$/;"	f	file:
_sched_setscheduler	core.c	/^static int _sched_setscheduler(struct task_struct *p, int policy,$/;"	f	file:
_task_util_est	fair.c	/^static inline unsigned long _task_util_est(struct task_struct *p)$/;"	f	file:
account_cfs_rq_runtime	fair.c	/^static void account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec) {}$/;"	f	file:
account_cfs_rq_runtime	fair.c	/^void account_cfs_rq_runtime(struct cfs_rq *cfs_rq, u64 delta_exec)$/;"	f	file:
account_entity_dequeue	fair.c	/^account_entity_dequeue(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
account_entity_enqueue	fair.c	/^account_entity_enqueue(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
account_guest_time	cputime.c	/^void account_guest_time(struct task_struct *p, u64 cputime)$/;"	f
account_idle_ticks	cputime.c	/^void account_idle_ticks(unsigned long ticks)$/;"	f
account_idle_time	cputime.c	/^void account_idle_time(u64 cputime)$/;"	f
account_numa_dequeue	fair.c	/^static inline void account_numa_dequeue(struct rq *rq, struct task_struct *p)$/;"	f	file:
account_numa_dequeue	fair.c	/^static void account_numa_dequeue(struct rq *rq, struct task_struct *p)$/;"	f	file:
account_numa_enqueue	fair.c	/^static inline void account_numa_enqueue(struct rq *rq, struct task_struct *p)$/;"	f	file:
account_numa_enqueue	fair.c	/^static void account_numa_enqueue(struct rq *rq, struct task_struct *p)$/;"	f	file:
account_other_time	cputime.c	/^static inline u64 account_other_time(u64 max)$/;"	f	file:
account_process_tick	cputime.c	/^void account_process_tick(struct task_struct *p, int user_tick)$/;"	f
account_steal_time	cputime.c	/^void account_steal_time(u64 cputime)$/;"	f
account_system_index_time	cputime.c	/^void account_system_index_time(struct task_struct *p,$/;"	f
account_system_time	cputime.c	/^void account_system_time(struct task_struct *p, int hardirq_offset, u64 cputime)$/;"	f
account_user_time	cputime.c	/^void account_user_time(struct task_struct *p, u64 cputime)$/;"	f
accumulate_sum	fair.c	/^accumulate_sum(u64 delta, int cpu, struct sched_avg *sa,$/;"	f	file:
activate_task	core.c	/^void activate_task(struct rq *rq, struct task_struct *p, int flags)$/;"	f
active	sched.h	/^	struct rt_prio_array	active;$/;"	m	struct:rt_rq	typeref:struct:rt_rq::rt_prio_array
active_balance	sched.h	/^	int			active_balance;$/;"	m	struct:rq
active_balance_work	sched.h	/^	struct cpu_stop_work	active_balance_work;$/;"	m	struct:rq	typeref:struct:rq::cpu_stop_work
active_load_balance_cpu_stop	fair.c	/^static int active_load_balance_cpu_stop(void *data)$/;"	f	file:
active_nodes	fair.c	/^	int active_nodes;$/;"	m	struct:numa_group	file:
add_nr_running	sched.h	/^static inline void add_nr_running(struct rq *rq, unsigned count)$/;"	f
add_positive	fair.c	2723;"	d	file:
add_rq_bw	deadline.c	/^void add_rq_bw(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
add_running_bw	deadline.c	/^void add_running_bw(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
add_tg_cfs_propagate	fair.c	/^static inline void add_tg_cfs_propagate(struct cfs_rq *cfs_rq, long runnable_sum) {}$/;"	f	file:
add_tg_cfs_propagate	fair.c	/^static inline void add_tg_cfs_propagate(struct cfs_rq *cfs_rq, long runnable_sum)$/;"	f	file:
add_wait_queue	wait.c	/^EXPORT_SYMBOL(add_wait_queue);$/;"	v
add_wait_queue	wait.c	/^void add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)$/;"	f
add_wait_queue_exclusive	wait.c	/^EXPORT_SYMBOL(add_wait_queue_exclusive);$/;"	v
add_wait_queue_exclusive	wait.c	/^void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)$/;"	f
age_stamp	sched.h	/^	u64			age_stamp;$/;"	m	struct:rq
all	fair.c	/^enum fbq_type { regular, remote, all };$/;"	e	enum:fbq_type	file:
alloc_fair_sched_group	fair.c	/^int alloc_fair_sched_group(struct task_group *tg, struct task_group *parent)$/;"	f
alloc_rootdomain	topology.c	/^static struct root_domain *alloc_rootdomain(void)$/;"	f	file:
alloc_rt_sched_group	rt.c	/^int alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)$/;"	f
alloc_sched_domains	topology.c	/^cpumask_var_t *alloc_sched_domains(unsigned int ndoms)$/;"	f
arch_asym_cpu_priority	fair.c	/^int __weak arch_asym_cpu_priority(int cpu)$/;"	f
arch_cpu_idle	idle.c	/^void __weak arch_cpu_idle(void)$/;"	f
arch_cpu_idle_dead	idle.c	/^void __weak arch_cpu_idle_dead(void) { }$/;"	f
arch_cpu_idle_enter	idle.c	/^void __weak arch_cpu_idle_enter(void) { }$/;"	f
arch_cpu_idle_exit	idle.c	/^void __weak arch_cpu_idle_exit(void) { }$/;"	f
arch_cpu_idle_prepare	idle.c	/^void __weak arch_cpu_idle_prepare(void) { }$/;"	f
arch_scale_cpu_capacity	sched.h	/^unsigned long arch_scale_cpu_capacity(struct sched_domain *sd, int cpu)$/;"	f
arch_scale_cpu_capacity	sched.h	/^unsigned long arch_scale_cpu_capacity(void __always_unused *sd, int cpu)$/;"	f
arch_scale_freq_capacity	sched.h	/^unsigned long arch_scale_freq_capacity(int cpu)$/;"	f
arch_scale_freq_invariant	sched.h	2175;"	d
arch_scale_freq_invariant	sched.h	2178;"	d
arch_update_cpu_topology	topology.c	/^int __weak arch_update_cpu_topology(void)$/;"	f
arch_vtime_task_switch	cputime.c	/^void arch_vtime_task_switch(struct task_struct *prev)$/;"	f
assert_clock_updated	sched.h	/^static inline void assert_clock_updated(struct rq *rq)$/;"	f
assign_cfs_rq_runtime	fair.c	/^static int assign_cfs_rq_runtime(struct cfs_rq *cfs_rq)$/;"	f	file:
asym_prefer_cpu	sched.h	/^	int			asym_prefer_cpu;	\/* CPU of highest priority in group *\/$/;"	m	struct:sched_group
attach_entity_cfs_rq	fair.c	/^static void attach_entity_cfs_rq(struct sched_entity *se)$/;"	f	file:
attach_entity_load_avg	fair.c	/^attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags) {}$/;"	f	file:
attach_entity_load_avg	fair.c	/^static void attach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)$/;"	f	file:
attach_one_task	fair.c	/^static void attach_one_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
attach_task	fair.c	/^static void attach_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
attach_task_cfs_rq	fair.c	/^static void attach_task_cfs_rq(struct task_struct *p)$/;"	f	file:
attach_tasks	fair.c	/^static void attach_tasks(struct lb_env *env)$/;"	f	file:
attr_set	cpufreq_schedutil.c	/^	struct gov_attr_set	attr_set;$/;"	m	struct:sugov_tunables	typeref:struct:sugov_tunables::gov_attr_set	file:
autogroup	autogroup.h	/^struct autogroup {$/;"	s
autogroup	sched.h	/^	struct autogroup	*autogroup;$/;"	m	struct:task_group	typeref:struct:task_group::autogroup
autogroup_create	autogroup.c	/^static inline struct autogroup *autogroup_create(void)$/;"	f	file:
autogroup_default	autogroup.c	/^static struct autogroup autogroup_default;$/;"	v	typeref:struct:autogroup	file:
autogroup_destroy	autogroup.c	/^static inline void autogroup_destroy(struct kref *kref)$/;"	f	file:
autogroup_free	autogroup.c	/^void autogroup_free(struct task_group *tg)$/;"	f
autogroup_free	autogroup.h	/^static inline void autogroup_free(struct task_group *tg) { }$/;"	f
autogroup_init	autogroup.c	/^void __init autogroup_init(struct task_struct *init_task)$/;"	f
autogroup_init	autogroup.h	/^static inline void autogroup_init(struct task_struct *init_task) {  }$/;"	f
autogroup_kref_get	autogroup.c	/^static inline struct autogroup *autogroup_kref_get(struct autogroup *ag)$/;"	f	file:
autogroup_kref_put	autogroup.c	/^static inline void autogroup_kref_put(struct autogroup *ag)$/;"	f	file:
autogroup_move_group	autogroup.c	/^autogroup_move_group(struct task_struct *p, struct autogroup *ag)$/;"	f	file:
autogroup_path	autogroup.c	/^int autogroup_path(struct task_group *tg, char *buf, int buflen)$/;"	f
autogroup_path	autogroup.h	/^static inline int autogroup_path(struct task_group *tg, char *buf, int buflen)$/;"	f
autogroup_seq_nr	autogroup.c	/^static atomic_t autogroup_seq_nr;$/;"	v	file:
autogroup_task_get	autogroup.c	/^static inline struct autogroup *autogroup_task_get(struct task_struct *p)$/;"	f	file:
autogroup_task_group	autogroup.h	/^autogroup_task_group(struct task_struct *p, struct task_group *tg)$/;"	f
autoremove_wake_function	wait.c	/^EXPORT_SYMBOL(autoremove_wake_function);$/;"	v
autoremove_wake_function	wait.c	/^int autoremove_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key)$/;"	f
available_idle_cpu	core.c	/^int available_idle_cpu(int cpu)$/;"	f
avenrun	loadavg.c	/^EXPORT_SYMBOL(avenrun); \/* should be removed *\/$/;"	v
avenrun	loadavg.c	/^unsigned long avenrun[3];$/;"	v
avg	sched.h	/^	struct sched_avg	avg;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::sched_avg
avg_idle	sched.h	/^	u64			avg_idle;$/;"	m	struct:rq
avg_load	fair.c	/^	unsigned long avg_load;	\/* Average load across all groups in sd *\/$/;"	m	struct:sd_lb_stats	file:
avg_load	fair.c	/^	unsigned long avg_load; \/*Avg load across the CPUs of the group *\/$/;"	m	struct:sg_lb_stats	file:
balance_callback	core.c	/^static inline void balance_callback(struct rq *rq)$/;"	f	file:
balance_callback	sched.h	/^	struct callback_head	*balance_callback;$/;"	m	struct:rq	typeref:struct:rq::callback_head
balance_runtime	rt.c	/^static inline void balance_runtime(struct rt_rq *rt_rq) {}$/;"	f	file:
balance_runtime	rt.c	/^static void balance_runtime(struct rt_rq *rt_rq)$/;"	f	file:
best_cpu	fair.c	/^	int best_cpu;$/;"	m	struct:task_numa_env	file:
best_imp	fair.c	/^	long best_imp;$/;"	m	struct:task_numa_env	file:
best_task	fair.c	/^	struct task_struct *best_task;$/;"	m	struct:task_numa_env	typeref:struct:task_numa_env::task_struct	file:
bit_wait	wait_bit.c	/^EXPORT_SYMBOL(bit_wait);$/;"	v
bit_wait	wait_bit.c	/^__sched int bit_wait(struct wait_bit_key *word, int mode)$/;"	f
bit_wait_io	wait_bit.c	/^EXPORT_SYMBOL(bit_wait_io);$/;"	v
bit_wait_io	wait_bit.c	/^__sched int bit_wait_io(struct wait_bit_key *word, int mode)$/;"	f
bit_wait_io_timeout	wait_bit.c	/^EXPORT_SYMBOL_GPL(bit_wait_io_timeout);$/;"	v
bit_wait_io_timeout	wait_bit.c	/^__sched int bit_wait_io_timeout(struct wait_bit_key *word, int mode)$/;"	f
bit_wait_timeout	wait_bit.c	/^EXPORT_SYMBOL_GPL(bit_wait_timeout);$/;"	v
bit_wait_timeout	wait_bit.c	/^__sched int bit_wait_timeout(struct wait_bit_key *word, int mode)$/;"	f
bit_waitqueue	wait_bit.c	/^EXPORT_SYMBOL(bit_waitqueue);$/;"	v
bit_waitqueue	wait_bit.c	/^wait_queue_head_t *bit_waitqueue(void *word, int bit)$/;"	f
build_balance_mask	topology.c	/^build_balance_mask(struct sched_domain *sd, struct sched_group *sg, struct cpumask *mask)$/;"	f	file:
build_group_from_child_sched_domain	topology.c	/^build_group_from_child_sched_domain(struct sched_domain *sd, int cpu)$/;"	f	file:
build_overlap_sched_groups	topology.c	/^build_overlap_sched_groups(struct sched_domain *sd, int cpu)$/;"	f	file:
build_sched_domain	topology.c	/^static struct sched_domain *build_sched_domain(struct sched_domain_topology_level *tl,$/;"	f	file:
build_sched_domains	topology.c	/^build_sched_domains(const struct cpumask *cpu_map, struct sched_domain_attr *attr)$/;"	f	file:
build_sched_groups	topology.c	/^build_sched_groups(struct sched_domain *sd, int cpu)$/;"	f	file:
busiest	fair.c	/^	struct sched_group *busiest;	\/* Busiest group in this sd *\/$/;"	m	struct:sd_lb_stats	typeref:struct:sd_lb_stats::sched_group	file:
busiest_stat	fair.c	/^	struct sg_lb_stats busiest_stat;\/* Statistics of the busiest group *\/$/;"	m	struct:sd_lb_stats	typeref:struct:sd_lb_stats::sg_lb_stats	file:
bw	sched.h	/^	u64			bw;$/;"	m	struct:dl_bw
bw_ratio	sched.h	/^	u64			bw_ratio;$/;"	m	struct:dl_rq
cached_raw_freq	cpufreq_schedutil.c	/^	unsigned int		cached_raw_freq;$/;"	m	struct:sugov_policy	file:
calc_delta_fair	fair.c	/^static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se)$/;"	f	file:
calc_global_load	loadavg.c	/^void calc_global_load(unsigned long ticks)$/;"	f
calc_global_load_tick	loadavg.c	/^void calc_global_load_tick(struct rq *this_rq)$/;"	f
calc_global_nohz	loadavg.c	/^static inline void calc_global_nohz(void) { }$/;"	f	file:
calc_global_nohz	loadavg.c	/^static void calc_global_nohz(void)$/;"	f	file:
calc_group_runnable	fair.c	/^static long calc_group_runnable(struct cfs_rq *cfs_rq, long shares)$/;"	f	file:
calc_group_shares	fair.c	/^static long calc_group_shares(struct cfs_rq *cfs_rq)$/;"	f	file:
calc_load	loadavg.c	/^calc_load(unsigned long load, unsigned long exp, unsigned long active)$/;"	f	file:
calc_load_active	sched.h	/^	long			calc_load_active;$/;"	m	struct:rq
calc_load_fold_active	loadavg.c	/^long calc_load_fold_active(struct rq *this_rq, long adjust)$/;"	f
calc_load_idx	loadavg.c	/^static int calc_load_idx;$/;"	v	file:
calc_load_migrate	core.c	/^static void calc_load_migrate(struct rq *rq)$/;"	f	file:
calc_load_n	loadavg.c	/^calc_load_n(unsigned long load, unsigned long exp,$/;"	f	file:
calc_load_nohz	loadavg.c	/^static atomic_long_t calc_load_nohz[2];$/;"	v	file:
calc_load_nohz_fold	loadavg.c	/^static inline long calc_load_nohz_fold(void) { return 0; }$/;"	f	file:
calc_load_nohz_fold	loadavg.c	/^static long calc_load_nohz_fold(void)$/;"	f	file:
calc_load_nohz_start	loadavg.c	/^void calc_load_nohz_start(void)$/;"	f
calc_load_nohz_stop	loadavg.c	/^void calc_load_nohz_stop(void)$/;"	f
calc_load_read_idx	loadavg.c	/^static inline int calc_load_read_idx(void)$/;"	f	file:
calc_load_tasks	loadavg.c	/^atomic_long_t calc_load_tasks;$/;"	v
calc_load_update	loadavg.c	/^unsigned long calc_load_update;$/;"	v
calc_load_update	sched.h	/^	unsigned long		calc_load_update;$/;"	m	struct:rq
calc_load_write_idx	loadavg.c	/^static inline int calc_load_write_idx(void)$/;"	f	file:
calculate_imbalance	fair.c	/^static inline void calculate_imbalance(struct lb_env *env, struct sd_lb_stats *sds)$/;"	f	file:
call_cpuidle	idle.c	/^static int call_cpuidle(struct cpuidle_driver *drv, struct cpuidle_device *dev,$/;"	f	file:
can_migrate_task	fair.c	/^int can_migrate_task(struct task_struct *p, struct lb_env *env)$/;"	f	file:
can_nice	core.c	/^int can_nice(const struct task_struct *p, const int nice)$/;"	f
cap_scale	sched.h	189;"	d
capacity	sched.h	/^	unsigned long		capacity;$/;"	m	struct:sched_group_capacity
capacity_margin	fair.c	/^unsigned int capacity_margin				= 1280;$/;"	v
capacity_of	fair.c	/^static unsigned long capacity_of(int cpu)$/;"	f	file:
capacity_orig_of	fair.c	/^static unsigned long capacity_orig_of(int cpu)$/;"	f	file:
capacity_spare_wake	fair.c	/^static unsigned long capacity_spare_wake(int cpu, struct task_struct *p)$/;"	f	file:
cfs	sched.h	/^	struct cfs_rq		cfs;$/;"	m	struct:rq	typeref:struct:rq::cfs_rq
cfs_bandwidth	sched.h	/^	struct cfs_bandwidth	cfs_bandwidth;$/;"	m	struct:task_group	typeref:struct:task_group::cfs_bandwidth
cfs_bandwidth	sched.h	/^struct cfs_bandwidth { };$/;"	s
cfs_bandwidth	sched.h	/^struct cfs_bandwidth {$/;"	s
cfs_bandwidth_slack_period	fair.c	/^static const u64 cfs_bandwidth_slack_period = 5 * NSEC_PER_MSEC;$/;"	v	file:
cfs_bandwidth_usage_dec	fair.c	/^void cfs_bandwidth_usage_dec(void) {}$/;"	f
cfs_bandwidth_usage_dec	fair.c	/^void cfs_bandwidth_usage_dec(void)$/;"	f
cfs_bandwidth_usage_inc	fair.c	/^void cfs_bandwidth_usage_inc(void) {}$/;"	f
cfs_bandwidth_usage_inc	fair.c	/^void cfs_bandwidth_usage_inc(void)$/;"	f
cfs_bandwidth_used	fair.c	/^static bool cfs_bandwidth_used(void)$/;"	f	file:
cfs_bandwidth_used	fair.c	/^static inline bool cfs_bandwidth_used(void)$/;"	f	file:
cfs_rq	sched.h	/^	struct cfs_rq		**cfs_rq;$/;"	m	struct:task_group	typeref:struct:task_group::cfs_rq
cfs_rq	sched.h	/^struct cfs_rq {$/;"	s
cfs_rq_clock_task	fair.c	/^static inline u64 cfs_rq_clock_task(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_has_blocked	fair.c	/^static inline bool cfs_rq_has_blocked(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_is_decayed	fair.c	/^static inline bool cfs_rq_is_decayed(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_last_update_time	fair.c	/^static inline u64 cfs_rq_last_update_time(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_load_avg	fair.c	/^static inline unsigned long cfs_rq_load_avg(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_of	fair.c	/^static inline struct cfs_rq *cfs_rq_of(struct sched_entity *se)$/;"	f	file:
cfs_rq_runnable_load_avg	fair.c	/^static inline unsigned long cfs_rq_runnable_load_avg(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_throttled	fair.c	/^static inline int cfs_rq_throttled(struct cfs_rq *cfs_rq)$/;"	f	file:
cfs_rq_util_change	fair.c	/^static inline void cfs_rq_util_change(struct cfs_rq *cfs_rq, int flags)$/;"	f	file:
cfs_schedulable_data	core.c	/^struct cfs_schedulable_data {$/;"	s	file:
cfs_se_util_change	fair.c	/^static inline void cfs_se_util_change(struct sched_avg *avg)$/;"	f	file:
cfs_tasks	sched.h	/^	struct list_head cfs_tasks;$/;"	m	struct:rq	typeref:struct:rq::list_head
check_asym_packing	fair.c	/^static int check_asym_packing(struct lb_env *env, struct sd_lb_stats *sds)$/;"	f	file:
check_cfs_rq_runtime	fair.c	/^static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq) { return false; }$/;"	f	file:
check_cfs_rq_runtime	fair.c	/^static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq)$/;"	f	file:
check_class_changed	core.c	/^static inline void check_class_changed(struct rq *rq, struct task_struct *p,$/;"	f	file:
check_cpu_capacity	fair.c	/^check_cpu_capacity(struct rq *rq, struct sched_domain *sd)$/;"	f	file:
check_enqueue_throttle	fair.c	/^static void check_enqueue_throttle(struct cfs_rq *cfs_rq) {}$/;"	f	file:
check_enqueue_throttle	fair.c	/^static void check_enqueue_throttle(struct cfs_rq *cfs_rq)$/;"	f	file:
check_preempt_curr	core.c	/^void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags)$/;"	f
check_preempt_curr	sched.h	/^	void (*check_preempt_curr)(struct rq *rq, struct task_struct *p, int flags);$/;"	m	struct:sched_class
check_preempt_curr_dl	deadline.c	/^static void check_preempt_curr_dl(struct rq *rq, struct task_struct *p,$/;"	f	file:
check_preempt_curr_idle	idle.c	/^static void check_preempt_curr_idle(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
check_preempt_curr_rt	rt.c	/^static void check_preempt_curr_rt(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
check_preempt_curr_stop	stop_task.c	/^check_preempt_curr_stop(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
check_preempt_equal_dl	deadline.c	/^static void check_preempt_equal_dl(struct rq *rq, struct task_struct *p)$/;"	f	file:
check_preempt_equal_prio	rt.c	/^static void check_preempt_equal_prio(struct rq *rq, struct task_struct *p)$/;"	f	file:
check_preempt_tick	fair.c	/^check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)$/;"	f	file:
check_preempt_wakeup	fair.c	/^static void check_preempt_wakeup(struct rq *rq, struct task_struct *p, int wake_flags)$/;"	f	file:
check_same_owner	core.c	/^static bool check_same_owner(struct task_struct *p)$/;"	f	file:
check_schedstat_required	fair.c	/^static inline void check_schedstat_required(void)$/;"	f	file:
check_spread	fair.c	/^static void check_spread(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
children	sched.h	/^	struct list_head	children;$/;"	m	struct:task_group	typeref:struct:task_group::list_head
claim_allocations	topology.c	/^static void claim_allocations(int cpu, struct sched_domain *sd)$/;"	f	file:
clear_buddies	fair.c	/^static void clear_buddies(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
clear_sched_clock_stable	clock.c	/^void clear_sched_clock_stable(void)$/;"	f
clock	clock.c	/^	u64			clock;$/;"	m	struct:sched_clock_data	file:
clock	sched.h	/^	u64			clock;$/;"	m	struct:rq
clock_task	sched.h	/^	u64			clock_task;$/;"	m	struct:rq
clock_update_flags	sched.h	/^	unsigned int		clock_update_flags;$/;"	m	struct:rq
clock_update_flags	sched.h	/^	unsigned int clock_update_flags;$/;"	m	struct:rq_flags
complete	completion.c	/^EXPORT_SYMBOL(complete);$/;"	v
complete	completion.c	/^void complete(struct completion *x)$/;"	f
complete_all	completion.c	/^EXPORT_SYMBOL(complete_all);$/;"	v
complete_all	completion.c	/^void complete_all(struct completion *x)$/;"	f
completion_done	completion.c	/^EXPORT_SYMBOL(completion_done);$/;"	v
completion_done	completion.c	/^bool completion_done(struct completion *x)$/;"	f
compute_capacity	fair.c	/^	unsigned long compute_capacity;$/;"	m	struct:numa_stats	file:
const_debug	sched.h	1324;"	d
const_debug	sched.h	1326;"	d
context_switch	core.c	/^context_switch(struct rq *rq, struct task_struct *prev,$/;"	f	file:
convert_prio	cpupri.c	/^static int convert_prio(int prio)$/;"	f	file:
cookie	sched.h	/^	struct pin_cookie cookie;$/;"	m	struct:rq_flags	typeref:struct:rq_flags::pin_cookie
count	cpupri.h	/^	atomic_t		count;$/;"	m	struct:cpupri_vec
cpu	core.c	/^	int			cpu;$/;"	m	struct:tick_work	file:
cpu	cpudeadline.h	/^	int			cpu;$/;"	m	struct:cpudl_item
cpu	cpufreq_schedutil.c	/^	unsigned int		cpu;$/;"	m	struct:sugov_cpu	file:
cpu	sched.h	/^	int			cpu;$/;"	m	struct:rq
cpu_attach_domain	topology.c	/^cpu_attach_domain(struct sched_domain *sd, struct root_domain *rd, int cpu)$/;"	f	file:
cpu_avg_load_per_task	fair.c	/^static unsigned long cpu_avg_load_per_task(int cpu)$/;"	f	file:
cpu_capacity	sched.h	/^	unsigned long		cpu_capacity;$/;"	m	struct:rq
cpu_capacity_orig	sched.h	/^	unsigned long		cpu_capacity_orig;$/;"	m	struct:rq
cpu_cfs_period_read_u64	core.c	/^static u64 cpu_cfs_period_read_u64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_cfs_period_write_u64	core.c	/^static int cpu_cfs_period_write_u64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_cfs_quota_read_s64	core.c	/^static s64 cpu_cfs_quota_read_s64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_cfs_quota_write_s64	core.c	/^static int cpu_cfs_quota_write_s64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_cfs_stat_show	core.c	/^static int cpu_cfs_stat_show(struct seq_file *sf, void *v)$/;"	f	file:
cpu_cgroup_attach	core.c	/^static void cpu_cgroup_attach(struct cgroup_taskset *tset)$/;"	f	file:
cpu_cgroup_can_attach	core.c	/^static int cpu_cgroup_can_attach(struct cgroup_taskset *tset)$/;"	f	file:
cpu_cgroup_css_alloc	core.c	/^cpu_cgroup_css_alloc(struct cgroup_subsys_state *parent_css)$/;"	f	file:
cpu_cgroup_css_free	core.c	/^static void cpu_cgroup_css_free(struct cgroup_subsys_state *css)$/;"	f	file:
cpu_cgroup_css_online	core.c	/^static int cpu_cgroup_css_online(struct cgroup_subsys_state *css)$/;"	f	file:
cpu_cgroup_css_released	core.c	/^static void cpu_cgroup_css_released(struct cgroup_subsys_state *css)$/;"	f	file:
cpu_cgroup_fork	core.c	/^static void cpu_cgroup_fork(struct task_struct *task)$/;"	f	file:
cpu_cgrp_subsys	core.c	/^struct cgroup_subsys cpu_cgrp_subsys = {$/;"	v	typeref:struct:cgroup_subsys
cpu_curr	sched.h	928;"	d
cpu_extra_stat_show	core.c	/^static int cpu_extra_stat_show(struct seq_file *sf,$/;"	f	file:
cpu_files	core.c	/^static struct cftype cpu_files[] = {$/;"	v	typeref:struct:cftype	file:
cpu_idle_force_poll	idle.c	/^static int __read_mostly cpu_idle_force_poll;$/;"	v	file:
cpu_idle_nopoll_setup	idle.c	/^static int __init cpu_idle_nopoll_setup(char *__unused)$/;"	f	file:
cpu_idle_poll	idle.c	/^static noinline int __cpuidle cpu_idle_poll(void)$/;"	f	file:
cpu_idle_poll_ctrl	idle.c	/^void cpu_idle_poll_ctrl(bool enable)$/;"	f
cpu_idle_poll_setup	idle.c	/^static int __init cpu_idle_poll_setup(char *__unused)$/;"	f	file:
cpu_in_idle	idle.c	/^bool cpu_in_idle(unsigned long pc)$/;"	f
cpu_legacy_files	core.c	/^static struct cftype cpu_legacy_files[] = {$/;"	v	typeref:struct:cftype	file:
cpu_load	sched.h	/^	unsigned long		cpu_load[CPU_LOAD_IDX_MAX];$/;"	m	struct:rq
cpu_load_update	fair.c	/^static void cpu_load_update(struct rq *this_rq, unsigned long this_load,$/;"	f	file:
cpu_load_update_active	fair.c	/^void cpu_load_update_active(struct rq *this_rq)$/;"	f
cpu_load_update_active	sched.h	/^static inline void cpu_load_update_active(struct rq *this_rq) { }$/;"	f
cpu_load_update_idle	fair.c	/^static void cpu_load_update_idle(struct rq *this_rq)$/;"	f	file:
cpu_load_update_nohz	fair.c	/^static inline void cpu_load_update_nohz(struct rq *this_rq,$/;"	f	file:
cpu_load_update_nohz	fair.c	/^static void cpu_load_update_nohz(struct rq *this_rq,$/;"	f	file:
cpu_load_update_nohz_start	fair.c	/^void cpu_load_update_nohz_start(void)$/;"	f
cpu_load_update_nohz_stop	fair.c	/^void cpu_load_update_nohz_stop(void)$/;"	f
cpu_load_update_periodic	fair.c	/^static void cpu_load_update_periodic(struct rq *this_rq, unsigned long load)$/;"	f	file:
cpu_max_show	core.c	/^static int cpu_max_show(struct seq_file *sf, void *v)$/;"	f	file:
cpu_max_write	core.c	/^static ssize_t cpu_max_write(struct kernfs_open_file *of,$/;"	f	file:
cpu_of	sched.h	/^static inline int cpu_of(struct rq *rq)$/;"	f
cpu_period_quota_parse	core.c	/^static int __maybe_unused cpu_period_quota_parse(char *buf,$/;"	f	file:
cpu_period_quota_print	core.c	/^static void __maybe_unused cpu_period_quota_print(struct seq_file *sf,$/;"	f	file:
cpu_rq	sched.h	925;"	d
cpu_rt_period_read_uint	core.c	/^static u64 cpu_rt_period_read_uint(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_rt_period_write_uint	core.c	/^static int cpu_rt_period_write_uint(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_rt_runtime_read	core.c	/^static s64 cpu_rt_runtime_read(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_rt_runtime_write	core.c	/^static int cpu_rt_runtime_write(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_sdc	clock.c	/^static inline struct sched_clock_data *cpu_sdc(int cpu)$/;"	f	file:
cpu_shares_read_u64	core.c	/^static u64 cpu_shares_read_u64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_shares_write_u64	core.c	/^static int cpu_shares_write_u64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_startup_entry	idle.c	/^void cpu_startup_entry(enum cpuhp_state state)$/;"	f
cpu_to_pri	cpupri.h	/^	int			*cpu_to_pri;$/;"	m	struct:cpupri
cpu_util	fair.c	/^static inline unsigned long cpu_util(int cpu)$/;"	f	file:
cpu_util_cfs	sched.h	/^static inline unsigned long cpu_util_cfs(struct rq *rq)$/;"	f
cpu_util_dl	sched.h	/^static inline unsigned long cpu_util_dl(struct rq *rq)$/;"	f
cpu_util_wake	fair.c	/^static unsigned long cpu_util_wake(int cpu, struct task_struct *p)$/;"	f	file:
cpu_weight_nice_read_s64	core.c	/^static s64 cpu_weight_nice_read_s64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_weight_nice_write_s64	core.c	/^static int cpu_weight_nice_write_s64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_weight_read_u64	core.c	/^static u64 cpu_weight_read_u64(struct cgroup_subsys_state *css,$/;"	f	file:
cpu_weight_write_u64	core.c	/^static int cpu_weight_write_u64(struct cgroup_subsys_state *css,$/;"	f	file:
cpuacct	cpuacct.c	/^struct cpuacct {$/;"	s	file:
cpuacct_account_field	cpuacct.c	/^void cpuacct_account_field(struct task_struct *tsk, int index, u64 val)$/;"	f
cpuacct_all_seq_show	cpuacct.c	/^static int cpuacct_all_seq_show(struct seq_file *m, void *V)$/;"	f	file:
cpuacct_cgrp_subsys	cpuacct.c	/^struct cgroup_subsys cpuacct_cgrp_subsys = {$/;"	v	typeref:struct:cgroup_subsys
cpuacct_charge	cpuacct.c	/^void cpuacct_charge(struct task_struct *tsk, u64 cputime)$/;"	f
cpuacct_cpuusage_read	cpuacct.c	/^static u64 cpuacct_cpuusage_read(struct cpuacct *ca, int cpu,$/;"	f	file:
cpuacct_cpuusage_write	cpuacct.c	/^static void cpuacct_cpuusage_write(struct cpuacct *ca, int cpu, u64 val)$/;"	f	file:
cpuacct_css_alloc	cpuacct.c	/^cpuacct_css_alloc(struct cgroup_subsys_state *parent_css)$/;"	f	file:
cpuacct_css_free	cpuacct.c	/^static void cpuacct_css_free(struct cgroup_subsys_state *css)$/;"	f	file:
cpuacct_percpu_seq_show	cpuacct.c	/^static int cpuacct_percpu_seq_show(struct seq_file *m, void *V)$/;"	f	file:
cpuacct_percpu_sys_seq_show	cpuacct.c	/^static int cpuacct_percpu_sys_seq_show(struct seq_file *m, void *V)$/;"	f	file:
cpuacct_percpu_user_seq_show	cpuacct.c	/^static int cpuacct_percpu_user_seq_show(struct seq_file *m, void *V)$/;"	f	file:
cpuacct_stat_desc	cpuacct.c	/^static const char * const cpuacct_stat_desc[] = {$/;"	v	file:
cpuacct_stat_index	cpuacct.c	/^enum cpuacct_stat_index {$/;"	g	file:
cpuacct_stats_show	cpuacct.c	/^static int cpuacct_stats_show(struct seq_file *sf, void *v)$/;"	f	file:
cpuacct_usage	cpuacct.c	/^struct cpuacct_usage {$/;"	s	file:
cpudl	cpudeadline.h	/^struct cpudl {$/;"	s
cpudl	sched.h	/^	struct cpudl		cpudl;$/;"	m	struct:root_domain	typeref:struct:root_domain::cpudl
cpudl_cleanup	cpudeadline.c	/^void cpudl_cleanup(struct cpudl *cp)$/;"	f
cpudl_clear	cpudeadline.c	/^void cpudl_clear(struct cpudl *cp, int cpu)$/;"	f
cpudl_clear_freecpu	cpudeadline.c	/^void cpudl_clear_freecpu(struct cpudl *cp, int cpu)$/;"	f
cpudl_find	cpudeadline.c	/^int cpudl_find(struct cpudl *cp, struct task_struct *p,$/;"	f
cpudl_heapify	cpudeadline.c	/^static void cpudl_heapify(struct cpudl *cp, int idx)$/;"	f	file:
cpudl_heapify_down	cpudeadline.c	/^static void cpudl_heapify_down(struct cpudl *cp, int idx)$/;"	f	file:
cpudl_heapify_up	cpudeadline.c	/^static void cpudl_heapify_up(struct cpudl *cp, int idx)$/;"	f	file:
cpudl_init	cpudeadline.c	/^int cpudl_init(struct cpudl *cp)$/;"	f
cpudl_item	cpudeadline.h	/^struct cpudl_item {$/;"	s
cpudl_maximum	cpudeadline.c	/^static inline int cpudl_maximum(struct cpudl *cp)$/;"	f	file:
cpudl_set	cpudeadline.c	/^void cpudl_set(struct cpudl *cp, int cpu, u64 dl)$/;"	f
cpudl_set_freecpu	cpudeadline.c	/^void cpudl_set_freecpu(struct cpudl *cp, int cpu)$/;"	f
cpufreq_add_update_util_hook	cpufreq.c	/^EXPORT_SYMBOL_GPL(cpufreq_add_update_util_hook);$/;"	v
cpufreq_add_update_util_hook	cpufreq.c	/^void cpufreq_add_update_util_hook(int cpu, struct update_util_data *data,$/;"	f
cpufreq_default_governor	cpufreq_schedutil.c	/^struct cpufreq_governor *cpufreq_default_governor(void)$/;"	f
cpufreq_remove_update_util_hook	cpufreq.c	/^EXPORT_SYMBOL_GPL(cpufreq_remove_update_util_hook);$/;"	v
cpufreq_remove_update_util_hook	cpufreq.c	/^void cpufreq_remove_update_util_hook(int cpu)$/;"	f
cpufreq_update_util	sched.h	/^static inline void cpufreq_update_util(struct rq *rq, unsigned int flags) {}$/;"	f
cpufreq_update_util	sched.h	/^static inline void cpufreq_update_util(struct rq *rq, unsigned int flags)$/;"	f
cpuidle_idle_call	idle.c	/^static void cpuidle_idle_call(void)$/;"	f	file:
cpumask	sched.h	/^	unsigned long		cpumask[0];		\/* Balance mask *\/$/;"	m	struct:sched_group_capacity
cpumask	sched.h	/^	unsigned long		cpumask[0];$/;"	m	struct:sched_group
cpupri	cpupri.h	/^struct cpupri {$/;"	s
cpupri	sched.h	/^	struct cpupri		cpupri;$/;"	m	struct:root_domain	typeref:struct:root_domain::cpupri
cpupri_cleanup	cpupri.c	/^void cpupri_cleanup(struct cpupri *cp)$/;"	f
cpupri_find	cpupri.c	/^int cpupri_find(struct cpupri *cp, struct task_struct *p,$/;"	f
cpupri_init	cpupri.c	/^int cpupri_init(struct cpupri *cp)$/;"	f
cpupri_set	cpupri.c	/^void cpupri_set(struct cpupri *cp, int cpu, int newpri)$/;"	f
cpupri_vec	cpupri.h	/^struct cpupri_vec {$/;"	s
cpus	fair.c	/^	struct cpumask		*cpus;$/;"	m	struct:lb_env	typeref:struct:lb_env::cpumask	file:
cpus_share_cache	core.c	/^bool cpus_share_cache(int this_cpu, int that_cpu)$/;"	f
cpuset_cpu_active	core.c	/^static void cpuset_cpu_active(void)$/;"	f	file:
cpuset_cpu_inactive	core.c	/^static int cpuset_cpu_inactive(unsigned int cpu)$/;"	f	file:
cpuset_cpumask_can_shrink	core.c	/^int cpuset_cpumask_can_shrink(const struct cpumask *cur,$/;"	f
cpustat	cpuacct.c	/^	struct kernel_cpustat __percpu	*cpustat;$/;"	m	struct:cpuacct	typeref:struct:cpuacct::__percpu	file:
cputime_adjust	cputime.c	/^void cputime_adjust(struct task_cputime *curr, struct prev_cputime *prev,$/;"	f
cpuusage	cpuacct.c	/^	struct cpuacct_usage __percpu	*cpuusage;$/;"	m	struct:cpuacct	typeref:struct:cpuacct::__percpu	file:
cpuusage_read	cpuacct.c	/^static u64 cpuusage_read(struct cgroup_subsys_state *css, struct cftype *cft)$/;"	f	file:
cpuusage_sys_read	cpuacct.c	/^static u64 cpuusage_sys_read(struct cgroup_subsys_state *css,$/;"	f	file:
cpuusage_user_read	cpuacct.c	/^static u64 cpuusage_user_read(struct cgroup_subsys_state *css,$/;"	f	file:
cpuusage_write	cpuacct.c	/^static int cpuusage_write(struct cgroup_subsys_state *css, struct cftype *cft,$/;"	f	file:
css	cpuacct.c	/^	struct cgroup_subsys_state	css;$/;"	m	struct:cpuacct	typeref:struct:cpuacct::cgroup_subsys_state	file:
css	sched.h	/^	struct cgroup_subsys_state css;$/;"	m	struct:task_group	typeref:struct:task_group::cgroup_subsys_state
css_ca	cpuacct.c	/^static inline struct cpuacct *css_ca(struct cgroup_subsys_state *css)$/;"	f	file:
css_tg	core.c	/^static inline struct task_group *css_tg(struct cgroup_subsys_state *css)$/;"	f	file:
curr	sched.h	/^		int		curr; \/* highest queued rt task prio *\/$/;"	m	struct:rt_rq::__anon3
curr	sched.h	/^		u64		curr;$/;"	m	struct:dl_rq::__anon4
curr	sched.h	/^	struct sched_entity	*curr;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::sched_entity
curr	sched.h	/^	struct task_struct	*curr;$/;"	m	struct:rq	typeref:struct:rq::task_struct
curr_task	core.c	/^struct task_struct *curr_task(int cpu)$/;"	f
dattr_cur	topology.c	/^static struct sched_domain_attr		*dattr_cur;$/;"	v	typeref:struct:sched_domain_attr	file:
dattrs_equal	topology.c	/^static int dattrs_equal(struct sched_domain_attr *cur, int idx_cur,$/;"	f	file:
deactivate_task	core.c	/^void deactivate_task(struct rq *rq, struct task_struct *p, int flags)$/;"	f
deadline_queue_pull_task	deadline.c	/^static inline void deadline_queue_pull_task(struct rq *rq)$/;"	f	file:
deadline_queue_push_tasks	deadline.c	/^static inline void deadline_queue_push_tasks(struct rq *rq)$/;"	f	file:
dec_dl_deadline	deadline.c	/^static inline void dec_dl_deadline(struct dl_rq *dl_rq, u64 deadline) {}$/;"	f	file:
dec_dl_deadline	deadline.c	/^static void dec_dl_deadline(struct dl_rq *dl_rq, u64 deadline)$/;"	f	file:
dec_dl_migration	deadline.c	/^static void dec_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
dec_dl_migration	deadline.c	/^void dec_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
dec_dl_tasks	deadline.c	/^void dec_dl_tasks(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
dec_rt_group	rt.c	/^dec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
dec_rt_group	rt.c	/^void dec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq) {}$/;"	f	file:
dec_rt_migration	rt.c	/^static void dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
dec_rt_migration	rt.c	/^void dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
dec_rt_prio	rt.c	/^dec_rt_prio(struct rt_rq *rt_rq, int prio)$/;"	f	file:
dec_rt_prio	rt.c	/^static inline void dec_rt_prio(struct rt_rq *rt_rq, int prio) {}$/;"	f	file:
dec_rt_prio_smp	rt.c	/^dec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio)$/;"	f	file:
dec_rt_prio_smp	rt.c	/^void dec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}$/;"	f	file:
dec_rt_tasks	rt.c	/^void dec_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
decay_load	fair.c	/^static u64 decay_load(u64 val, u64 n)$/;"	f	file:
decay_load_missed	fair.c	/^decay_load_missed(unsigned long load, unsigned long missed_updates, int idx)$/;"	f	file:
def_dl_bandwidth	deadline.c	/^struct dl_bandwidth def_dl_bandwidth;$/;"	v	typeref:struct:dl_bandwidth
def_root_domain	topology.c	/^struct root_domain def_root_domain;$/;"	v	typeref:struct:root_domain
def_rt_bandwidth	rt.c	/^struct rt_bandwidth def_rt_bandwidth;$/;"	v	typeref:struct:rt_bandwidth
default_cfs_period	fair.c	/^static inline u64 default_cfs_period(void)$/;"	f	file:
default_idle_call	idle.c	/^void __cpuidle default_idle_call(void)$/;"	f
default_relax_domain_level	topology.c	/^static int default_relax_domain_level = -1;$/;"	v	file:
default_topology	topology.c	/^static struct sched_domain_topology_level default_topology[] = {$/;"	v	typeref:struct:sched_domain_topology_level	file:
default_wake_function	core.c	/^EXPORT_SYMBOL(default_wake_function);$/;"	v
default_wake_function	core.c	/^int default_wake_function(wait_queue_entry_t *curr, unsigned mode, int wake_flags,$/;"	f
degrade_factor	fair.c	/^static const u8 degrade_factor[CPU_LOAD_IDX_MAX][DEGRADE_SHIFT + 1] = {$/;"	v	file:
degrade_zero_ticks	fair.c	/^static const u8 degrade_zero_ticks[CPU_LOAD_IDX_MAX] = {0, 8, 32, 64, 128};$/;"	v	file:
dequeue_dl_entity	deadline.c	/^static void dequeue_dl_entity(struct sched_dl_entity *dl_se)$/;"	f	file:
dequeue_entity	fair.c	/^dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)$/;"	f	file:
dequeue_load_avg	fair.c	/^dequeue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) { }$/;"	f	file:
dequeue_load_avg	fair.c	/^dequeue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
dequeue_pushable_dl_task	deadline.c	/^static void dequeue_pushable_dl_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
dequeue_pushable_dl_task	deadline.c	/^void dequeue_pushable_dl_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
dequeue_pushable_task	rt.c	/^static inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
dequeue_pushable_task	rt.c	/^static void dequeue_pushable_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
dequeue_rt_entity	rt.c	/^static void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)$/;"	f	file:
dequeue_rt_stack	rt.c	/^static void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)$/;"	f	file:
dequeue_runnable_load_avg	fair.c	/^dequeue_runnable_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) { }$/;"	f	file:
dequeue_runnable_load_avg	fair.c	/^dequeue_runnable_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
dequeue_task	core.c	/^static inline void dequeue_task(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
dequeue_task	sched.h	/^	void (*dequeue_task) (struct rq *rq, struct task_struct *p, int flags);$/;"	m	struct:sched_class
dequeue_task_dl	deadline.c	/^static void dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
dequeue_task_fair	fair.c	/^static void dequeue_task_fair(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
dequeue_task_idle	idle.c	/^dequeue_task_idle(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
dequeue_task_rt	rt.c	/^static void dequeue_task_rt(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
dequeue_task_stop	stop_task.c	/^dequeue_task_stop(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
dequeue_top_rt_rq	rt.c	/^dequeue_top_rt_rq(struct rt_rq *rt_rq)$/;"	f	file:
dest_cpu	core.c	/^	int dest_cpu;$/;"	m	struct:migration_arg	file:
destroy_cfs_bandwidth	fair.c	/^static inline void destroy_cfs_bandwidth(struct cfs_bandwidth *cfs_b) {}$/;"	f	file:
destroy_cfs_bandwidth	fair.c	/^static void destroy_cfs_bandwidth(struct cfs_bandwidth *cfs_b)$/;"	f	file:
destroy_rt_bandwidth	rt.c	/^static void destroy_rt_bandwidth(struct rt_bandwidth *rt_b)$/;"	f	file:
destroy_sched_domain	topology.c	/^static void destroy_sched_domain(struct sched_domain *sd)$/;"	f	file:
destroy_sched_domains	topology.c	/^static void destroy_sched_domains(struct sched_domain *sd)$/;"	f	file:
destroy_sched_domains_rcu	topology.c	/^static void destroy_sched_domains_rcu(struct rcu_head *rcu)$/;"	f	file:
detach_destroy_domains	topology.c	/^static void detach_destroy_domains(const struct cpumask *cpu_map)$/;"	f	file:
detach_entity_cfs_rq	fair.c	/^static void detach_entity_cfs_rq(struct sched_entity *se)$/;"	f	file:
detach_entity_load_avg	fair.c	/^detach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) {}$/;"	f	file:
detach_entity_load_avg	fair.c	/^static void detach_entity_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
detach_one_task	fair.c	/^static struct task_struct *detach_one_task(struct lb_env *env)$/;"	f	file:
detach_task	fair.c	/^static void detach_task(struct task_struct *p, struct lb_env *env)$/;"	f	file:
detach_task_cfs_rq	fair.c	/^static void detach_task_cfs_rq(struct task_struct *p)$/;"	f	file:
detach_tasks	fair.c	/^static int detach_tasks(struct lb_env *env)$/;"	f	file:
dirty_sched_domain_sysctl	debug.c	/^void dirty_sched_domain_sysctl(int cpu)$/;"	f
dirty_sched_domain_sysctl	sched.h	/^static inline void dirty_sched_domain_sysctl(int cpu)$/;"	f
disable_sched_clock_irqtime	cputime.c	/^void disable_sched_clock_irqtime(void)$/;"	f
dist	fair.c	/^	int dist;$/;"	m	struct:task_numa_env	file:
distribute_cfs_runtime	fair.c	/^static u64 distribute_cfs_runtime(struct cfs_bandwidth *cfs_b,$/;"	f	file:
distribute_running	sched.h	/^	bool                    distribute_running;$/;"	m	struct:cfs_bandwidth
dl	cpudeadline.h	/^	u64			dl;$/;"	m	struct:cpudl_item
dl	sched.h	/^	struct dl_rq		dl;$/;"	m	struct:rq	typeref:struct:rq::dl_rq
dl_bandwidth	sched.h	/^struct dl_bandwidth {$/;"	s
dl_bandwidth_enabled	sched.h	/^static inline int dl_bandwidth_enabled(void)$/;"	f
dl_bw	sched.h	/^	struct dl_bw		dl_bw;$/;"	m	struct:dl_rq	typeref:struct:dl_rq::dl_bw
dl_bw	sched.h	/^	struct dl_bw		dl_bw;$/;"	m	struct:root_domain	typeref:struct:root_domain::dl_bw
dl_bw	sched.h	/^struct dl_bw {$/;"	s
dl_bw_cpus	deadline.c	/^static inline int dl_bw_cpus(int i)$/;"	f	file:
dl_bw_of	deadline.c	/^static inline struct dl_bw *dl_bw_of(int i)$/;"	f	file:
dl_change_utilization	deadline.c	/^void dl_change_utilization(struct task_struct *p, u64 new_bw)$/;"	f
dl_check_constrained_dl	deadline.c	/^static inline void dl_check_constrained_dl(struct sched_dl_entity *dl_se)$/;"	f	file:
dl_clear_overload	deadline.c	/^static inline void dl_clear_overload(struct rq *rq)$/;"	f	file:
dl_cpu_busy	deadline.c	/^bool dl_cpu_busy(unsigned int cpu)$/;"	f
dl_cpuset_cpumask_can_shrink	deadline.c	/^int dl_cpuset_cpumask_can_shrink(const struct cpumask *cur,$/;"	f
dl_entity_is_special	sched.h	/^static inline bool dl_entity_is_special(struct sched_dl_entity *dl_se)$/;"	f
dl_entity_overflow	deadline.c	/^static bool dl_entity_overflow(struct sched_dl_entity *dl_se,$/;"	f	file:
dl_entity_preempt	sched.h	/^dl_entity_preempt(struct sched_dl_entity *a, struct sched_dl_entity *b)$/;"	f
dl_is_implicit	deadline.c	/^static inline bool dl_is_implicit(struct sched_dl_entity *dl_se)$/;"	f	file:
dl_next_period	deadline.c	/^static inline u64 dl_next_period(struct sched_dl_entity *dl_se)$/;"	f	file:
dl_nr_migratory	sched.h	/^	unsigned long		dl_nr_migratory;$/;"	m	struct:dl_rq
dl_nr_running	sched.h	/^	unsigned long		dl_nr_running;$/;"	m	struct:dl_rq
dl_overloaded	deadline.c	/^static inline int dl_overloaded(struct rq *rq)$/;"	f	file:
dl_param_changed	deadline.c	/^bool dl_param_changed(struct task_struct *p, const struct sched_attr *attr)$/;"	f
dl_period	sched.h	/^	u64			dl_period;$/;"	m	struct:dl_bandwidth
dl_policy	sched.h	/^static inline int dl_policy(int policy)$/;"	f
dl_rq	sched.h	/^struct dl_rq {$/;"	s
dl_rq_of_se	deadline.c	/^static inline struct dl_rq *dl_rq_of_se(struct sched_dl_entity *dl_se)$/;"	f	file:
dl_runtime	sched.h	/^	u64			dl_runtime;$/;"	m	struct:dl_bandwidth
dl_runtime_exceeded	deadline.c	/^int dl_runtime_exceeded(struct sched_dl_entity *dl_se)$/;"	f	file:
dl_runtime_lock	sched.h	/^	raw_spinlock_t		dl_runtime_lock;$/;"	m	struct:dl_bandwidth
dl_sched_class	deadline.c	/^const struct sched_class dl_sched_class = {$/;"	v	typeref:struct:sched_class
dl_set_overload	deadline.c	/^static inline void dl_set_overload(struct rq *rq)$/;"	f	file:
dl_task_can_attach	deadline.c	/^int dl_task_can_attach(struct task_struct *p, const struct cpumask *cs_cpus_allowed)$/;"	f
dl_task_of	deadline.c	/^static inline struct task_struct *dl_task_of(struct sched_dl_entity *dl_se)$/;"	f	file:
dl_task_offline_migration	deadline.c	/^static struct rq *dl_task_offline_migration(struct rq *rq, struct task_struct *p)$/;"	f	file:
dl_task_timer	deadline.c	/^static enum hrtimer_restart dl_task_timer(struct hrtimer *timer)$/;"	f	file:
dlo_count	sched.h	/^	atomic_t		dlo_count;$/;"	m	struct:root_domain
dlo_mask	sched.h	/^	cpumask_var_t		dlo_mask;$/;"	m	struct:root_domain
do_balance_runtime	rt.c	/^static void do_balance_runtime(struct rt_rq *rt_rq)$/;"	f	file:
do_idle	idle.c	/^static void do_idle(void)$/;"	f	file:
do_sched_cfs_period_timer	fair.c	/^static int do_sched_cfs_period_timer(struct cfs_bandwidth *cfs_b, int overrun)$/;"	f	file:
do_sched_cfs_slack_timer	fair.c	/^static void do_sched_cfs_slack_timer(struct cfs_bandwidth *cfs_b)$/;"	f	file:
do_sched_rt_period_timer	rt.c	/^static int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun)$/;"	f	file:
do_sched_setscheduler	core.c	/^do_sched_setscheduler(pid_t pid, int policy, struct sched_param __user *param)$/;"	f	file:
do_sched_yield	core.c	/^static void do_sched_yield(void)$/;"	f	file:
do_set_cpus_allowed	core.c	/^void do_set_cpus_allowed(struct task_struct *p, const struct cpumask *new_mask)$/;"	f
do_task_dead	core.c	/^void __noreturn do_task_dead(void)$/;"	f
do_wait_for_common	completion.c	/^do_wait_for_common(struct completion *x,$/;"	f	file:
do_wait_intr	wait.c	/^EXPORT_SYMBOL(do_wait_intr);$/;"	v
do_wait_intr	wait.c	/^int do_wait_intr(wait_queue_head_t *wq, wait_queue_entry_t *wait)$/;"	f
do_wait_intr_irq	wait.c	/^EXPORT_SYMBOL(do_wait_intr_irq);$/;"	v
do_wait_intr_irq	wait.c	/^int do_wait_intr_irq(wait_queue_head_t *wq, wait_queue_entry_t *wait)$/;"	f
doms_cur	topology.c	/^static cpumask_var_t			*doms_cur;$/;"	v	file:
done	idle.c	/^	int done;$/;"	m	struct:idle_timer	file:
double_lock	sched.h	/^static inline void double_lock(spinlock_t *l1, spinlock_t *l2)$/;"	f
double_lock_balance	sched.h	/^static inline int double_lock_balance(struct rq *this_rq, struct rq *busiest)$/;"	f
double_lock_irq	sched.h	/^static inline void double_lock_irq(spinlock_t *l1, spinlock_t *l2)$/;"	f
double_raw_lock	sched.h	/^static inline void double_raw_lock(raw_spinlock_t *l1, raw_spinlock_t *l2)$/;"	f
dst_cpu	core.c	/^	int src_cpu, dst_cpu;$/;"	m	struct:migration_swap_arg	file:
dst_cpu	fair.c	/^	int			dst_cpu;$/;"	m	struct:lb_env	file:
dst_cpu	fair.c	/^	int dst_cpu, dst_nid;$/;"	m	struct:task_numa_env	file:
dst_grpmask	fair.c	/^	struct cpumask		*dst_grpmask;$/;"	m	struct:lb_env	typeref:struct:lb_env::cpumask	file:
dst_nid	fair.c	/^	int dst_cpu, dst_nid;$/;"	m	struct:task_numa_env	file:
dst_rq	fair.c	/^	struct rq		*dst_rq;$/;"	m	struct:lb_env	typeref:struct:lb_env::rq	file:
dst_stats	fair.c	/^	struct numa_stats src_stats, dst_stats;$/;"	m	struct:task_numa_env	typeref:struct:task_numa_env::	file:
dst_task	core.c	/^	struct task_struct *src_task, *dst_task;$/;"	m	struct:migration_swap_arg	typeref:struct:migration_swap_arg::	file:
dump_cpu_task	core.c	/^void dump_cpu_task(int cpu)$/;"	f
earliest_dl	sched.h	/^	} earliest_dl;$/;"	m	struct:dl_rq	typeref:struct:dl_rq::__anon4
effective_prio	core.c	/^static int effective_prio(struct task_struct *p)$/;"	f	file:
elements	cpudeadline.h	/^	struct cpudl_item	*elements;$/;"	m	struct:cpudl	typeref:struct:cpudl::cpudl_item
enable_sched_clock_irqtime	cputime.c	/^void enable_sched_clock_irqtime(void)$/;"	f
enqueue_dl_entity	deadline.c	/^enqueue_dl_entity(struct sched_dl_entity *dl_se,$/;"	f	file:
enqueue_entity	fair.c	/^enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)$/;"	f	file:
enqueue_load_avg	fair.c	/^enqueue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) { }$/;"	f	file:
enqueue_load_avg	fair.c	/^enqueue_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
enqueue_pushable_dl_task	deadline.c	/^static void enqueue_pushable_dl_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
enqueue_pushable_dl_task	deadline.c	/^void enqueue_pushable_dl_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
enqueue_pushable_task	rt.c	/^static inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
enqueue_pushable_task	rt.c	/^static void enqueue_pushable_task(struct rq *rq, struct task_struct *p)$/;"	f	file:
enqueue_rt_entity	rt.c	/^static void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)$/;"	f	file:
enqueue_runnable_load_avg	fair.c	/^enqueue_runnable_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se) { }$/;"	f	file:
enqueue_runnable_load_avg	fair.c	/^enqueue_runnable_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
enqueue_task	core.c	/^static inline void enqueue_task(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
enqueue_task	sched.h	/^	void (*enqueue_task) (struct rq *rq, struct task_struct *p, int flags);$/;"	m	struct:sched_class
enqueue_task_dl	deadline.c	/^static void enqueue_task_dl(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
enqueue_task_fair	fair.c	/^enqueue_task_fair(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
enqueue_task_rt	rt.c	/^enqueue_task_rt(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
enqueue_task_stop	stop_task.c	/^enqueue_task_stop(struct rq *rq, struct task_struct *p, int flags)$/;"	f	file:
enqueue_top_rt_rq	rt.c	/^enqueue_top_rt_rq(struct rt_rq *rt_rq)$/;"	f	file:
entity_before	fair.c	/^static inline int entity_before(struct sched_entity *a,$/;"	f	file:
entity_is_task	fair.c	259;"	d	file:
entity_is_task	fair.c	422;"	d	file:
entity_tick	fair.c	/^entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr, int queued)$/;"	f	file:
exec_clock	sched.h	/^	u64			exec_clock;$/;"	m	struct:cfs_rq
expire_cfs_rq_runtime	fair.c	/^static void expire_cfs_rq_runtime(struct cfs_rq *cfs_rq)$/;"	f	file:
expires_seq	sched.h	/^	int			expires_seq;$/;"	m	struct:cfs_bandwidth
expires_seq	sched.h	/^	int			expires_seq;$/;"	m	struct:cfs_rq
extra_bw	sched.h	/^	u64			extra_bw;$/;"	m	struct:dl_rq
fair_policy	sched.h	/^static inline int fair_policy(int policy)$/;"	f
fair_sched_class	fair.c	/^const struct sched_class fair_sched_class = {$/;"	v	typeref:struct:sched_class
fair_sched_class	fair.c	/^const struct sched_class fair_sched_class;$/;"	v	typeref:struct:sched_class
fake_sched_class	core.c	/^static const struct sched_class fake_sched_class = {$/;"	v	typeref:struct:sched_class	file:
fake_task	core.c	/^static struct task_struct fake_task = {$/;"	v	typeref:struct:task_struct	file:
fallback_doms	topology.c	/^static cpumask_var_t			fallback_doms;$/;"	v	file:
faults	fair.c	/^	unsigned long faults[0];$/;"	m	struct:numa_group	file:
faults_cpu	fair.c	/^	unsigned long *faults_cpu;$/;"	m	struct:numa_group	file:
fbq_classify_group	fair.c	/^static inline enum fbq_type fbq_classify_group(struct sg_lb_stats *sgs)$/;"	f	file:
fbq_classify_rq	fair.c	/^static inline enum fbq_type fbq_classify_rq(struct rq *rq)$/;"	f	file:
fbq_type	fair.c	/^	enum fbq_type		fbq_type;$/;"	m	struct:lb_env	typeref:enum:lb_env::fbq_type	file:
fbq_type	fair.c	/^enum fbq_type { regular, remote, all };$/;"	g	file:
fetch_or	core.c	340;"	d	file:
files	cpuacct.c	/^static struct cftype files[] = {$/;"	v	typeref:struct:cftype	file:
find_busiest_group	fair.c	/^static struct sched_group *find_busiest_group(struct lb_env *env)$/;"	f	file:
find_busiest_queue	fair.c	/^static struct rq *find_busiest_queue(struct lb_env *env,$/;"	f	file:
find_idlest_cpu	fair.c	/^static inline int find_idlest_cpu(struct sched_domain *sd, struct task_struct *p,$/;"	f	file:
find_idlest_group	fair.c	/^find_idlest_group(struct sched_domain *sd, struct task_struct *p,$/;"	f	file:
find_idlest_group_cpu	fair.c	/^find_idlest_group_cpu(struct sched_group *group, struct task_struct *p, int this_cpu)$/;"	f	file:
find_later_rq	deadline.c	/^static int find_later_rq(struct task_struct *task)$/;"	f	file:
find_lock_later_rq	deadline.c	/^static struct rq *find_lock_later_rq(struct task_struct *task, struct rq *rq)$/;"	f	file:
find_lock_lowest_rq	rt.c	/^static struct rq *find_lock_lowest_rq(struct task_struct *task, struct rq *rq)$/;"	f	file:
find_lowest_rq	rt.c	/^static int find_lowest_rq(struct task_struct *task)$/;"	f	file:
find_matching_se	fair.c	/^find_matching_se(struct sched_entity **se, struct sched_entity **pse)$/;"	f	file:
find_new_ilb	fair.c	/^static inline int find_new_ilb(void)$/;"	f	file:
find_numa_distance	topology.c	/^bool find_numa_distance(int distance)$/;"	f
find_process_by_pid	core.c	/^static struct task_struct *find_process_by_pid(pid_t pid)$/;"	f	file:
finish_arch_post_lock_switch	core.c	2617;"	d	file:
finish_lock_switch	core.c	/^static inline void finish_lock_switch(struct rq *rq)$/;"	f	file:
finish_swait	swait.c	/^EXPORT_SYMBOL(finish_swait);$/;"	v
finish_swait	swait.c	/^void finish_swait(struct swait_queue_head *q, struct swait_queue *wait)$/;"	f
finish_task	core.c	/^static inline void finish_task(struct task_struct *prev)$/;"	f	file:
finish_wait	wait.c	/^EXPORT_SYMBOL(finish_wait);$/;"	v
finish_wait	wait.c	/^void finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)$/;"	f
fire_sched_in_preempt_notifiers	core.c	/^static __always_inline void fire_sched_in_preempt_notifiers(struct task_struct *curr)$/;"	f	file:
fire_sched_in_preempt_notifiers	core.c	/^static inline void fire_sched_in_preempt_notifiers(struct task_struct *curr)$/;"	f	file:
fire_sched_out_preempt_notifiers	core.c	/^fire_sched_out_preempt_notifiers(struct task_struct *curr,$/;"	f	file:
fix_small_imbalance	fair.c	/^void fix_small_imbalance(struct lb_env *env, struct sd_lb_stats *sds)$/;"	f	file:
fixed_power_int	loadavg.c	/^fixed_power_int(unsigned long x, unsigned int frac_bits, unsigned int n)$/;"	f	file:
flags	fair.c	/^	unsigned int		flags;$/;"	m	struct:lb_env	file:
flags	sched.h	/^	unsigned long flags;$/;"	m	struct:rq_flags
for_each_class	sched.h	1557;"	d
for_each_domain	sched.h	1119;"	d
for_each_leaf_cfs_rq_safe	fair.c	359;"	d	file:
for_each_leaf_cfs_rq_safe	fair.c	454;"	d	file:
for_each_lower_domain	sched.h	1123;"	d
for_each_rt_rq	rt.c	467;"	d	file:
for_each_rt_rq	rt.c	574;"	d	file:
for_each_sched_entity	fair.c	268;"	d	file:
for_each_sched_entity	fair.c	424;"	d	file:
for_each_sched_rt_entity	rt.c	472;"	d	file:
for_each_sched_rt_entity	rt.c	577;"	d	file:
for_each_sd_topology	topology.c	1219;"	d	file:
force_schedstat_enabled	core.c	/^void force_schedstat_enabled(void)$/;"	f
free_cpus	cpudeadline.h	/^	cpumask_var_t		free_cpus;$/;"	m	struct:cpudl
free_fair_sched_group	fair.c	/^void free_fair_sched_group(struct task_group *tg) { }$/;"	f
free_fair_sched_group	fair.c	/^void free_fair_sched_group(struct task_group *tg)$/;"	f
free_rootdomain	topology.c	/^static void free_rootdomain(struct rcu_head *rcu)$/;"	f	file:
free_rt_sched_group	rt.c	/^void free_rt_sched_group(struct task_group *tg) { }$/;"	f
free_rt_sched_group	rt.c	/^void free_rt_sched_group(struct task_group *tg)$/;"	f
free_sched_domains	topology.c	/^void free_sched_domains(cpumask_var_t doms[], unsigned int ndoms)$/;"	f
free_sched_groups	topology.c	/^static void free_sched_groups(struct sched_group *sg, int free_sgc)$/;"	f	file:
freq_update_delay_ns	cpufreq_schedutil.c	/^	s64			freq_update_delay_ns;$/;"	m	struct:sugov_policy	file:
get_avenrun	loadavg.c	/^void get_avenrun(unsigned long *loads, unsigned long offset, int shift)$/;"	f
get_group	topology.c	/^static struct sched_group *get_group(int cpu, struct sd_data *sdd)$/;"	f	file:
get_iowait_load	core.c	/^void get_iowait_load(unsigned long *nr_waiters, unsigned long *load)$/;"	f
get_next_freq	cpufreq_schedutil.c	/^static unsigned int get_next_freq(struct sugov_policy *sg_policy,$/;"	f	file:
get_nohz_timer_target	core.c	/^int get_nohz_timer_target(void)$/;"	f
get_numa_group	fair.c	/^static inline int get_numa_group(struct numa_group *grp)$/;"	f	file:
get_preempt_disable_ip	core.c	/^static inline unsigned long get_preempt_disable_ip(struct task_struct *p)$/;"	f	file:
get_rr_interval	sched.h	/^	unsigned int (*get_rr_interval)(struct rq *rq,$/;"	m	struct:sched_class
get_rr_interval_fair	fair.c	/^static unsigned int get_rr_interval_fair(struct rq *rq, struct task_struct *task)$/;"	f	file:
get_rr_interval_idle	idle.c	/^static unsigned int get_rr_interval_idle(struct rq *rq, struct task_struct *task)$/;"	f	file:
get_rr_interval_rt	rt.c	/^static unsigned int get_rr_interval_rt(struct rq *rq, struct task_struct *task)$/;"	f	file:
get_rr_interval_stop	stop_task.c	/^get_rr_interval_stop(struct rq *rq, struct task_struct *task)$/;"	f	file:
get_sd_balance_interval	fair.c	/^get_sd_balance_interval(struct sched_domain *sd, int cpu_busy)$/;"	f	file:
get_sd_load_idx	fair.c	/^static inline int get_sd_load_idx(struct sched_domain *sd,$/;"	f	file:
get_update_sysctl_factor	fair.c	/^static unsigned int get_update_sysctl_factor(void)$/;"	f	file:
get_user_cpu_mask	core.c	/^static int get_user_cpu_mask(unsigned long __user *user_mask_ptr, unsigned len,$/;"	f	file:
get_vtime_delta	cputime.c	/^static u64 get_vtime_delta(struct vtime *vtime)$/;"	f	file:
gid	fair.c	/^	pid_t gid;$/;"	m	struct:numa_group	file:
global_rt_period	sched.h	/^static inline u64 global_rt_period(void)$/;"	f
global_rt_runtime	sched.h	/^static inline u64 global_rt_runtime(void)$/;"	f
global_tunables	cpufreq_schedutil.c	/^static struct sugov_tunables *global_tunables;$/;"	v	typeref:struct:sugov_tunables	file:
got_nohz_idle_kick	core.c	/^static inline bool got_nohz_idle_kick(void)$/;"	f	file:
group_balance_cpu	topology.c	/^int group_balance_cpu(struct sched_group *sg)$/;"	f
group_balance_mask	sched.h	/^static inline struct cpumask *group_balance_mask(struct sched_group *sg)$/;"	f
group_capacity	fair.c	/^	unsigned long group_capacity;$/;"	m	struct:sg_lb_stats	file:
group_cfs_rq	fair.c	/^static inline struct cfs_rq *group_cfs_rq(struct sched_entity *grp)$/;"	f	file:
group_classify	fair.c	/^group_type group_classify(struct sched_group *group,$/;"	f	file:
group_faults	fair.c	/^static inline unsigned long group_faults(struct task_struct *p, int nid)$/;"	f	file:
group_faults_cpu	fair.c	/^static inline unsigned long group_faults_cpu(struct numa_group *group, int nid)$/;"	f	file:
group_faults_priv	fair.c	/^static inline unsigned long group_faults_priv(struct numa_group *ng)$/;"	f	file:
group_faults_shared	fair.c	/^static inline unsigned long group_faults_shared(struct numa_group *ng)$/;"	f	file:
group_first_cpu	sched.h	/^static inline unsigned int group_first_cpu(struct sched_group *group)$/;"	f
group_has_capacity	fair.c	/^group_has_capacity(struct lb_env *env, struct sg_lb_stats *sgs)$/;"	f	file:
group_imbalanced	fair.c	/^	group_imbalanced,$/;"	e	enum:group_type	file:
group_is_overloaded	fair.c	/^group_is_overloaded(struct lb_env *env, struct sg_lb_stats *sgs)$/;"	f	file:
group_load	fair.c	/^	unsigned long group_load; \/* Total load over the CPUs of the group *\/$/;"	m	struct:sg_lb_stats	file:
group_no_capacity	fair.c	/^	int group_no_capacity;$/;"	m	struct:sg_lb_stats	file:
group_other	fair.c	/^	group_other = 0,$/;"	e	enum:group_type	file:
group_overloaded	fair.c	/^	group_overloaded,$/;"	e	enum:group_type	file:
group_path	debug.c	/^static char group_path[PATH_MAX];$/;"	v	file:
group_rt_rq	rt.c	/^static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)$/;"	f	file:
group_smaller_cpu_capacity	fair.c	/^group_smaller_cpu_capacity(struct sched_group *sg, struct sched_group *ref)$/;"	f	file:
group_type	fair.c	/^	enum group_type group_type;$/;"	m	struct:sg_lb_stats	typeref:enum:sg_lb_stats::group_type	file:
group_type	fair.c	/^enum group_type {$/;"	g	file:
group_util	fair.c	/^	unsigned long group_util; \/* Total utilization of the group *\/$/;"	m	struct:sg_lb_stats	file:
group_weight	fair.c	/^	unsigned int group_weight;$/;"	m	struct:sg_lb_stats	file:
group_weight	fair.c	/^static inline unsigned long group_weight(struct task_struct *p, int nid,$/;"	f	file:
group_weight	sched.h	/^	unsigned int		group_weight;$/;"	m	struct:sched_group
grub_reclaim	deadline.c	/^static u64 grub_reclaim(u64 delta, struct rq *rq, struct sched_dl_entity *dl_se)$/;"	f	file:
h_load	sched.h	/^	unsigned long		h_load;$/;"	m	struct:cfs_rq
h_load_next	sched.h	/^	struct sched_entity	*h_load_next;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::sched_entity
h_nr_running	sched.h	/^	unsigned int		h_nr_running;$/;"	m	struct:cfs_rq
has_blocked	fair.c	/^	int has_blocked;		\/* Idle CPUS has blocked load *\/$/;"	m	struct:__anon1	file:
has_blocked_load	sched.h	/^	unsigned int		has_blocked_load;$/;"	m	struct:rq
has_free_capacity	fair.c	/^	int has_free_capacity;$/;"	m	struct:numa_stats	file:
has_pushable_dl_tasks	deadline.c	/^static inline int has_pushable_dl_tasks(struct rq *rq)$/;"	f	file:
has_pushable_tasks	rt.c	/^static inline int has_pushable_tasks(struct rq *rq)$/;"	f	file:
hierarchical_quota	sched.h	/^	s64			hierarchical_quota;$/;"	m	struct:cfs_bandwidth
highest_flag_domain	sched.h	/^static inline struct sched_domain *highest_flag_domain(int cpu, int flag)$/;"	f
highest_prio	sched.h	/^	} highest_prio;$/;"	m	struct:rt_rq	typeref:struct:rt_rq::__anon3
housekeeping_affine	isolation.c	/^EXPORT_SYMBOL_GPL(housekeeping_affine);$/;"	v
housekeeping_affine	isolation.c	/^void housekeeping_affine(struct task_struct *t, enum hk_flags flags)$/;"	f
housekeeping_any_cpu	isolation.c	/^EXPORT_SYMBOL_GPL(housekeeping_any_cpu);$/;"	v
housekeeping_any_cpu	isolation.c	/^int housekeeping_any_cpu(enum hk_flags flags)$/;"	f
housekeeping_cpumask	isolation.c	/^EXPORT_SYMBOL_GPL(housekeeping_cpumask);$/;"	v
housekeeping_cpumask	isolation.c	/^const struct cpumask *housekeeping_cpumask(enum hk_flags flags)$/;"	f
housekeeping_flags	isolation.c	/^static unsigned int housekeeping_flags;$/;"	v	file:
housekeeping_init	isolation.c	/^void __init housekeeping_init(void)$/;"	f
housekeeping_isolcpus_setup	isolation.c	/^static int __init housekeeping_isolcpus_setup(char *str)$/;"	f	file:
housekeeping_mask	isolation.c	/^static cpumask_var_t housekeeping_mask;$/;"	v	file:
housekeeping_nohz_full_setup	isolation.c	/^static int __init housekeeping_nohz_full_setup(char *str)$/;"	f	file:
housekeeping_overriden	isolation.c	/^DEFINE_STATIC_KEY_FALSE(housekeeping_overriden);$/;"	v
housekeeping_overriden	isolation.c	/^EXPORT_SYMBOL_GPL(housekeeping_overriden);$/;"	v
housekeeping_setup	isolation.c	/^static int __init housekeeping_setup(char *str, enum hk_flags flags)$/;"	f	file:
housekeeping_test_cpu	isolation.c	/^EXPORT_SYMBOL_GPL(housekeeping_test_cpu);$/;"	v
housekeeping_test_cpu	isolation.c	/^bool housekeeping_test_cpu(int cpu, enum hk_flags flags)$/;"	f
hrtick	core.c	/^static enum hrtimer_restart hrtick(struct hrtimer *timer)$/;"	f	file:
hrtick_clear	core.c	/^static inline void hrtick_clear(struct rq *rq)$/;"	f	file:
hrtick_clear	core.c	/^static void hrtick_clear(struct rq *rq)$/;"	f	file:
hrtick_csd	sched.h	/^	call_single_data_t	hrtick_csd;$/;"	m	struct:rq
hrtick_csd_pending	sched.h	/^	int			hrtick_csd_pending;$/;"	m	struct:rq
hrtick_enabled	sched.h	/^static inline int hrtick_enabled(struct rq *rq)$/;"	f
hrtick_rq_init	core.c	/^static inline void hrtick_rq_init(struct rq *rq)$/;"	f	file:
hrtick_rq_init	core.c	/^static void hrtick_rq_init(struct rq *rq)$/;"	f	file:
hrtick_start	core.c	/^void hrtick_start(struct rq *rq, u64 delay)$/;"	f
hrtick_start_fair	fair.c	/^hrtick_start_fair(struct rq *rq, struct task_struct *p)$/;"	f	file:
hrtick_start_fair	fair.c	/^static void hrtick_start_fair(struct rq *rq, struct task_struct *p)$/;"	f	file:
hrtick_timer	sched.h	/^	struct hrtimer		hrtick_timer;$/;"	m	struct:rq	typeref:struct:rq::hrtimer
hrtick_update	fair.c	/^static inline void hrtick_update(struct rq *rq)$/;"	f	file:
hrtick_update	fair.c	/^static void hrtick_update(struct rq *rq)$/;"	f	file:
ia64_set_curr_task	core.c	/^void ia64_set_curr_task(int cpu, struct task_struct *p)$/;"	f
id	autogroup.h	/^	unsigned long		id;$/;"	m	struct:autogroup
id	sched.h	/^	int			id;$/;"	m	struct:sched_group_capacity
idle	fair.c	/^	enum cpu_idle_type	idle;$/;"	m	struct:lb_env	typeref:enum:lb_env::cpu_idle_type	file:
idle	sched.h	/^	short			idle;$/;"	m	struct:cfs_bandwidth
idle	sched.h	/^	struct task_struct	*idle;$/;"	m	struct:rq	typeref:struct:rq::task_struct
idle_balance	fair.c	/^static inline int idle_balance(struct rq *rq, struct rq_flags *rf)$/;"	f	file:
idle_balance	fair.c	/^static int idle_balance(struct rq *this_rq, struct rq_flags *rf)$/;"	f	file:
idle_balance	sched.h	/^	unsigned char		idle_balance;$/;"	m	struct:rq
idle_cpu	core.c	/^int idle_cpu(int cpu)$/;"	f
idle_cpus	fair.c	/^	unsigned int idle_cpus;$/;"	m	struct:sg_lb_stats	file:
idle_cpus_mask	fair.c	/^	cpumask_var_t idle_cpus_mask;$/;"	m	struct:__anon1	file:
idle_get_state	sched.h	/^static inline struct cpuidle_state *idle_get_state(struct rq *rq)$/;"	f
idle_inject_timer_fn	idle.c	/^static enum hrtimer_restart idle_inject_timer_fn(struct hrtimer *timer)$/;"	f	file:
idle_policy	sched.h	/^static inline int idle_policy(int policy)$/;"	f
idle_sched_class	idle.c	/^const struct sched_class idle_sched_class = {$/;"	v	typeref:struct:sched_class
idle_set_state	sched.h	/^static inline void idle_set_state(struct rq *rq,$/;"	f
idle_stamp	sched.h	/^	u64			idle_stamp;$/;"	m	struct:rq
idle_state	sched.h	/^	struct cpuidle_state	*idle_state;$/;"	m	struct:rq	typeref:struct:rq::cpuidle_state
idle_task	core.c	/^struct task_struct *idle_task(int cpu)$/;"	f
idle_task_exit	core.c	/^void idle_task_exit(void)$/;"	f
idle_timer	idle.c	/^struct idle_timer {$/;"	s	file:
idx	cpudeadline.h	/^	int			idx;$/;"	m	struct:cpudl_item
ignore_dl_rate_limit	cpufreq_schedutil.c	/^static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu, struct sugov_policy *sg_policy)$/;"	f	file:
imbalance	fair.c	/^	long			imbalance;$/;"	m	struct:lb_env	file:
imbalance	sched.h	/^	int			imbalance;		\/* XXX unrelated to capacity but shared group state *\/$/;"	m	struct:sched_group_capacity
imbalance_pct	fair.c	/^	int imbalance_pct;$/;"	m	struct:task_numa_env	file:
in_sched_functions	core.c	/^int in_sched_functions(unsigned long addr)$/;"	f
inactive_task_timer	deadline.c	/^static enum hrtimer_restart inactive_task_timer(struct hrtimer *timer)$/;"	f	file:
inc_dl_deadline	deadline.c	/^static inline void inc_dl_deadline(struct dl_rq *dl_rq, u64 deadline) {}$/;"	f	file:
inc_dl_deadline	deadline.c	/^static void inc_dl_deadline(struct dl_rq *dl_rq, u64 deadline)$/;"	f	file:
inc_dl_migration	deadline.c	/^static void inc_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
inc_dl_migration	deadline.c	/^void inc_dl_migration(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
inc_dl_tasks	deadline.c	/^void inc_dl_tasks(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
inc_rt_group	rt.c	/^inc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
inc_rt_migration	rt.c	/^static void inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
inc_rt_migration	rt.c	/^void inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
inc_rt_prio	rt.c	/^inc_rt_prio(struct rt_rq *rt_rq, int prio)$/;"	f	file:
inc_rt_prio	rt.c	/^static inline void inc_rt_prio(struct rt_rq *rt_rq, int prio) {}$/;"	f	file:
inc_rt_prio_smp	rt.c	/^inc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio)$/;"	f	file:
inc_rt_prio_smp	rt.c	/^void inc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}$/;"	f	file:
inc_rt_tasks	rt.c	/^void inc_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)$/;"	f	file:
init_cfs_bandwidth	fair.c	/^void init_cfs_bandwidth(struct cfs_bandwidth *cfs_b) {}$/;"	f
init_cfs_bandwidth	fair.c	/^void init_cfs_bandwidth(struct cfs_bandwidth *cfs_b)$/;"	f
init_cfs_rq	fair.c	/^void init_cfs_rq(struct cfs_rq *cfs_rq)$/;"	f
init_cfs_rq_runtime	fair.c	/^static void init_cfs_rq_runtime(struct cfs_rq *cfs_rq) {}$/;"	f	file:
init_cfs_rq_runtime	fair.c	/^static void init_cfs_rq_runtime(struct cfs_rq *cfs_rq)$/;"	f	file:
init_defrootdomain	topology.c	/^void init_defrootdomain(void)$/;"	f
init_dl_bandwidth	deadline.c	/^void init_dl_bandwidth(struct dl_bandwidth *dl_b, u64 period, u64 runtime)$/;"	f
init_dl_bw	deadline.c	/^void init_dl_bw(struct dl_bw *dl_b)$/;"	f
init_dl_inactive_task_timer	deadline.c	/^void init_dl_inactive_task_timer(struct sched_dl_entity *dl_se)$/;"	f
init_dl_rq	deadline.c	/^void init_dl_rq(struct dl_rq *dl_rq)$/;"	f
init_dl_rq_bw_ratio	deadline.c	/^void init_dl_rq_bw_ratio(struct dl_rq *dl_rq)$/;"	f
init_dl_task_timer	deadline.c	/^void init_dl_task_timer(struct sched_dl_entity *dl_se)$/;"	f
init_entity_runnable_average	fair.c	/^void init_entity_runnable_average(struct sched_entity *se)$/;"	f
init_idle	core.c	/^void init_idle(struct task_struct *idle, int cpu)$/;"	f
init_numa_balancing	fair.c	/^void init_numa_balancing(unsigned long clone_flags, struct task_struct *p)$/;"	f
init_numa_balancing	sched.h	/^init_numa_balancing(unsigned long clone_flags, struct task_struct *p)$/;"	f
init_numa_topology_type	topology.c	/^static void init_numa_topology_type(void)$/;"	f	file:
init_overlap_sched_group	topology.c	/^static void init_overlap_sched_group(struct sched_domain *sd,$/;"	f	file:
init_rootdomain	topology.c	/^static int init_rootdomain(struct root_domain *rd)$/;"	f	file:
init_rt_bandwidth	rt.c	/^void init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)$/;"	f
init_rt_rq	rt.c	/^void init_rt_rq(struct rt_rq *rt_rq)$/;"	f
init_sched_debug_procfs	debug.c	/^__initcall(init_sched_debug_procfs);$/;"	v
init_sched_debug_procfs	debug.c	/^static int __init init_sched_debug_procfs(void)$/;"	f	file:
init_sched_dl_class	deadline.c	/^void __init init_sched_dl_class(void)$/;"	f
init_sched_fair_class	fair.c	/^__init void init_sched_fair_class(void)$/;"	f
init_sched_groups_capacity	topology.c	/^static void init_sched_groups_capacity(int cpu, struct sched_domain *sd)$/;"	f	file:
init_sched_rt_class	rt.c	/^void __init init_sched_rt_class(void)$/;"	f
init_schedstats	core.c	/^static inline void init_schedstats(void) {}$/;"	f	file:
init_schedstats	core.c	/^static void __init init_schedstats(void)$/;"	f	file:
init_sd_lb_stats	fair.c	/^static inline void init_sd_lb_stats(struct sd_lb_stats *sds)$/;"	f	file:
init_tg_cfs_entry	fair.c	/^void init_tg_cfs_entry(struct task_group *tg, struct cfs_rq *cfs_rq,$/;"	f
init_tg_rt_entry	rt.c	/^void init_tg_rt_entry(struct task_group *tg, struct rt_rq *rt_rq,$/;"	f
init_wait_entry	wait.c	/^EXPORT_SYMBOL(init_wait_entry);$/;"	v
init_wait_entry	wait.c	/^void init_wait_entry(struct wait_queue_entry *wq_entry, int flags)$/;"	f
init_wait_var_entry	wait_bit.c	/^EXPORT_SYMBOL(init_wait_var_entry);$/;"	v
init_wait_var_entry	wait_bit.c	/^void init_wait_var_entry(struct wait_bit_queue_entry *wbq_entry, void *var, int flags)$/;"	f
io_schedule	core.c	/^EXPORT_SYMBOL(io_schedule);$/;"	v
io_schedule	core.c	/^void io_schedule(void)$/;"	f
io_schedule_finish	core.c	/^void io_schedule_finish(int token)$/;"	f
io_schedule_prepare	core.c	/^int io_schedule_prepare(void)$/;"	f
io_schedule_timeout	core.c	/^EXPORT_SYMBOL(io_schedule_timeout);$/;"	v
io_schedule_timeout	core.c	/^long __sched io_schedule_timeout(long timeout)$/;"	f
iowait_boost	cpufreq_schedutil.c	/^	unsigned int		iowait_boost;$/;"	m	struct:sugov_cpu	file:
iowait_boost_max	cpufreq_schedutil.c	/^	unsigned int		iowait_boost_max;$/;"	m	struct:sugov_cpu	file:
iowait_boost_pending	cpufreq_schedutil.c	/^	bool			iowait_boost_pending;$/;"	m	struct:sugov_cpu	file:
ipi_mb	membarrier.c	/^static void ipi_mb(void *info)$/;"	f	file:
irq_start_time	sched.h	/^	u64			irq_start_time;$/;"	m	struct:irqtime
irq_time_read	sched.h	/^static inline u64 irq_time_read(int cpu)$/;"	f
irq_work	cpufreq_schedutil.c	/^	struct			irq_work irq_work;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::irq_work	file:
irqtime	sched.h	/^struct irqtime {$/;"	s
irqtime_account_delta	cputime.c	/^static void irqtime_account_delta(struct irqtime *irqtime, u64 delta,$/;"	f	file:
irqtime_account_idle_ticks	cputime.c	/^static inline void irqtime_account_idle_ticks(int ticks) { }$/;"	f	file:
irqtime_account_idle_ticks	cputime.c	/^static void irqtime_account_idle_ticks(int ticks)$/;"	f	file:
irqtime_account_irq	cputime.c	/^EXPORT_SYMBOL_GPL(irqtime_account_irq);$/;"	v
irqtime_account_irq	cputime.c	/^void irqtime_account_irq(struct task_struct *curr)$/;"	f
irqtime_account_process_tick	cputime.c	/^static inline void irqtime_account_process_tick(struct task_struct *p, int user_tick,$/;"	f	file:
irqtime_account_process_tick	cputime.c	/^static void irqtime_account_process_tick(struct task_struct *p, int user_tick,$/;"	f	file:
irqtime_tick_accounted	cputime.c	/^static u64 irqtime_tick_accounted(u64 dummy)$/;"	f	file:
irqtime_tick_accounted	cputime.c	/^static u64 irqtime_tick_accounted(u64 maxtime)$/;"	f	file:
is_cpu_allowed	core.c	/^static inline bool is_cpu_allowed(struct task_struct *p, int cpu)$/;"	f	file:
is_kthread_should_stop	wait.c	/^static inline bool is_kthread_should_stop(void)$/;"	f	file:
is_leftmost	deadline.c	/^static inline int is_leftmost(struct task_struct *p, struct dl_rq *dl_rq)$/;"	f	file:
is_per_cpu_kthread	core.c	/^static inline bool is_per_cpu_kthread(struct task_struct *p)$/;"	f	file:
is_same_group	fair.c	/^is_same_group(struct sched_entity *se, struct sched_entity *pse)$/;"	f	file:
jump_label_key__false	debug.c	79;"	d	file:
jump_label_key__true	debug.c	78;"	d	file:
kernel_cpustat	core.c	/^EXPORT_PER_CPU_SYMBOL(kernel_cpustat);$/;"	v
kick_ilb	fair.c	/^static void kick_ilb(unsigned int flags)$/;"	f	file:
kick_process	core.c	/^EXPORT_SYMBOL_GPL(kick_process);$/;"	v
kick_process	core.c	/^void kick_process(struct task_struct *p)$/;"	f
kref	autogroup.h	/^	struct kref		kref;$/;"	m	struct:autogroup	typeref:struct:autogroup::kref
kstat	core.c	/^EXPORT_PER_CPU_SYMBOL(kstat);$/;"	v
last	sched.h	/^	struct sched_entity	*last;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::sched_entity
last_blocked_load_update_tick	sched.h	/^	unsigned long		last_blocked_load_update_tick;$/;"	m	struct:rq
last_freq_update_time	cpufreq_schedutil.c	/^	u64			last_freq_update_time;$/;"	m	struct:sugov_policy	file:
last_h_load_update	sched.h	/^	u64			last_h_load_update;$/;"	m	struct:cfs_rq
last_load_update_tick	sched.h	/^	unsigned long		last_load_update_tick;$/;"	m	struct:rq
last_update	cpufreq_schedutil.c	/^	u64			last_update;$/;"	m	struct:sugov_cpu	file:
lb_env	fair.c	/^struct lb_env {$/;"	s	file:
leaf_cfs_rq_list	sched.h	/^	struct list_head	leaf_cfs_rq_list;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::list_head
leaf_cfs_rq_list	sched.h	/^	struct list_head	leaf_cfs_rq_list;$/;"	m	struct:rq	typeref:struct:rq::list_head
left_child	cpudeadline.c	/^static inline int left_child(int i)$/;"	f	file:
list	sched.h	/^	struct list_head	list;$/;"	m	struct:task_group	typeref:struct:task_group::list_head
list_add_leaf_cfs_rq	fair.c	/^static inline void list_add_leaf_cfs_rq(struct cfs_rq *cfs_rq)$/;"	f	file:
list_del_leaf_cfs_rq	fair.c	/^static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)$/;"	f	file:
load	fair.c	/^	unsigned long load;$/;"	m	struct:numa_stats	file:
load	sched.h	/^	struct load_weight	load;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::load_weight
load	sched.h	/^	struct load_weight	load;$/;"	m	struct:rq	typeref:struct:rq::load_weight
load_avg	sched.h	/^		unsigned long	load_avg;$/;"	m	struct:cfs_rq::__anon2
load_balance	fair.c	/^static int load_balance(int this_cpu, struct rq *this_rq,$/;"	f	file:
load_last_update_time_copy	sched.h	/^	u64			load_last_update_time_copy;$/;"	m	struct:cfs_rq
load_per_task	fair.c	/^	unsigned long load_per_task;$/;"	m	struct:sg_lb_stats	file:
load_too_imbalanced	fair.c	/^static bool load_too_imbalanced(long src_load, long dst_load,$/;"	f	file:
local	fair.c	/^	struct sched_group *local;	\/* Local group in this sd *\/$/;"	m	struct:sd_lb_stats	typeref:struct:sd_lb_stats::sched_group	file:
local_stat	fair.c	/^	struct sg_lb_stats local_stat;	\/* Statistics of the local group *\/$/;"	m	struct:sd_lb_stats	typeref:struct:sd_lb_stats::sg_lb_stats	file:
lock	autogroup.h	/^	struct rw_semaphore	lock;$/;"	m	struct:autogroup	typeref:struct:autogroup::rw_semaphore
lock	cpudeadline.h	/^	raw_spinlock_t		lock;$/;"	m	struct:cpudl
lock	fair.c	/^	spinlock_t lock; \/* nr_tasks, tasks *\/$/;"	m	struct:numa_group	file:
lock	sched.h	/^	raw_spinlock_t		lock;$/;"	m	struct:cfs_bandwidth
lock	sched.h	/^	raw_spinlock_t		lock;$/;"	m	struct:dl_bw
lock	sched.h	/^	raw_spinlock_t		lock;$/;"	m	struct:rq
loop	fair.c	/^	unsigned int		loop;$/;"	m	struct:lb_env	file:
loop_break	fair.c	/^	unsigned int		loop_break;$/;"	m	struct:lb_env	file:
loop_max	fair.c	/^	unsigned int		loop_max;$/;"	m	struct:lb_env	file:
lowest_flag_domain	sched.h	/^static inline struct sched_domain *lowest_flag_domain(int cpu, int flag)$/;"	f
mask	cpupri.h	/^	cpumask_var_t		mask;$/;"	m	struct:cpupri_vec
max	cpufreq_schedutil.c	/^	unsigned long		max;$/;"	m	struct:sugov_cpu	file:
max_cfs_quota_period	core.c	/^const u64 max_cfs_quota_period = 1 * NSEC_PER_SEC; \/* 1s *\/$/;"	v
max_cpu_capacity	sched.h	/^	unsigned long		max_cpu_capacity;$/;"	m	struct:root_domain
max_faults_cpu	fair.c	/^	unsigned long max_faults_cpu;$/;"	m	struct:numa_group	file:
max_idle_balance_cost	sched.h	/^	u64			max_idle_balance_cost;$/;"	m	struct:rq
max_load_balance_interval	fair.c	/^static unsigned long __read_mostly max_load_balance_interval = HZ\/10;$/;"	v	file:
max_load_idx	debug.c	/^static int max_load_idx = CPU_LOAD_IDX_MAX-1;$/;"	v	file:
max_vruntime	fair.c	/^static inline u64 max_vruntime(u64 max_vruntime, u64 vruntime)$/;"	f	file:
membarrier_global_expedited	membarrier.c	/^static int membarrier_global_expedited(void)$/;"	f	file:
membarrier_private_expedited	membarrier.c	/^static int membarrier_private_expedited(int flags)$/;"	f	file:
membarrier_register_global_expedited	membarrier.c	/^static int membarrier_register_global_expedited(void)$/;"	f	file:
membarrier_register_private_expedited	membarrier.c	/^static int membarrier_register_private_expedited(int flags)$/;"	f	file:
migrate_degrades_locality	fair.c	/^static inline int migrate_degrades_locality(struct task_struct *p,$/;"	f	file:
migrate_degrades_locality	fair.c	/^static int migrate_degrades_locality(struct task_struct *p, struct lb_env *env)$/;"	f	file:
migrate_swap	core.c	/^int migrate_swap(struct task_struct *cur, struct task_struct *p)$/;"	f
migrate_swap_stop	core.c	/^static int migrate_swap_stop(void *data)$/;"	f	file:
migrate_task_rq	sched.h	/^	void (*migrate_task_rq)(struct task_struct *p);$/;"	m	struct:sched_class
migrate_task_rq_dl	deadline.c	/^static void migrate_task_rq_dl(struct task_struct *p)$/;"	f	file:
migrate_task_rq_fair	fair.c	/^static void migrate_task_rq_fair(struct task_struct *p)$/;"	f	file:
migrate_task_to	core.c	/^int migrate_task_to(struct task_struct *p, int target_cpu)$/;"	f
migrate_tasks	core.c	/^static void migrate_tasks(struct rq *dead_rq, struct rq_flags *rf)$/;"	f	file:
migration_arg	core.c	/^struct migration_arg {$/;"	s	file:
migration_cpu_stop	core.c	/^static int migration_cpu_stop(void *data)$/;"	f	file:
migration_init	core.c	/^early_initcall(migration_init);$/;"	v
migration_init	core.c	/^static int __init migration_init(void)$/;"	f	file:
migration_swap_arg	core.c	/^struct migration_swap_arg {$/;"	s	file:
min_bandwidth_expiration	fair.c	/^static const u64 min_bandwidth_expiration = 2 * NSEC_PER_MSEC;$/;"	v	file:
min_capacity	sched.h	/^	unsigned long		min_capacity;		\/* Min per-CPU capacity in group *\/$/;"	m	struct:sched_group_capacity
min_cfs_quota_period	core.c	/^const u64 min_cfs_quota_period = 1 * NSEC_PER_MSEC; \/* 1ms *\/$/;"	v
min_cfs_rq_runtime	fair.c	/^static const u64 min_cfs_rq_runtime = 1 * NSEC_PER_MSEC;$/;"	v	file:
min_load_idx	debug.c	/^static int min_load_idx = 0;$/;"	v	file:
min_vruntime	fair.c	/^static inline u64 min_vruntime(u64 min_vruntime, u64 vruntime)$/;"	f	file:
min_vruntime	sched.h	/^	u64			min_vruntime;$/;"	m	struct:cfs_rq
min_vruntime_copy	sched.h	/^	u64			min_vruntime_copy;$/;"	m	struct:cfs_rq
move_entity	rt.c	/^static inline bool move_entity(unsigned int flags)$/;"	f	file:
move_queued_task	core.c	/^static struct rq *move_queued_task(struct rq *rq, struct rq_flags *rf,$/;"	f	file:
ndoms_cur	topology.c	/^static int				ndoms_cur;$/;"	v	file:
need_active_balance	fair.c	/^static int need_active_balance(struct lb_env *env)$/;"	f	file:
need_freq_update	cpufreq_schedutil.c	/^	bool			need_freq_update;$/;"	m	struct:sugov_policy	file:
need_pull_dl_task	deadline.c	/^static inline bool need_pull_dl_task(struct rq *rq, struct task_struct *prev)$/;"	f	file:
need_pull_rt_task	rt.c	/^static inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)$/;"	f	file:
new_dst_cpu	fair.c	/^	int			new_dst_cpu;$/;"	m	struct:lb_env	file:
next	sched.h	/^		int		next; \/* next highest *\/$/;"	m	struct:rt_rq::__anon3
next	sched.h	/^		u64		next;$/;"	m	struct:dl_rq::__anon4
next	sched.h	/^	const struct sched_class *next;$/;"	m	struct:sched_class	typeref:struct:sched_class::sched_class
next	sched.h	/^	struct sched_entity	*next;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::sched_entity
next	sched.h	/^	struct sched_group	*next;			\/* Must be a circular list *\/$/;"	m	struct:sched_group	typeref:struct:sched_group::sched_group
next_balance	fair.c	/^	unsigned long next_balance;     \/* in jiffy units *\/$/;"	m	struct:__anon1	file:
next_balance	sched.h	/^	unsigned long		next_balance;$/;"	m	struct:rq
next_blocked	fair.c	/^	unsigned long next_blocked;	\/* Next update of blocked load in jiffies *\/$/;"	m	struct:__anon1	file:
next_freq	cpufreq_schedutil.c	/^	unsigned int		next_freq;$/;"	m	struct:sugov_policy	file:
next_task_group	rt.c	/^static inline struct task_group *next_task_group(struct task_group *tg)$/;"	f	file:
next_update	sched.h	/^	unsigned long		next_update;$/;"	m	struct:sched_group_capacity
nice	autogroup.h	/^	int			nice;$/;"	m	struct:autogroup
nohz_balance_enter_idle	fair.c	/^void nohz_balance_enter_idle(int cpu)$/;"	f
nohz_balance_exit_idle	fair.c	/^void nohz_balance_exit_idle(struct rq *rq)$/;"	f
nohz_balance_exit_idle	sched.h	/^static inline void nohz_balance_exit_idle(struct rq *rq) { }$/;"	f
nohz_balancer_kick	fair.c	/^static inline void nohz_balancer_kick(struct rq *rq) { }$/;"	f	file:
nohz_balancer_kick	fair.c	/^static void nohz_balancer_kick(struct rq *rq)$/;"	f	file:
nohz_flags	sched.h	/^	atomic_t nohz_flags;$/;"	m	struct:rq
nohz_flags	sched.h	2071;"	d
nohz_idle_balance	fair.c	/^static bool nohz_idle_balance(struct rq *this_rq, enum cpu_idle_type idle)$/;"	f	file:
nohz_idle_balance	fair.c	/^static inline bool nohz_idle_balance(struct rq *this_rq, enum cpu_idle_type idle)$/;"	f	file:
nohz_newidle_balance	fair.c	/^static inline void nohz_newidle_balance(struct rq *this_rq) { }$/;"	f	file:
nohz_newidle_balance	fair.c	/^static void nohz_newidle_balance(struct rq *this_rq)$/;"	f	file:
nohz_tick_stopped	sched.h	/^	unsigned int		nohz_tick_stopped;$/;"	m	struct:rq
normal_prio	core.c	/^static inline int normal_prio(struct task_struct *p)$/;"	f	file:
normalize_cfs_quota	core.c	/^static u64 normalize_cfs_quota(struct task_group *tg,$/;"	f	file:
normalize_rt_tasks	core.c	/^void normalize_rt_tasks(void)$/;"	f
normalized_sysctl_sched_latency	fair.c	/^unsigned int normalized_sysctl_sched_latency		= 6000000ULL;$/;"	v
normalized_sysctl_sched_min_granularity	fair.c	/^unsigned int normalized_sysctl_sched_min_granularity	= 750000ULL;$/;"	v
normalized_sysctl_sched_wakeup_granularity	fair.c	/^unsigned int normalized_sysctl_sched_wakeup_granularity	= 1000000UL;$/;"	v
nr	sched.h	/^		int		nr;$/;"	m	struct:cfs_rq::__anon2
nr_context_switches	core.c	/^unsigned long long nr_context_switches(void)$/;"	f
nr_cpus	fair.c	/^	atomic_t nr_cpus;$/;"	m	struct:__anon1	file:
nr_iowait	core.c	/^unsigned long nr_iowait(void)$/;"	f
nr_iowait	sched.h	/^	atomic_t		nr_iowait;$/;"	m	struct:rq
nr_iowait_cpu	core.c	/^unsigned long nr_iowait_cpu(int cpu)$/;"	f
nr_load_updates	sched.h	/^	unsigned long		nr_load_updates;$/;"	m	struct:rq
nr_numa_running	fair.c	/^	unsigned int nr_numa_running;$/;"	m	struct:sg_lb_stats	file:
nr_numa_running	sched.h	/^	unsigned int		nr_numa_running;$/;"	m	struct:rq
nr_periods	sched.h	/^	int			nr_periods;$/;"	m	struct:cfs_bandwidth
nr_preferred_running	fair.c	/^	unsigned int nr_preferred_running;$/;"	m	struct:sg_lb_stats	file:
nr_preferred_running	sched.h	/^	unsigned int		nr_preferred_running;$/;"	m	struct:rq
nr_running	core.c	/^unsigned long nr_running(void)$/;"	f
nr_running	fair.c	/^	unsigned long nr_running;$/;"	m	struct:numa_stats	file:
nr_running	sched.h	/^	unsigned int		nr_running;$/;"	m	struct:cfs_rq
nr_running	sched.h	/^	unsigned int		nr_running;$/;"	m	struct:rq
nr_spread_over	sched.h	/^	unsigned int		nr_spread_over;$/;"	m	struct:cfs_rq
nr_switches	sched.h	/^	u64			nr_switches;$/;"	m	struct:rq
nr_tasks	fair.c	/^	int nr_tasks;$/;"	m	struct:numa_group	file:
nr_throttled	sched.h	/^	int			nr_throttled;$/;"	m	struct:cfs_bandwidth
nr_uninterruptible	sched.h	/^	unsigned long		nr_uninterruptible;$/;"	m	struct:rq
nsec_high	debug.c	/^static long long nsec_high(unsigned long long nsec)$/;"	f	file:
nsec_low	debug.c	/^static unsigned long nsec_low(unsigned long long nsec)$/;"	f	file:
num_cpus_frozen	core.c	/^static int num_cpus_frozen;$/;"	v	file:
numa_faults_stats	sched.h	/^enum numa_faults_stats {$/;"	g
numa_get_avg_runtime	fair.c	/^static u64 numa_get_avg_runtime(struct task_struct *p, u64 *period)$/;"	f	file:
numa_group	fair.c	/^struct numa_group {$/;"	s	file:
numa_group_count_active_nodes	fair.c	/^static void numa_group_count_active_nodes(struct numa_group *numa_group)$/;"	f	file:
numa_has_capacity	fair.c	/^static bool numa_has_capacity(struct task_numa_env *env)$/;"	f	file:
numa_is_active_node	fair.c	/^static bool numa_is_active_node(int nid, struct numa_group *ng)$/;"	f	file:
numa_migrate_preferred	fair.c	/^static void numa_migrate_preferred(struct task_struct *p)$/;"	f	file:
numa_stats	fair.c	/^struct numa_stats {$/;"	s	file:
numa_topology_type	sched.h	/^enum numa_topology_type {$/;"	g
on_dl_rq	deadline.c	/^static inline int on_dl_rq(struct sched_dl_entity *dl_se)$/;"	f	file:
on_list	sched.h	/^	int			on_list;$/;"	m	struct:cfs_rq
on_null_domain	fair.c	/^static inline int on_null_domain(struct rq *rq)$/;"	f	file:
on_rt_rq	rt.c	/^static inline int on_rt_rq(struct sched_rt_entity *rt_se)$/;"	f	file:
online	sched.h	/^	cpumask_var_t		online;$/;"	m	struct:root_domain
online	sched.h	/^	int			online;$/;"	m	struct:rq
online_fair_sched_group	fair.c	/^void online_fair_sched_group(struct task_group *tg) { }$/;"	f
online_fair_sched_group	fair.c	/^void online_fair_sched_group(struct task_group *tg)$/;"	f
out_of_line_wait_on_bit	wait_bit.c	/^EXPORT_SYMBOL(out_of_line_wait_on_bit);$/;"	v
out_of_line_wait_on_bit	wait_bit.c	/^int __sched out_of_line_wait_on_bit(void *word, int bit,$/;"	f
out_of_line_wait_on_bit_lock	wait_bit.c	/^EXPORT_SYMBOL(out_of_line_wait_on_bit_lock);$/;"	v
out_of_line_wait_on_bit_lock	wait_bit.c	/^int __sched out_of_line_wait_on_bit_lock(void *word, int bit,$/;"	f
out_of_line_wait_on_bit_timeout	wait_bit.c	/^EXPORT_SYMBOL_GPL(out_of_line_wait_on_bit_timeout);$/;"	v
out_of_line_wait_on_bit_timeout	wait_bit.c	/^int __sched out_of_line_wait_on_bit_timeout($/;"	f
overloaded	sched.h	/^	int			overloaded;$/;"	m	struct:dl_rq
overloaded	sched.h	/^	int			overloaded;$/;"	m	struct:rt_rq
p	fair.c	/^	struct task_struct *p;$/;"	m	struct:task_numa_env	typeref:struct:task_numa_env::task_struct	file:
parent	cpudeadline.c	/^static inline int parent(int i)$/;"	f	file:
parent	sched.h	/^	struct task_group	*parent;$/;"	m	struct:task_group	typeref:struct:task_group::task_group
parent_ca	cpuacct.c	/^static inline struct cpuacct *parent_ca(struct cpuacct *ca)$/;"	f	file:
parent_entity	fair.c	/^static inline struct sched_entity *parent_entity(struct sched_entity *se)$/;"	f	file:
partition_sched_domains	topology.c	/^void partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],$/;"	f
period	core.c	/^	u64 period, quota;$/;"	m	struct:cfs_schedulable_data	file:
period	sched.h	/^	ktime_t			period;$/;"	m	struct:cfs_bandwidth
period_active	sched.h	/^	short			period_active;$/;"	m	struct:cfs_bandwidth
period_timer	sched.h	/^	struct hrtimer		period_timer;$/;"	m	struct:cfs_bandwidth	typeref:struct:cfs_bandwidth::hrtimer
pick_dl_task	deadline.c	/^static int pick_dl_task(struct rq *rq, struct task_struct *p, int cpu)$/;"	f	file:
pick_earliest_pushable_dl_task	deadline.c	/^static struct task_struct *pick_earliest_pushable_dl_task(struct rq *rq, int cpu)$/;"	f	file:
pick_highest_pushable_task	rt.c	/^static struct task_struct *pick_highest_pushable_task(struct rq *rq, int cpu)$/;"	f	file:
pick_next_dl_entity	deadline.c	/^static struct sched_dl_entity *pick_next_dl_entity(struct rq *rq,$/;"	f	file:
pick_next_entity	fair.c	/^pick_next_entity(struct cfs_rq *cfs_rq, struct sched_entity *curr)$/;"	f	file:
pick_next_pushable_dl_task	deadline.c	/^static struct task_struct *pick_next_pushable_dl_task(struct rq *rq)$/;"	f	file:
pick_next_pushable_task	rt.c	/^static struct task_struct *pick_next_pushable_task(struct rq *rq)$/;"	f	file:
pick_next_rt_entity	rt.c	/^static struct sched_rt_entity *pick_next_rt_entity(struct rq *rq,$/;"	f	file:
pick_next_task	core.c	/^pick_next_task(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)$/;"	f	file:
pick_next_task	sched.h	/^	struct task_struct * (*pick_next_task)(struct rq *rq,$/;"	m	struct:sched_class	typeref:struct:sched_class::pick_next_task
pick_next_task_dl	deadline.c	/^pick_next_task_dl(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)$/;"	f	file:
pick_next_task_fair	fair.c	/^pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)$/;"	f	file:
pick_next_task_idle	idle.c	/^pick_next_task_idle(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)$/;"	f	file:
pick_next_task_rt	rt.c	/^pick_next_task_rt(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)$/;"	f	file:
pick_next_task_stop	stop_task.c	/^pick_next_task_stop(struct rq *rq, struct task_struct *prev, struct rq_flags *rf)$/;"	f	file:
pick_rt_task	rt.c	/^static int pick_rt_task(struct rq *rq, struct task_struct *p, int cpu)$/;"	f	file:
place_entity	fair.c	/^place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial)$/;"	f	file:
play_idle	idle.c	/^EXPORT_SYMBOL_GPL(play_idle);$/;"	v
play_idle	idle.c	/^void play_idle(unsigned long duration_ms)$/;"	f
policy	cpufreq_schedutil.c	/^	struct cpufreq_policy	*policy;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::cpufreq_policy	file:
post_init_entity_util_avg	fair.c	/^void post_init_entity_util_avg(struct sched_entity *se)$/;"	f
pr_fmt	cpufreq_schedutil.c	12;"	d	file:
preempt_count_add	core.c	/^EXPORT_SYMBOL(preempt_count_add);$/;"	v
preempt_count_add	core.c	/^NOKPROBE_SYMBOL(preempt_count_add);$/;"	v
preempt_count_add	core.c	/^void preempt_count_add(int val)$/;"	f
preempt_count_equals	core.c	/^static inline int preempt_count_equals(int preempt_offset)$/;"	f	file:
preempt_count_sub	core.c	/^EXPORT_SYMBOL(preempt_count_sub);$/;"	v
preempt_count_sub	core.c	/^NOKPROBE_SYMBOL(preempt_count_sub);$/;"	v
preempt_count_sub	core.c	/^void preempt_count_sub(int val)$/;"	f
preempt_latency_start	core.c	/^static inline void preempt_latency_start(int val) { }$/;"	f	file:
preempt_latency_start	core.c	/^static inline void preempt_latency_start(int val)$/;"	f	file:
preempt_latency_stop	core.c	/^static inline void preempt_latency_stop(int val) { }$/;"	f	file:
preempt_latency_stop	core.c	/^static inline void preempt_latency_stop(int val)$/;"	f	file:
preempt_notifier_dec	core.c	/^EXPORT_SYMBOL_GPL(preempt_notifier_dec);$/;"	v
preempt_notifier_dec	core.c	/^void preempt_notifier_dec(void)$/;"	f
preempt_notifier_inc	core.c	/^EXPORT_SYMBOL_GPL(preempt_notifier_inc);$/;"	v
preempt_notifier_inc	core.c	/^void preempt_notifier_inc(void)$/;"	f
preempt_notifier_register	core.c	/^EXPORT_SYMBOL_GPL(preempt_notifier_register);$/;"	v
preempt_notifier_register	core.c	/^void preempt_notifier_register(struct preempt_notifier *notifier)$/;"	f
preempt_notifier_unregister	core.c	/^EXPORT_SYMBOL_GPL(preempt_notifier_unregister);$/;"	v
preempt_notifier_unregister	core.c	/^void preempt_notifier_unregister(struct preempt_notifier *notifier)$/;"	f
preempt_schedule	core.c	/^EXPORT_SYMBOL(preempt_schedule);$/;"	v
preempt_schedule	core.c	/^NOKPROBE_SYMBOL(preempt_schedule);$/;"	v
preempt_schedule	core.c	/^asmlinkage __visible void __sched notrace preempt_schedule(void)$/;"	f
preempt_schedule_common	core.c	/^static void __sched notrace preempt_schedule_common(void)$/;"	f	file:
preempt_schedule_irq	core.c	/^asmlinkage __visible void __sched preempt_schedule_irq(void)$/;"	f
preempt_schedule_notrace	core.c	/^EXPORT_SYMBOL_GPL(preempt_schedule_notrace);$/;"	v
preempt_schedule_notrace	core.c	/^asmlinkage __visible void __sched notrace preempt_schedule_notrace(void)$/;"	f
preferred_group_nid	fair.c	/^static int preferred_group_nid(struct task_struct *p, int nid)$/;"	f	file:
prefetch_curr_exec_start	core.c	/^static inline void prefetch_curr_exec_start(struct task_struct *p)$/;"	f	file:
prepare_arch_switch	core.c	2613;"	d	file:
prepare_lock_switch	core.c	/^prepare_lock_switch(struct rq *rq, struct task_struct *next, struct rq_flags *rf)$/;"	f	file:
prepare_task	core.c	/^static inline void prepare_task(struct task_struct *next)$/;"	f	file:
prepare_task_switch	core.c	/^prepare_task_switch(struct rq *rq, struct task_struct *prev,$/;"	f	file:
prepare_to_swait	swait.c	/^EXPORT_SYMBOL(prepare_to_swait);$/;"	v
prepare_to_swait	swait.c	/^void prepare_to_swait(struct swait_queue_head *q, struct swait_queue *wait, int state)$/;"	f
prepare_to_swait_event	swait.c	/^EXPORT_SYMBOL(prepare_to_swait_event);$/;"	v
prepare_to_swait_event	swait.c	/^long prepare_to_swait_event(struct swait_queue_head *q, struct swait_queue *wait, int state)$/;"	f
prepare_to_wait	wait.c	/^EXPORT_SYMBOL(prepare_to_wait);$/;"	v
prepare_to_wait	wait.c	/^prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)$/;"	f
prepare_to_wait_event	wait.c	/^EXPORT_SYMBOL(prepare_to_wait_event);$/;"	v
prepare_to_wait_event	wait.c	/^long prepare_to_wait_event(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)$/;"	f
prepare_to_wait_exclusive	wait.c	/^EXPORT_SYMBOL(prepare_to_wait_exclusive);$/;"	v
prepare_to_wait_exclusive	wait.c	/^prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)$/;"	f
prev_irq_time	sched.h	/^	u64			prev_irq_time;$/;"	m	struct:rq
prev_mm	sched.h	/^	struct mm_struct	*prev_mm;$/;"	m	struct:rq	typeref:struct:rq::mm_struct
prev_steal_time	sched.h	/^	u64			prev_steal_time;$/;"	m	struct:rq
prev_steal_time_rq	sched.h	/^	u64			prev_steal_time_rq;$/;"	m	struct:rq
pri_to_cpu	cpupri.h	/^	struct cpupri_vec	pri_to_cpu[CPUPRI_NR_PRIORITIES];$/;"	m	struct:cpupri	typeref:struct:cpupri::cpupri_vec
print_cfs_group_stats	debug.c	/^static void print_cfs_group_stats(struct seq_file *m, int cpu, struct task_group *tg)$/;"	f	file:
print_cfs_rq	debug.c	/^void print_cfs_rq(struct seq_file *m, int cpu, struct cfs_rq *cfs_rq)$/;"	f
print_cfs_stats	fair.c	/^void print_cfs_stats(struct seq_file *m, int cpu)$/;"	f
print_cpu	debug.c	/^static void print_cpu(struct seq_file *m, int cpu)$/;"	f	file:
print_dl_rq	debug.c	/^void print_dl_rq(struct seq_file *m, int cpu, struct dl_rq *dl_rq)$/;"	f
print_dl_stats	deadline.c	/^void print_dl_stats(struct seq_file *m, int cpu)$/;"	f
print_numa_stats	debug.c	/^void print_numa_stats(struct seq_file *m, int node, unsigned long tsf,$/;"	f
print_rq	debug.c	/^static void print_rq(struct seq_file *m, struct rq *rq, int rq_cpu)$/;"	f	file:
print_rt_rq	debug.c	/^void print_rt_rq(struct seq_file *m, int cpu, struct rt_rq *rt_rq)$/;"	f
print_rt_stats	rt.c	/^void print_rt_stats(struct seq_file *m, int cpu)$/;"	f
print_task	debug.c	/^print_task(struct seq_file *m, struct rq *rq, struct task_struct *p)$/;"	f	file:
prio_changed	sched.h	/^	void (*prio_changed) (struct rq *this_rq, struct task_struct *task,$/;"	m	struct:sched_class
prio_changed_dl	deadline.c	/^static void prio_changed_dl(struct rq *rq, struct task_struct *p,$/;"	f	file:
prio_changed_fair	fair.c	/^prio_changed_fair(struct rq *rq, struct task_struct *p, int oldprio)$/;"	f	file:
prio_changed_idle	idle.c	/^prio_changed_idle(struct rq *rq, struct task_struct *p, int oldprio)$/;"	f	file:
prio_changed_rt	rt.c	/^prio_changed_rt(struct rq *rq, struct task_struct *p, int oldprio)$/;"	f	file:
prio_changed_stop	stop_task.c	/^prio_changed_stop(struct rq *rq, struct task_struct *p, int oldprio)$/;"	f	file:
proc_sched_autogroup_set_nice	autogroup.c	/^int proc_sched_autogroup_set_nice(struct task_struct *p, int nice)$/;"	f
proc_sched_autogroup_show_task	autogroup.c	/^void proc_sched_autogroup_show_task(struct task_struct *p, struct seq_file *m)$/;"	f
proc_sched_set_task	debug.c	/^void proc_sched_set_task(struct task_struct *p)$/;"	f
proc_sched_show_task	debug.c	/^void proc_sched_show_task(struct task_struct *p, struct pid_namespace *ns,$/;"	f
proc_schedstat_init	stats.c	/^static int __init proc_schedstat_init(void)$/;"	f	file:
proc_schedstat_init	stats.c	/^subsys_initcall(proc_schedstat_init);$/;"	v
prop_runnable_sum	sched.h	/^	long			prop_runnable_sum;$/;"	m	struct:cfs_rq
propagate	sched.h	/^	long			propagate;$/;"	m	struct:cfs_rq
propagate_entity_cfs_rq	fair.c	/^static void propagate_entity_cfs_rq(struct sched_entity *se) { }$/;"	f	file:
propagate_entity_cfs_rq	fair.c	/^static void propagate_entity_cfs_rq(struct sched_entity *se)$/;"	f	file:
propagate_entity_load_avg	fair.c	/^static inline int propagate_entity_load_avg(struct sched_entity *se)$/;"	f	file:
pull_dl_task	deadline.c	/^static inline void pull_dl_task(struct rq *rq)$/;"	f	file:
pull_dl_task	deadline.c	/^static void pull_dl_task(struct rq *this_rq)$/;"	f	file:
pull_rt_task	rt.c	/^static inline void pull_rt_task(struct rq *this_rq)$/;"	f	file:
pull_rt_task	rt.c	/^static void pull_rt_task(struct rq *this_rq)$/;"	f	file:
push_cpu	sched.h	/^	int			push_cpu;$/;"	m	struct:rq
push_dl_task	deadline.c	/^static int push_dl_task(struct rq *rq)$/;"	f	file:
push_dl_tasks	deadline.c	/^static void push_dl_tasks(struct rq *rq)$/;"	f	file:
push_rt_task	rt.c	/^static int push_rt_task(struct rq *rq)$/;"	f	file:
push_rt_tasks	rt.c	/^static void push_rt_tasks(struct rq *rq)$/;"	f	file:
pushable_dl_tasks_root	sched.h	/^	struct rb_root_cached	pushable_dl_tasks_root;$/;"	m	struct:dl_rq	typeref:struct:dl_rq::rb_root_cached
pushable_tasks	sched.h	/^	struct plist_head	pushable_tasks;$/;"	m	struct:rt_rq	typeref:struct:rt_rq::plist_head
put_numa_group	fair.c	/^static inline void put_numa_group(struct numa_group *grp)$/;"	f	file:
put_prev_entity	fair.c	/^static void put_prev_entity(struct cfs_rq *cfs_rq, struct sched_entity *prev)$/;"	f	file:
put_prev_task	sched.h	/^	void (*put_prev_task)(struct rq *rq, struct task_struct *p);$/;"	m	struct:sched_class
put_prev_task	sched.h	/^static inline void put_prev_task(struct rq *rq, struct task_struct *prev)$/;"	f
put_prev_task_dl	deadline.c	/^static void put_prev_task_dl(struct rq *rq, struct task_struct *p)$/;"	f	file:
put_prev_task_fair	fair.c	/^static void put_prev_task_fair(struct rq *rq, struct task_struct *prev)$/;"	f	file:
put_prev_task_fake	core.c	/^static void put_prev_task_fake(struct rq *rq, struct task_struct *prev)$/;"	f	file:
put_prev_task_idle	idle.c	/^static void put_prev_task_idle(struct rq *rq, struct task_struct *prev)$/;"	f	file:
put_prev_task_rt	rt.c	/^static void put_prev_task_rt(struct rq *rq, struct task_struct *p)$/;"	f	file:
put_prev_task_stop	stop_task.c	/^static void put_prev_task_stop(struct rq *rq, struct task_struct *prev)$/;"	f	file:
queue	sched.h	/^	struct list_head queue[MAX_RT_PRIO];$/;"	m	struct:rt_prio_array	typeref:struct:rt_prio_array::list_head
queue_balance_callback	sched.h	/^queue_balance_callback(struct rq *rq,$/;"	f
quota	core.c	/^	u64 period, quota;$/;"	m	struct:cfs_schedulable_data	file:
quota	sched.h	/^	u64			quota;$/;"	m	struct:cfs_bandwidth
rate_limit_us	cpufreq_schedutil.c	/^	unsigned int		rate_limit_us;$/;"	m	struct:sugov_tunables	file:
rate_limit_us	cpufreq_schedutil.c	/^static struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);$/;"	v	typeref:struct:governor_attr	file:
rate_limit_us_show	cpufreq_schedutil.c	/^static ssize_t rate_limit_us_show(struct gov_attr_set *attr_set, char *buf)$/;"	f	file:
rate_limit_us_store	cpufreq_schedutil.c	/^rate_limit_us_store(struct gov_attr_set *attr_set, const char *buf, size_t count)$/;"	f	file:
raw_rq	sched.h	929;"	d
rcu	fair.c	/^	struct rcu_head rcu;$/;"	m	struct:numa_group	typeref:struct:numa_group::rcu_head	file:
rcu	sched.h	/^	struct rcu_head		rcu;$/;"	m	struct:root_domain	typeref:struct:root_domain::rcu_head
rcu	sched.h	/^	struct rcu_head		rcu;$/;"	m	struct:task_group	typeref:struct:task_group::rcu_head
rcu_dereference_check_sched_domain	sched.h	1108;"	d
rd	sched.h	/^	struct root_domain	*rd;$/;"	m	struct:rq	typeref:struct:rq::root_domain
rd	topology.c	/^	struct root_domain	*rd;$/;"	m	struct:s_data	typeref:struct:s_data::root_domain	file:
read_sum_exec_runtime	cputime.c	/^static inline u64 read_sum_exec_runtime(struct task_struct *t)$/;"	f	file:
read_sum_exec_runtime	cputime.c	/^static u64 read_sum_exec_runtime(struct task_struct *t)$/;"	f	file:
rebalance_domains	fair.c	/^static void rebalance_domains(struct rq *rq, enum cpu_idle_type idle)$/;"	f	file:
record_wakee	fair.c	/^static void record_wakee(struct task_struct *p)$/;"	f	file:
ref	sched.h	/^	atomic_t		ref;$/;"	m	struct:sched_group
ref	sched.h	/^	atomic_t		ref;$/;"	m	struct:sched_group_capacity
refcount	fair.c	/^	atomic_t refcount;$/;"	m	struct:numa_group	file:
refcount	sched.h	/^	atomic_t		refcount;$/;"	m	struct:root_domain
register_sched_domain_sysctl	debug.c	/^void register_sched_domain_sysctl(void)$/;"	f
register_sched_domain_sysctl	sched.h	/^static inline void register_sched_domain_sysctl(void)$/;"	f
regular	fair.c	/^enum fbq_type { regular, remote, all };$/;"	e	enum:fbq_type	file:
remote	fair.c	/^enum fbq_type { regular, remote, all };$/;"	e	enum:fbq_type	file:
remove_entity_load_avg	fair.c	/^static inline void remove_entity_load_avg(struct sched_entity *se) {}$/;"	f	file:
remove_entity_load_avg	fair.c	/^void remove_entity_load_avg(struct sched_entity *se)$/;"	f
remove_wait_queue	wait.c	/^EXPORT_SYMBOL(remove_wait_queue);$/;"	v
remove_wait_queue	wait.c	/^void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)$/;"	f
removed	sched.h	/^	} removed;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::__anon2
replenish_dl_entity	deadline.c	/^static void replenish_dl_entity(struct sched_dl_entity *dl_se,$/;"	f	file:
requeue_rt_entity	rt.c	/^requeue_rt_entity(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se, int head)$/;"	f	file:
requeue_task_rt	rt.c	/^static void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)$/;"	f	file:
resched_cpu	core.c	/^void resched_cpu(int cpu)$/;"	f
resched_curr	core.c	/^void resched_curr(struct rq *rq)$/;"	f
reset_ptenuma_scan	fair.c	/^static void reset_ptenuma_scan(struct task_struct *p)$/;"	f	file:
return_cfs_rq_runtime	fair.c	/^static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq) {}$/;"	f	file:
return_cfs_rq_runtime	fair.c	/^static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq)$/;"	f	file:
reweight_entity	fair.c	/^static void reweight_entity(struct cfs_rq *cfs_rq, struct sched_entity *se,$/;"	f	file:
reweight_task	fair.c	/^void reweight_task(struct task_struct *p, int prio)$/;"	f
right_child	cpudeadline.c	/^static inline int right_child(int i)$/;"	f	file:
root	sched.h	/^	struct rb_root_cached	root;$/;"	m	struct:dl_rq	typeref:struct:dl_rq::rb_root_cached
root_cpuacct	cpuacct.c	/^static struct cpuacct root_cpuacct = {$/;"	v	typeref:struct:cpuacct	file:
root_domain	sched.h	/^struct root_domain {$/;"	s
root_task_group	core.c	/^struct task_group root_task_group;$/;"	v	typeref:struct:task_group
rq	sched.h	/^	struct rq		*rq;	\/* CPU runqueue to which this cfs_rq is attached *\/$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::rq
rq	sched.h	/^	struct rq		*rq;$/;"	m	struct:rt_rq	typeref:struct:rt_rq::rq
rq	sched.h	/^struct rq {$/;"	s
rq_attach_root	topology.c	/^void rq_attach_root(struct rq *rq, struct root_domain *rd)$/;"	f
rq_clock	sched.h	/^static inline u64 rq_clock(struct rq *rq)$/;"	f
rq_clock_cancel_skipupdate	sched.h	/^static inline void rq_clock_cancel_skipupdate(struct rq *rq)$/;"	f
rq_clock_skip_update	sched.h	/^static inline void rq_clock_skip_update(struct rq *rq)$/;"	f
rq_clock_task	sched.h	/^static inline u64 rq_clock_task(struct rq *rq)$/;"	f
rq_cpu_time	sched.h	/^	unsigned long long	rq_cpu_time;$/;"	m	struct:rq
rq_flags	sched.h	/^struct rq_flags {$/;"	s
rq_of	fair.c	/^static inline struct rq *rq_of(struct cfs_rq *cfs_rq)$/;"	f	file:
rq_of_dl_rq	deadline.c	/^static inline struct rq *rq_of_dl_rq(struct dl_rq *dl_rq)$/;"	f	file:
rq_of_rt_rq	rt.c	/^static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)$/;"	f	file:
rq_of_rt_se	rt.c	/^static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)$/;"	f	file:
rq_offline	sched.h	/^	void (*rq_offline)(struct rq *rq);$/;"	m	struct:sched_class
rq_offline_dl	deadline.c	/^static void rq_offline_dl(struct rq *rq)$/;"	f	file:
rq_offline_fair	fair.c	/^static void rq_offline_fair(struct rq *rq)$/;"	f	file:
rq_offline_rt	rt.c	/^static void rq_offline_rt(struct rq *rq)$/;"	f	file:
rq_online	sched.h	/^	void (*rq_online)(struct rq *rq);$/;"	m	struct:sched_class
rq_online_dl	deadline.c	/^static void rq_online_dl(struct rq *rq)$/;"	f	file:
rq_online_fair	fair.c	/^static void rq_online_fair(struct rq *rq)$/;"	f	file:
rq_online_rt	rt.c	/^static void rq_online_rt(struct rq *rq)$/;"	f	file:
rq_pin_lock	sched.h	/^static inline void rq_pin_lock(struct rq *rq, struct rq_flags *rf)$/;"	f
rq_repin_lock	sched.h	/^static inline void rq_repin_lock(struct rq *rq, struct rq_flags *rf)$/;"	f
rq_sched_info	sched.h	/^	struct sched_info	rq_sched_info;$/;"	m	struct:rq	typeref:struct:rq::sched_info
rq_sched_info_arrive	stats.h	/^rq_sched_info_arrive(struct rq *rq, unsigned long long delta)$/;"	f
rq_sched_info_arrive	stats.h	/^static inline void rq_sched_info_arrive  (struct rq *rq, unsigned long long delta) { }$/;"	f
rq_sched_info_depart	stats.h	/^rq_sched_info_depart(struct rq *rq, unsigned long long delta)$/;"	f
rq_sched_info_depart	stats.h	/^static inline void rq_sched_info_depart  (struct rq *rq, unsigned long long delta) { }$/;"	f
rq_sched_info_dequeued	stats.h	/^rq_sched_info_dequeued(struct rq *rq, unsigned long long delta)$/;"	f
rq_sched_info_dequeued	stats.h	/^static inline void rq_sched_info_dequeued(struct rq *rq, unsigned long long delta) { }$/;"	f
rq_unpin_lock	sched.h	/^static inline void rq_unpin_lock(struct rq *rq, struct rq_flags *rf)$/;"	f
rr_nr_running	sched.h	/^	unsigned int		rr_nr_running;$/;"	m	struct:rt_rq
rt	sched.h	/^	struct rt_rq		rt;$/;"	m	struct:rq	typeref:struct:rq::rt_rq
rt_avg	sched.h	/^	u64			rt_avg;$/;"	m	struct:rq
rt_bandwidth	sched.h	/^	struct rt_bandwidth	rt_bandwidth;$/;"	m	struct:task_group	typeref:struct:task_group::rt_bandwidth
rt_bandwidth	sched.h	/^struct rt_bandwidth {$/;"	s
rt_bandwidth_enabled	sched.h	/^static inline int rt_bandwidth_enabled(void)$/;"	f
rt_clear_overload	rt.c	/^static inline void rt_clear_overload(struct rq *rq)$/;"	f	file:
rt_effective_prio	core.c	/^static inline int rt_effective_prio(struct task_struct *p, int prio)$/;"	f	file:
rt_entity_is_task	rt.c	108;"	d	file:
rt_entity_is_task	rt.c	222;"	d	file:
rt_mutex_setprio	core.c	/^void rt_mutex_setprio(struct task_struct *p, struct task_struct *pi_task)$/;"	f
rt_nr_boosted	sched.h	/^	unsigned long		rt_nr_boosted;$/;"	m	struct:rt_rq
rt_nr_migratory	sched.h	/^	unsigned long		rt_nr_migratory;$/;"	m	struct:rt_rq
rt_nr_running	sched.h	/^	unsigned int		rt_nr_running;$/;"	m	struct:rt_rq
rt_nr_total	sched.h	/^	unsigned long		rt_nr_total;$/;"	m	struct:rt_rq
rt_overloaded	rt.c	/^static inline int rt_overloaded(struct rq *rq)$/;"	f	file:
rt_period	rt.c	/^	u64 rt_period;$/;"	m	struct:rt_schedulable_data	file:
rt_period	sched.h	/^	ktime_t			rt_period;$/;"	m	struct:rt_bandwidth
rt_period_active	sched.h	/^	unsigned int		rt_period_active;$/;"	m	struct:rt_bandwidth
rt_period_timer	sched.h	/^	struct hrtimer		rt_period_timer;$/;"	m	struct:rt_bandwidth	typeref:struct:rt_bandwidth::hrtimer
rt_policy	sched.h	/^static inline int rt_policy(int policy)$/;"	f
rt_prio_array	sched.h	/^struct rt_prio_array {$/;"	s
rt_queue_pull_task	rt.c	/^static inline void rt_queue_pull_task(struct rq *rq)$/;"	f	file:
rt_queue_push_tasks	rt.c	/^static inline void rt_queue_push_tasks(struct rq *rq)$/;"	f	file:
rt_queued	sched.h	/^	int			rt_queued;$/;"	m	struct:rt_rq
rt_rq	sched.h	/^	struct rt_rq		**rt_rq;$/;"	m	struct:task_group	typeref:struct:task_group::rt_rq
rt_rq	sched.h	/^struct rt_rq {$/;"	s
rt_rq_is_runnable	sched.h	/^static inline bool rt_rq_is_runnable(struct rt_rq *rt_rq)$/;"	f
rt_rq_iter_t	rt.c	/^typedef struct rt_rq *rt_rq_iter_t;$/;"	t	typeref:struct:rt_rq	file:
rt_rq_iter_t	rt.c	/^typedef struct task_group *rt_rq_iter_t;$/;"	t	typeref:struct:task_group	file:
rt_rq_of_se	rt.c	/^static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)$/;"	f	file:
rt_rq_throttled	rt.c	/^static inline int rt_rq_throttled(struct rt_rq *rt_rq)$/;"	f	file:
rt_runtime	rt.c	/^	u64 rt_runtime;$/;"	m	struct:rt_schedulable_data	file:
rt_runtime	sched.h	/^	u64			rt_runtime;$/;"	m	struct:rt_bandwidth
rt_runtime	sched.h	/^	u64			rt_runtime;$/;"	m	struct:rt_rq
rt_runtime_lock	sched.h	/^	raw_spinlock_t		rt_runtime_lock;$/;"	m	struct:rt_bandwidth
rt_runtime_lock	sched.h	/^	raw_spinlock_t		rt_runtime_lock;$/;"	m	struct:rt_rq
rt_sched_class	rt.c	/^const struct sched_class rt_sched_class = {$/;"	v	typeref:struct:sched_class
rt_schedulable_data	rt.c	/^struct rt_schedulable_data {$/;"	s	file:
rt_se	sched.h	/^	struct sched_rt_entity	**rt_se;$/;"	m	struct:task_group	typeref:struct:task_group::sched_rt_entity
rt_se_boosted	rt.c	/^static int rt_se_boosted(struct sched_rt_entity *rt_se)$/;"	f	file:
rt_se_nr_running	rt.c	/^unsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)$/;"	f	file:
rt_se_prio	rt.c	/^static inline int rt_se_prio(struct sched_rt_entity *rt_se)$/;"	f	file:
rt_se_rr_nr_running	rt.c	/^unsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)$/;"	f	file:
rt_set_overload	rt.c	/^static inline void rt_set_overload(struct rq *rq)$/;"	f	file:
rt_task_of	rt.c	/^static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)$/;"	f	file:
rt_throttled	sched.h	/^	int			rt_throttled;$/;"	m	struct:rt_rq
rt_time	sched.h	/^	u64			rt_time;$/;"	m	struct:rt_rq
rto_count	sched.h	/^	atomic_t		rto_count;$/;"	m	struct:root_domain
rto_cpu	sched.h	/^	int			rto_cpu;$/;"	m	struct:root_domain
rto_lock	sched.h	/^	raw_spinlock_t		rto_lock;$/;"	m	struct:root_domain
rto_loop	sched.h	/^	int			rto_loop;$/;"	m	struct:root_domain
rto_loop_next	sched.h	/^	atomic_t		rto_loop_next;$/;"	m	struct:root_domain
rto_loop_start	sched.h	/^	atomic_t		rto_loop_start;$/;"	m	struct:root_domain
rto_mask	sched.h	/^	cpumask_var_t		rto_mask;$/;"	m	struct:root_domain
rto_next_cpu	rt.c	/^static int rto_next_cpu(struct root_domain *rd)$/;"	f	file:
rto_push_irq_work_func	rt.c	/^void rto_push_irq_work_func(struct irq_work *work)$/;"	f
rto_push_work	sched.h	/^	struct irq_work		rto_push_work;$/;"	m	struct:root_domain	typeref:struct:root_domain::irq_work
rto_start_trylock	rt.c	/^static inline bool rto_start_trylock(atomic_t *v)$/;"	f	file:
rto_start_unlock	rt.c	/^static inline void rto_start_unlock(atomic_t *v)$/;"	f	file:
run_rebalance_domains	fair.c	/^static __latent_entropy void run_rebalance_domains(struct softirq_action *h)$/;"	f	file:
runnable_avg_yN_inv	sched-pelt.h	/^static const u32 runnable_avg_yN_inv[] = {$/;"	v
runnable_sum	sched.h	/^		unsigned long	runnable_sum;$/;"	m	struct:cfs_rq::__anon2
runnable_weight	sched.h	/^	unsigned long		runnable_weight;$/;"	m	struct:cfs_rq
running_bw	sched.h	/^	u64			running_bw;$/;"	m	struct:dl_rq
running_clock	clock.c	/^u64 __weak running_clock(void)$/;"	f
runtime	sched.h	/^	u64			runtime;$/;"	m	struct:cfs_bandwidth
runtime_enabled	sched.h	/^	int			runtime_enabled;$/;"	m	struct:cfs_rq
runtime_expires	sched.h	/^	u64			runtime_expires;$/;"	m	struct:cfs_bandwidth
runtime_expires	sched.h	/^	u64			runtime_expires;$/;"	m	struct:cfs_rq
runtime_refresh_within	fair.c	/^static int runtime_refresh_within(struct cfs_bandwidth *cfs_b, u64 min_expire)$/;"	f	file:
runtime_remaining	sched.h	/^	s64			runtime_remaining;$/;"	m	struct:cfs_rq
s_alloc	topology.c	/^enum s_alloc {$/;"	g	file:
s_data	topology.c	/^struct s_data {$/;"	s	file:
sa_none	topology.c	/^	sa_none,$/;"	e	enum:s_alloc	file:
sa_rootdomain	topology.c	/^	sa_rootdomain,$/;"	e	enum:s_alloc	file:
sa_sd	topology.c	/^	sa_sd,$/;"	e	enum:s_alloc	file:
sa_sd_storage	topology.c	/^	sa_sd_storage,$/;"	e	enum:s_alloc	file:
saved_idle_calls	cpufreq_schedutil.c	/^	unsigned long		saved_idle_calls;$/;"	m	struct:sugov_cpu	file:
scale_load	sched.h	124;"	d
scale_load	sched.h	128;"	d
scale_load_down	sched.h	125;"	d
scale_load_down	sched.h	129;"	d
scale_rt_capacity	fair.c	/^static unsigned long scale_rt_capacity(int cpu)$/;"	f	file:
scale_stime	cputime.c	/^static u64 scale_stime(u64 stime, u64 rtime, u64 total)$/;"	f	file:
sched_asym_prefer	sched.h	/^static inline bool sched_asym_prefer(int a, int b)$/;"	f
sched_autogroup_create_attach	autogroup.c	/^EXPORT_SYMBOL(sched_autogroup_create_attach);$/;"	v
sched_autogroup_create_attach	autogroup.c	/^void sched_autogroup_create_attach(struct task_struct *p)$/;"	f
sched_autogroup_detach	autogroup.c	/^EXPORT_SYMBOL(sched_autogroup_detach);$/;"	v
sched_autogroup_detach	autogroup.c	/^void sched_autogroup_detach(struct task_struct *p)$/;"	f
sched_autogroup_exit	autogroup.c	/^void sched_autogroup_exit(struct signal_struct *sig)$/;"	f
sched_autogroup_exit_task	autogroup.c	/^void sched_autogroup_exit_task(struct task_struct *p)$/;"	f
sched_autogroup_fork	autogroup.c	/^void sched_autogroup_fork(struct signal_struct *sig)$/;"	f
sched_avg_period	sched.h	/^static inline u64 sched_avg_period(void)$/;"	f
sched_avg_update	core.c	/^void sched_avg_update(struct rq *rq)$/;"	f
sched_avg_update	sched.h	/^static inline void sched_avg_update(struct rq *rq) { }$/;"	f
sched_can_stop_tick	core.c	/^bool sched_can_stop_tick(struct rq *rq)$/;"	f
sched_cfs_bandwidth_slice	fair.c	/^static inline u64 sched_cfs_bandwidth_slice(void)$/;"	f	file:
sched_cfs_period_timer	fair.c	/^static enum hrtimer_restart sched_cfs_period_timer(struct hrtimer *timer)$/;"	f	file:
sched_cfs_slack_timer	fair.c	/^static enum hrtimer_restart sched_cfs_slack_timer(struct hrtimer *timer)$/;"	f	file:
sched_change_group	core.c	/^static void sched_change_group(struct task_struct *tsk, int type)$/;"	f	file:
sched_class	sched.h	/^struct sched_class {$/;"	s
sched_class_highest	sched.h	1553;"	d
sched_class_highest	sched.h	1555;"	d
sched_clock	clock.c	/^EXPORT_SYMBOL_GPL(sched_clock);$/;"	v
sched_clock	clock.c	/^unsigned long long __weak sched_clock(void)$/;"	f
sched_clock_cpu	clock.c	/^EXPORT_SYMBOL_GPL(sched_clock_cpu);$/;"	v
sched_clock_cpu	clock.c	/^u64 sched_clock_cpu(int cpu)$/;"	f
sched_clock_data	clock.c	/^struct sched_clock_data {$/;"	s	file:
sched_clock_idle_sleep_event	clock.c	/^EXPORT_SYMBOL_GPL(sched_clock_idle_sleep_event);$/;"	v
sched_clock_idle_sleep_event	clock.c	/^void sched_clock_idle_sleep_event(void)$/;"	f
sched_clock_idle_wakeup_event	clock.c	/^EXPORT_SYMBOL_GPL(sched_clock_idle_wakeup_event);$/;"	v
sched_clock_idle_wakeup_event	clock.c	/^void sched_clock_idle_wakeup_event(void)$/;"	f
sched_clock_init	clock.c	/^void sched_clock_init(void)$/;"	f
sched_clock_init_late	clock.c	/^late_initcall(sched_clock_init_late);$/;"	v
sched_clock_init_late	clock.c	/^static int __init sched_clock_init_late(void)$/;"	f	file:
sched_clock_irqtime	cputime.c	/^static int sched_clock_irqtime;$/;"	v	file:
sched_clock_irqtime	cputime.c	88;"	d	file:
sched_clock_local	clock.c	/^static u64 sched_clock_local(struct sched_clock_data *scd)$/;"	f	file:
sched_clock_remote	clock.c	/^static u64 sched_clock_remote(struct sched_clock_data *scd)$/;"	f	file:
sched_clock_running	clock.c	/^__read_mostly int sched_clock_running;$/;"	v
sched_clock_stable	clock.c	/^int sched_clock_stable(void)$/;"	f
sched_clock_tick	clock.c	/^void sched_clock_tick(void)$/;"	f
sched_clock_tick_stable	clock.c	/^void sched_clock_tick_stable(void)$/;"	f
sched_copy_attr	core.c	/^static int sched_copy_attr(struct sched_attr __user *uattr, struct sched_attr *attr)$/;"	f	file:
sched_count	sched.h	/^	unsigned int		sched_count;$/;"	m	struct:rq
sched_cpu_activate	core.c	/^int sched_cpu_activate(unsigned int cpu)$/;"	f
sched_cpu_deactivate	core.c	/^int sched_cpu_deactivate(unsigned int cpu)$/;"	f
sched_cpu_dying	core.c	/^int sched_cpu_dying(unsigned int cpu)$/;"	f
sched_cpu_starting	core.c	/^int sched_cpu_starting(unsigned int cpu)$/;"	f
sched_create_group	core.c	/^struct task_group *sched_create_group(struct task_group *parent)$/;"	f
sched_debug	topology.c	/^static inline bool sched_debug(void)$/;"	f	file:
sched_debug_enabled	debug.c	/^__read_mostly bool sched_debug_enabled;$/;"	v
sched_debug_enabled	topology.c	140;"	d	file:
sched_debug_header	debug.c	/^static void sched_debug_header(struct seq_file *m)$/;"	f	file:
sched_debug_next	debug.c	/^static void *sched_debug_next(struct seq_file *file, void *data, loff_t *offset)$/;"	f	file:
sched_debug_setup	topology.c	/^static int __init sched_debug_setup(char *str)$/;"	f	file:
sched_debug_show	debug.c	/^static int sched_debug_show(struct seq_file *m, void *v)$/;"	f	file:
sched_debug_sops	debug.c	/^static const struct seq_operations sched_debug_sops = {$/;"	v	typeref:struct:seq_operations	file:
sched_debug_start	debug.c	/^static void *sched_debug_start(struct seq_file *file, loff_t *offset)$/;"	f	file:
sched_debug_stop	debug.c	/^static void sched_debug_stop(struct seq_file *file, void *data)$/;"	f	file:
sched_destroy_group	core.c	/^void sched_destroy_group(struct task_group *tg)$/;"	f
sched_dl_do_global	deadline.c	/^void sched_dl_do_global(void)$/;"	f
sched_dl_global_validate	deadline.c	/^int sched_dl_global_validate(void)$/;"	f
sched_dl_overflow	deadline.c	/^int sched_dl_overflow(struct task_struct *p, int policy,$/;"	f
sched_domain_debug	topology.c	/^static void sched_domain_debug(struct sched_domain *sd, int cpu)$/;"	f	file:
sched_domain_debug	topology.c	141;"	d	file:
sched_domain_debug_one	topology.c	/^static int sched_domain_debug_one(struct sched_domain *sd, int cpu, int level,$/;"	f	file:
sched_domain_level_max	topology.c	/^int sched_domain_level_max;$/;"	v
sched_domain_topology	topology.c	/^static struct sched_domain_topology_level *sched_domain_topology =$/;"	v	typeref:struct:sched_domain_topology_level	file:
sched_domains_curr_level	topology.c	/^static int			sched_domains_curr_level;$/;"	v	file:
sched_domains_mutex	topology.c	/^DEFINE_MUTEX(sched_domains_mutex);$/;"	v
sched_domains_numa_distance	topology.c	/^static int			*sched_domains_numa_distance;$/;"	v	file:
sched_domains_numa_levels	topology.c	/^static int			sched_domains_numa_levels;$/;"	v	file:
sched_domains_numa_masks	topology.c	/^static struct cpumask		***sched_domains_numa_masks;$/;"	v	typeref:struct:cpumask	file:
sched_domains_numa_masks_clear	sched.h	/^static inline void sched_domains_numa_masks_clear(unsigned int cpu) { }$/;"	f
sched_domains_numa_masks_clear	topology.c	/^void sched_domains_numa_masks_clear(unsigned int cpu)$/;"	f
sched_domains_numa_masks_set	sched.h	/^static inline void sched_domains_numa_masks_set(unsigned int cpu) { }$/;"	f
sched_domains_numa_masks_set	topology.c	/^void sched_domains_numa_masks_set(unsigned int cpu)$/;"	f
sched_domains_tmpmask	topology.c	/^cpumask_var_t sched_domains_tmpmask;$/;"	v
sched_domains_tmpmask2	topology.c	/^cpumask_var_t sched_domains_tmpmask2;$/;"	v
sched_exec	core.c	/^void sched_exec(void)$/;"	f
sched_feat	sched.h	1357;"	d
sched_feat	sched.h	1373;"	d
sched_feat_disable	debug.c	/^static void sched_feat_disable(int i) { };$/;"	f	file:
sched_feat_disable	debug.c	/^static void sched_feat_disable(int i)$/;"	f	file:
sched_feat_enable	debug.c	/^static void sched_feat_enable(int i) { };$/;"	f	file:
sched_feat_enable	debug.c	/^static void sched_feat_enable(int i)$/;"	f	file:
sched_feat_fops	debug.c	/^static const struct file_operations sched_feat_fops = {$/;"	v	typeref:struct:file_operations	file:
sched_feat_keys	debug.c	/^struct static_key sched_feat_keys[__SCHED_FEAT_NR] = {$/;"	v	typeref:struct:static_key
sched_feat_names	debug.c	/^static const char * const sched_feat_names[] = {$/;"	v	file:
sched_feat_open	debug.c	/^static int sched_feat_open(struct inode *inode, struct file *filp)$/;"	f	file:
sched_feat_set	debug.c	/^static int sched_feat_set(char *cmp)$/;"	f	file:
sched_feat_show	debug.c	/^static int sched_feat_show(struct seq_file *m, void *v)$/;"	f	file:
sched_feat_write	debug.c	/^sched_feat_write(struct file *filp, const char __user *ubuf,$/;"	f	file:
sched_fork	core.c	/^int sched_fork(unsigned long clone_flags, struct task_struct *p)$/;"	f
sched_free_group	core.c	/^static void sched_free_group(struct task_group *tg)$/;"	f	file:
sched_free_group_rcu	core.c	/^static void sched_free_group_rcu(struct rcu_head *rhp)$/;"	f	file:
sched_get_rd	topology.c	/^void sched_get_rd(struct root_domain *rd)$/;"	f
sched_getaffinity	core.c	/^long sched_getaffinity(pid_t pid, struct cpumask *mask)$/;"	f
sched_goidle	sched.h	/^	unsigned int		sched_goidle;$/;"	m	struct:rq
sched_group	sched.h	/^struct sched_group {$/;"	s
sched_group_capacity	sched.h	/^struct sched_group_capacity {$/;"	s
sched_group_rt_period	rt.c	/^long sched_group_rt_period(struct task_group *tg)$/;"	f
sched_group_rt_runtime	rt.c	/^long sched_group_rt_runtime(struct task_group *tg)$/;"	f
sched_group_set_rt_period	rt.c	/^int sched_group_set_rt_period(struct task_group *tg, u64 rt_period_us)$/;"	f
sched_group_set_rt_runtime	rt.c	/^int sched_group_set_rt_runtime(struct task_group *tg, long rt_runtime_us)$/;"	f
sched_group_set_shares	fair.c	/^int sched_group_set_shares(struct task_group *tg, unsigned long shares)$/;"	f
sched_group_span	sched.h	/^static inline struct cpumask *sched_group_span(struct sched_group *sg)$/;"	f
sched_idle_set_state	idle.c	/^void sched_idle_set_state(struct cpuidle_state *idle_state)$/;"	f
sched_info_arrive	stats.h	/^static void sched_info_arrive(struct rq *rq, struct task_struct *t)$/;"	f
sched_info_arrive	stats.h	165;"	d
sched_info_depart	stats.h	/^static inline void sched_info_depart(struct rq *rq, struct task_struct *t)$/;"	f
sched_info_depart	stats.h	164;"	d
sched_info_dequeued	stats.h	/^static inline void sched_info_dequeued(struct rq *rq, struct task_struct *t)$/;"	f
sched_info_dequeued	stats.h	163;"	d
sched_info_queued	stats.h	/^static inline void sched_info_queued(struct rq *rq, struct task_struct *t)$/;"	f
sched_info_queued	stats.h	161;"	d
sched_info_reset_dequeued	stats.h	/^static inline void sched_info_reset_dequeued(struct task_struct *t)$/;"	f
sched_info_reset_dequeued	stats.h	162;"	d
sched_info_switch	stats.h	/^sched_info_switch(struct rq *rq, struct task_struct *prev, struct task_struct *next)$/;"	f
sched_info_switch	stats.h	166;"	d
sched_init	core.c	/^void __init sched_init(void)$/;"	f
sched_init_debug	debug.c	/^late_initcall(sched_init_debug);$/;"	v
sched_init_debug	debug.c	/^static __init int sched_init_debug(void)$/;"	f	file:
sched_init_domains	topology.c	/^int sched_init_domains(const struct cpumask *cpu_map)$/;"	f
sched_init_granularity	fair.c	/^void sched_init_granularity(void)$/;"	f
sched_init_numa	sched.h	/^static inline void sched_init_numa(void) { }$/;"	f
sched_init_numa	topology.c	/^void sched_init_numa(void)$/;"	f
sched_init_smp	core.c	/^void __init sched_init_smp(void)$/;"	f
sched_max_numa_distance	topology.c	/^int				sched_max_numa_distance;$/;"	v
sched_move_task	core.c	/^void sched_move_task(struct task_struct *tsk)$/;"	f
sched_nr_latency	fair.c	/^static unsigned int sched_nr_latency = 8;$/;"	v	file:
sched_nr_migrate_break	fair.c	/^static const unsigned int sched_nr_migrate_break = 32;$/;"	v	file:
sched_numa_balancing	core.c	/^DEFINE_STATIC_KEY_FALSE(sched_numa_balancing);$/;"	v
sched_numa_topology_type	topology.c	/^enum numa_topology_type sched_numa_topology_type;$/;"	v	typeref:enum:numa_topology_type
sched_numa_warn	topology.c	/^static void sched_numa_warn(const char *str)$/;"	f	file:
sched_offline_group	core.c	/^void sched_offline_group(struct task_group *tg)$/;"	f
sched_online_group	core.c	/^void sched_online_group(struct task_group *tg, struct task_group *parent)$/;"	f
sched_prio_to_weight	core.c	/^const int sched_prio_to_weight[40] = {$/;"	v
sched_prio_to_wmult	core.c	/^const u32 sched_prio_to_wmult[40] = {$/;"	v
sched_proc_update_handler	fair.c	/^int sched_proc_update_handler(struct ctl_table *table, int write,$/;"	f
sched_put_rd	topology.c	/^void sched_put_rd(struct root_domain *rd)$/;"	f
sched_read_attr	core.c	/^static int sched_read_attr(struct sched_attr __user *uattr,$/;"	f	file:
sched_rq_cpu_starting	core.c	/^static void sched_rq_cpu_starting(unsigned int cpu)$/;"	f	file:
sched_rr_get_interval	core.c	/^static int sched_rr_get_interval(pid_t pid, struct timespec64 *t)$/;"	f	file:
sched_rr_handler	rt.c	/^int sched_rr_handler(struct ctl_table *table, int write,$/;"	f
sched_rr_timeslice	rt.c	/^int sched_rr_timeslice = RR_TIMESLICE;$/;"	v
sched_rt_avg_update	sched.h	/^static inline void sched_rt_avg_update(struct rq *rq, u64 rt_delta) { }$/;"	f
sched_rt_avg_update	sched.h	/^static inline void sched_rt_avg_update(struct rq *rq, u64 rt_delta)$/;"	f
sched_rt_bandwidth	rt.c	/^static inline struct rt_bandwidth *sched_rt_bandwidth(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_bandwidth_account	rt.c	/^bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)$/;"	f
sched_rt_can_attach	rt.c	/^int sched_rt_can_attach(struct task_group *tg, struct task_struct *tsk)$/;"	f
sched_rt_do_global	rt.c	/^static void sched_rt_do_global(void)$/;"	f	file:
sched_rt_global_constraints	rt.c	/^static int sched_rt_global_constraints(void)$/;"	f	file:
sched_rt_global_validate	rt.c	/^static int sched_rt_global_validate(void)$/;"	f	file:
sched_rt_handler	rt.c	/^int sched_rt_handler(struct ctl_table *table, int write,$/;"	f
sched_rt_period	rt.c	/^static inline u64 sched_rt_period(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_period_mask	rt.c	/^static inline const struct cpumask *sched_rt_period_mask(void)$/;"	f	file:
sched_rt_period_rt_rq	rt.c	/^struct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)$/;"	f	file:
sched_rt_period_timer	rt.c	/^static enum hrtimer_restart sched_rt_period_timer(struct hrtimer *timer)$/;"	f	file:
sched_rt_rq_dequeue	rt.c	/^static inline void sched_rt_rq_dequeue(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_rq_dequeue	rt.c	/^static void sched_rt_rq_dequeue(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_rq_enqueue	rt.c	/^static inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_rq_enqueue	rt.c	/^static void sched_rt_rq_enqueue(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_runtime	rt.c	/^static inline u64 sched_rt_runtime(struct rt_rq *rt_rq)$/;"	f	file:
sched_rt_runtime_exceeded	rt.c	/^static int sched_rt_runtime_exceeded(struct rt_rq *rt_rq)$/;"	f	file:
sched_schedstats	core.c	/^DEFINE_STATIC_KEY_FALSE(sched_schedstats);$/;"	v
sched_set_stop_task	core.c	/^void sched_set_stop_task(int cpu, struct task_struct *stop)$/;"	f
sched_setaffinity	core.c	/^long sched_setaffinity(pid_t pid, const struct cpumask *in_mask)$/;"	f
sched_setattr	core.c	/^EXPORT_SYMBOL_GPL(sched_setattr);$/;"	v
sched_setattr	core.c	/^int sched_setattr(struct task_struct *p, const struct sched_attr *attr)$/;"	f
sched_setattr_nocheck	core.c	/^int sched_setattr_nocheck(struct task_struct *p, const struct sched_attr *attr)$/;"	f
sched_setnuma	core.c	/^void sched_setnuma(struct task_struct *p, int nid)$/;"	f
sched_setscheduler	core.c	/^EXPORT_SYMBOL_GPL(sched_setscheduler);$/;"	v
sched_setscheduler	core.c	/^int sched_setscheduler(struct task_struct *p, int policy,$/;"	f
sched_setscheduler_nocheck	core.c	/^EXPORT_SYMBOL_GPL(sched_setscheduler_nocheck);$/;"	v
sched_setscheduler_nocheck	core.c	/^int sched_setscheduler_nocheck(struct task_struct *p, int policy,$/;"	f
sched_show_numa	debug.c	/^static void sched_show_numa(struct task_struct *p, struct seq_file *m)$/;"	f	file:
sched_show_task	core.c	/^EXPORT_SYMBOL_GPL(sched_show_task);$/;"	v
sched_show_task	core.c	/^void sched_show_task(struct task_struct *p)$/;"	f
sched_slice	fair.c	/^static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
sched_smt_present	fair.c	/^DEFINE_STATIC_KEY_FALSE(sched_smt_present);$/;"	v
sched_submit_work	core.c	/^static inline void sched_submit_work(struct task_struct *tsk)$/;"	f	file:
sched_tick_offload_init	core.c	/^int __init sched_tick_offload_init(void)$/;"	f
sched_tick_offload_init	sched.h	/^static inline int sched_tick_offload_init(void) { return 0; }$/;"	f
sched_tick_remote	core.c	/^static void sched_tick_remote(struct work_struct *work)$/;"	f	file:
sched_tick_start	core.c	/^static inline void sched_tick_start(int cpu) { }$/;"	f	file:
sched_tick_start	core.c	/^static void sched_tick_start(int cpu)$/;"	f	file:
sched_tick_stop	core.c	/^static inline void sched_tick_stop(int cpu) { }$/;"	f	file:
sched_tick_stop	core.c	/^static void sched_tick_stop(int cpu)$/;"	f	file:
sched_ttwu_pending	core.c	/^void sched_ttwu_pending(void)$/;"	f
sched_ttwu_pending	sched.h	/^static inline void sched_ttwu_pending(void) { }$/;"	f
sched_tunable_scaling_names	debug.c	/^static const char *sched_tunable_scaling_names[] = {$/;"	v	file:
sched_update_tick_dependency	sched.h	/^static inline void sched_update_tick_dependency(struct rq *rq) { }$/;"	f
sched_update_tick_dependency	sched.h	/^static inline void sched_update_tick_dependency(struct rq *rq)$/;"	f
sched_vslice	fair.c	/^static u64 sched_vslice(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
schedstat_add	stats.h	37;"	d
schedstat_add	stats.h	51;"	d
schedstat_enabled	stats.h	33;"	d
schedstat_enabled	stats.h	47;"	d
schedstat_inc	stats.h	35;"	d
schedstat_inc	stats.h	49;"	d
schedstat_next	stats.c	/^static void *schedstat_next(struct seq_file *file, void *data, loff_t *offset)$/;"	f	file:
schedstat_set	stats.h	39;"	d
schedstat_set	stats.h	53;"	d
schedstat_sops	stats.c	/^static const struct seq_operations schedstat_sops = {$/;"	v	typeref:struct:seq_operations	file:
schedstat_start	stats.c	/^static void *schedstat_start(struct seq_file *file, loff_t *offset)$/;"	f	file:
schedstat_stop	stats.c	/^static void schedstat_stop(struct seq_file *file, void *data)$/;"	f	file:
schedstat_val	stats.h	40;"	d
schedstat_val	stats.h	54;"	d
schedstat_val_or_zero	stats.h	41;"	d
schedstat_val_or_zero	stats.h	55;"	d
schedule	core.c	/^EXPORT_SYMBOL(schedule);$/;"	v
schedule	core.c	/^asmlinkage __visible void __sched schedule(void)$/;"	f
schedule_debug	core.c	/^static inline void schedule_debug(struct task_struct *prev)$/;"	f	file:
schedule_idle	core.c	/^void __sched schedule_idle(void)$/;"	f
schedule_preempt_disabled	core.c	/^void __sched schedule_preempt_disabled(void)$/;"	f
schedule_user	core.c	/^asmlinkage __visible void __sched schedule_user(void)$/;"	f
scheduler_ipi	core.c	/^void scheduler_ipi(void)$/;"	f
scheduler_running	core.c	/^__read_mostly int scheduler_running;$/;"	v
scheduler_tick	core.c	/^void scheduler_tick(void)$/;"	f
schedutil_gov	cpufreq_schedutil.c	/^static struct cpufreq_governor schedutil_gov = {$/;"	v	typeref:struct:cpufreq_governor	file:
schedutil_gov	cpufreq_schedutil.c	/^static struct cpufreq_governor schedutil_gov;$/;"	v	typeref:struct:cpufreq_governor	file:
score_nearby_nodes	fair.c	/^static unsigned long score_nearby_nodes(struct task_struct *p, int nid,$/;"	f	file:
sd	fair.c	/^	struct sched_domain	*sd;$/;"	m	struct:lb_env	typeref:struct:lb_env::sched_domain	file:
sd	sched.h	/^	struct sched_domain	*sd;$/;"	m	struct:rq	typeref:struct:rq::sched_domain
sd	topology.c	/^	struct sched_domain ** __percpu sd;$/;"	m	struct:s_data	typeref:struct:s_data::__percpu	file:
sd_alloc_ctl_cpu_table	debug.c	/^static struct ctl_table *sd_alloc_ctl_cpu_table(int cpu)$/;"	f	file:
sd_alloc_ctl_domain_table	debug.c	/^sd_alloc_ctl_domain_table(struct sched_domain *sd)$/;"	f	file:
sd_alloc_ctl_entry	debug.c	/^static struct ctl_table *sd_alloc_ctl_entry(int n)$/;"	f	file:
sd_ctl_dir	debug.c	/^static struct ctl_table sd_ctl_dir[] = {$/;"	v	typeref:struct:ctl_table	file:
sd_ctl_root	debug.c	/^static struct ctl_table sd_ctl_root[] = {$/;"	v	typeref:struct:ctl_table	file:
sd_degenerate	topology.c	/^static int sd_degenerate(struct sched_domain *sd)$/;"	f	file:
sd_free_ctl_entry	debug.c	/^static void sd_free_ctl_entry(struct ctl_table **tablep)$/;"	f	file:
sd_init	topology.c	/^sd_init(struct sched_domain_topology_level *tl,$/;"	f	file:
sd_lb_stats	fair.c	/^struct sd_lb_stats {$/;"	s	file:
sd_numa_mask	topology.c	/^static const struct cpumask *sd_numa_mask(int cpu)$/;"	f	file:
sd_parent_degenerate	topology.c	/^sd_parent_degenerate(struct sched_domain *sd, struct sched_domain *parent)$/;"	f	file:
sd_sysctl_cpus	debug.c	/^static cpumask_var_t		sd_sysctl_cpus;$/;"	v	file:
sd_sysctl_header	debug.c	/^static struct ctl_table_header	*sd_sysctl_header;$/;"	v	typeref:struct:ctl_table_header	file:
se	sched.h	/^	struct sched_entity	**se;$/;"	m	struct:task_group	typeref:struct:task_group::sched_entity
se_runnable	fair.c	/^static inline long se_runnable(struct sched_entity *se)$/;"	f	file:
se_weight	fair.c	/^static inline long se_weight(struct sched_entity *se)$/;"	f	file:
select_fallback_rq	core.c	/^static int select_fallback_rq(int cpu, struct task_struct *p)$/;"	f	file:
select_idle_core	fair.c	/^static inline int select_idle_core(struct task_struct *p, struct sched_domain *sd, int target)$/;"	f	file:
select_idle_core	fair.c	/^static int select_idle_core(struct task_struct *p, struct sched_domain *sd, int target)$/;"	f	file:
select_idle_cpu	fair.c	/^static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, int target)$/;"	f	file:
select_idle_sibling	fair.c	/^static int select_idle_sibling(struct task_struct *p, int prev, int target)$/;"	f	file:
select_idle_smt	fair.c	/^static inline int select_idle_smt(struct task_struct *p, struct sched_domain *sd, int target)$/;"	f	file:
select_idle_smt	fair.c	/^static int select_idle_smt(struct task_struct *p, struct sched_domain *sd, int target)$/;"	f	file:
select_task_rq	core.c	/^int select_task_rq(struct task_struct *p, int cpu, int sd_flags, int wake_flags)$/;"	f	file:
select_task_rq	sched.h	/^	int  (*select_task_rq)(struct task_struct *p, int task_cpu, int sd_flag, int flags);$/;"	m	struct:sched_class
select_task_rq_dl	deadline.c	/^select_task_rq_dl(struct task_struct *p, int cpu, int sd_flag, int flags)$/;"	f	file:
select_task_rq_fair	fair.c	/^select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_flags)$/;"	f	file:
select_task_rq_idle	idle.c	/^select_task_rq_idle(struct task_struct *p, int cpu, int sd_flag, int flags)$/;"	f	file:
select_task_rq_rt	rt.c	/^select_task_rq_rt(struct task_struct *p, int cpu, int sd_flag, int flags)$/;"	f	file:
select_task_rq_stop	stop_task.c	/^select_task_rq_stop(struct task_struct *p, int cpu, int sd_flag, int flags)$/;"	f	file:
set_cpu_rq_start_time	core.c	/^static void set_cpu_rq_start_time(unsigned int cpu)$/;"	f	file:
set_cpu_sd_state_busy	fair.c	/^static void set_cpu_sd_state_busy(int cpu)$/;"	f	file:
set_cpu_sd_state_idle	fair.c	/^static void set_cpu_sd_state_idle(int cpu)$/;"	f	file:
set_cpus_allowed	sched.h	/^	void (*set_cpus_allowed)(struct task_struct *p,$/;"	m	struct:sched_class
set_cpus_allowed_common	core.c	/^void set_cpus_allowed_common(struct task_struct *p, const struct cpumask *new_mask)$/;"	f
set_cpus_allowed_dl	deadline.c	/^static void set_cpus_allowed_dl(struct task_struct *p,$/;"	f	file:
set_cpus_allowed_ptr	core.c	/^EXPORT_SYMBOL_GPL(set_cpus_allowed_ptr);$/;"	v
set_cpus_allowed_ptr	core.c	/^int set_cpus_allowed_ptr(struct task_struct *p, const struct cpumask *new_mask)$/;"	f
set_curr_task	sched.h	/^	void (*set_curr_task)(struct rq *rq);$/;"	m	struct:sched_class
set_curr_task	sched.h	/^static inline void set_curr_task(struct rq *rq, struct task_struct *curr)$/;"	f
set_curr_task_dl	deadline.c	/^static void set_curr_task_dl(struct rq *rq)$/;"	f	file:
set_curr_task_fair	fair.c	/^static void set_curr_task_fair(struct rq *rq)$/;"	f	file:
set_curr_task_idle	idle.c	/^static void set_curr_task_idle(struct rq *rq)$/;"	f	file:
set_curr_task_rt	rt.c	/^static void set_curr_task_rt(struct rq *rq)$/;"	f	file:
set_curr_task_stop	stop_task.c	/^static void set_curr_task_stop(struct rq *rq)$/;"	f	file:
set_domain_attribute	topology.c	/^static void set_domain_attribute(struct sched_domain *sd,$/;"	f	file:
set_idle_cores	fair.c	/^static inline void set_idle_cores(int cpu, int val)$/;"	f	file:
set_last_buddy	fair.c	/^static void set_last_buddy(struct sched_entity *se)$/;"	f	file:
set_load_weight	core.c	/^static void set_load_weight(struct task_struct *p, bool update_load)$/;"	f	file:
set_next_buddy	fair.c	/^static void set_next_buddy(struct sched_entity *se)$/;"	f	file:
set_next_entity	fair.c	/^set_next_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
set_nr_and_not_polling	core.c	/^static bool set_nr_and_not_polling(struct task_struct *p)$/;"	f	file:
set_nr_if_polling	core.c	/^static bool set_nr_if_polling(struct task_struct *p)$/;"	f	file:
set_numabalancing_state	core.c	/^void set_numabalancing_state(bool enabled)$/;"	f
set_rq_offline	core.c	/^void set_rq_offline(struct rq *rq)$/;"	f
set_rq_online	core.c	/^void set_rq_online(struct rq *rq)$/;"	f
set_sched_topology	topology.c	/^void set_sched_topology(struct sched_domain_topology_level *tl)$/;"	f
set_schedstats	core.c	/^static void set_schedstats(bool enabled)$/;"	f	file:
set_skip_buddy	fair.c	/^static void set_skip_buddy(struct sched_entity *se)$/;"	f	file:
set_table_entry	debug.c	/^set_table_entry(struct ctl_table *entry,$/;"	f	file:
set_task_cpu	core.c	/^void set_task_cpu(struct task_struct *p, unsigned int new_cpu)$/;"	f
set_task_rq	sched.h	/^static inline void set_task_rq(struct task_struct *p, unsigned int cpu) { }$/;"	f
set_task_rq	sched.h	/^static inline void set_task_rq(struct task_struct *p, unsigned int cpu)$/;"	f
set_task_rq_fair	fair.c	/^void set_task_rq_fair(struct sched_entity *se,$/;"	f
set_task_rq_fair	sched.h	/^static inline void set_task_rq_fair(struct sched_entity *se,$/;"	f
set_user_nice	core.c	/^EXPORT_SYMBOL(set_user_nice);$/;"	v
set_user_nice	core.c	/^void set_user_nice(struct task_struct *p, long nice)$/;"	f
setup_autogroup	autogroup.c	/^static int __init setup_autogroup(char *str)$/;"	f	file:
setup_new_dl_entity	deadline.c	/^static inline void setup_new_dl_entity(struct sched_dl_entity *dl_se)$/;"	f	file:
setup_relax_domain_level	topology.c	/^static int __init setup_relax_domain_level(char *str)$/;"	f	file:
setup_schedstats	core.c	/^static int __init setup_schedstats(char *str)$/;"	f	file:
sg_imbalanced	fair.c	/^static inline int sg_imbalanced(struct sched_group *group)$/;"	f	file:
sg_lb_stats	fair.c	/^struct sg_lb_stats {$/;"	s	file:
sg_policy	cpufreq_schedutil.c	/^	struct sugov_policy	*sg_policy;$/;"	m	struct:sugov_cpu	typeref:struct:sugov_cpu::sugov_policy	file:
sgc	sched.h	/^	struct sched_group_capacity *sgc;$/;"	m	struct:sched_group	typeref:struct:sched_group::sched_group_capacity
shares	sched.h	/^	unsigned long		shares;$/;"	m	struct:task_group
should_numa_migrate_memory	fair.c	/^bool should_numa_migrate_memory(struct task_struct *p, struct page * page,$/;"	f
should_we_balance	fair.c	/^static int should_we_balance(struct lb_env *env)$/;"	f	file:
show_numa_stats	fair.c	/^void show_numa_stats(struct task_struct *p, struct seq_file *m)$/;"	f
show_schedstat	stats.c	/^static int show_schedstat(struct seq_file *seq, void *v)$/;"	f	file:
show_state_filter	core.c	/^void show_state_filter(unsigned long state_filter)$/;"	f
siblings	sched.h	/^	struct list_head	siblings;$/;"	m	struct:task_group	typeref:struct:task_group::list_head
single_task_running	core.c	/^EXPORT_SYMBOL(single_task_running);$/;"	v
single_task_running	core.c	/^bool single_task_running(void)$/;"	f
size	cpudeadline.h	/^	int			size;$/;"	m	struct:cpudl
skip	sched.h	/^	struct sched_entity	*skip;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::sched_entity
skip_blocked_update	fair.c	/^static inline bool skip_blocked_update(struct sched_entity *se)$/;"	f	file:
slack_timer	sched.h	/^	struct hrtimer		slack_timer;$/;"	m	struct:cfs_bandwidth	typeref:struct:cfs_bandwidth::hrtimer
source_load	fair.c	/^static unsigned long source_load(int cpu, int type)$/;"	f	file:
span	sched.h	/^	cpumask_var_t		span;$/;"	m	struct:root_domain
src_cpu	core.c	/^	int src_cpu, dst_cpu;$/;"	m	struct:migration_swap_arg	file:
src_cpu	fair.c	/^	int			src_cpu;$/;"	m	struct:lb_env	file:
src_cpu	fair.c	/^	int src_cpu, src_nid;$/;"	m	struct:task_numa_env	file:
src_nid	fair.c	/^	int src_cpu, src_nid;$/;"	m	struct:task_numa_env	file:
src_rq	fair.c	/^	struct rq		*src_rq;$/;"	m	struct:lb_env	typeref:struct:lb_env::rq	file:
src_stats	fair.c	/^	struct numa_stats src_stats, dst_stats;$/;"	m	struct:task_numa_env	typeref:struct:task_numa_env::numa_stats	file:
src_task	core.c	/^	struct task_struct *src_task, *dst_task;$/;"	m	struct:migration_swap_arg	typeref:struct:migration_swap_arg::task_struct	file:
start_cfs_bandwidth	fair.c	/^void start_cfs_bandwidth(struct cfs_bandwidth *cfs_b)$/;"	f
start_cfs_slack_bandwidth	fair.c	/^static void start_cfs_slack_bandwidth(struct cfs_bandwidth *cfs_b)$/;"	f	file:
start_dl_timer	deadline.c	/^static int start_dl_timer(struct task_struct *p)$/;"	f	file:
start_hrtick_dl	deadline.c	/^static void start_hrtick_dl(struct rq *rq, struct task_struct *p)$/;"	f	file:
start_rt_bandwidth	rt.c	/^static void start_rt_bandwidth(struct rt_bandwidth *rt_b)$/;"	f	file:
state_filter_match	core.c	/^state_filter_match(unsigned long state_filter, struct task_struct *p)$/;"	f	file:
steal_account_process_time	cputime.c	/^static __always_inline u64 steal_account_process_time(u64 maxtime)$/;"	f	file:
stop	sched.h	/^	struct task_struct	*stop;$/;"	m	struct:rq	typeref:struct:rq::task_struct
stop_sched_class	stop_task.c	/^const struct sched_class stop_sched_class = {$/;"	v	typeref:struct:sched_class
sub_nr_running	sched.h	/^static inline void sub_nr_running(struct rq *rq, unsigned count)$/;"	f
sub_positive	fair.c	2743;"	d	file:
sub_rq_bw	deadline.c	/^void sub_rq_bw(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
sub_running_bw	deadline.c	/^void sub_running_bw(struct sched_dl_entity *dl_se, struct dl_rq *dl_rq)$/;"	f	file:
sugov_aggregate_util	cpufreq_schedutil.c	/^static unsigned long sugov_aggregate_util(struct sugov_cpu *sg_cpu)$/;"	f	file:
sugov_attributes	cpufreq_schedutil.c	/^static struct attribute *sugov_attributes[] = {$/;"	v	typeref:struct:attribute	file:
sugov_cpu	cpufreq_schedutil.c	/^struct sugov_cpu {$/;"	s	file:
sugov_cpu_is_busy	cpufreq_schedutil.c	/^static bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu)$/;"	f	file:
sugov_cpu_is_busy	cpufreq_schedutil.c	/^static inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }$/;"	f	file:
sugov_deferred_update	cpufreq_schedutil.c	/^static void sugov_deferred_update(struct sugov_policy *sg_policy, u64 time,$/;"	f	file:
sugov_exit	cpufreq_schedutil.c	/^static void sugov_exit(struct cpufreq_policy *policy)$/;"	f	file:
sugov_fast_switch	cpufreq_schedutil.c	/^static void sugov_fast_switch(struct sugov_policy *sg_policy, u64 time,$/;"	f	file:
sugov_get_util	cpufreq_schedutil.c	/^static void sugov_get_util(struct sugov_cpu *sg_cpu)$/;"	f	file:
sugov_init	cpufreq_schedutil.c	/^static int sugov_init(struct cpufreq_policy *policy)$/;"	f	file:
sugov_iowait_apply	cpufreq_schedutil.c	/^static void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time,$/;"	f	file:
sugov_iowait_boost	cpufreq_schedutil.c	/^static void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,$/;"	f	file:
sugov_iowait_reset	cpufreq_schedutil.c	/^static bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,$/;"	f	file:
sugov_irq_work	cpufreq_schedutil.c	/^static void sugov_irq_work(struct irq_work *irq_work)$/;"	f	file:
sugov_kthread_create	cpufreq_schedutil.c	/^static int sugov_kthread_create(struct sugov_policy *sg_policy)$/;"	f	file:
sugov_kthread_stop	cpufreq_schedutil.c	/^static void sugov_kthread_stop(struct sugov_policy *sg_policy)$/;"	f	file:
sugov_limits	cpufreq_schedutil.c	/^static void sugov_limits(struct cpufreq_policy *policy)$/;"	f	file:
sugov_next_freq_shared	cpufreq_schedutil.c	/^static unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)$/;"	f	file:
sugov_policy	cpufreq_schedutil.c	/^struct sugov_policy {$/;"	s	file:
sugov_policy_alloc	cpufreq_schedutil.c	/^static struct sugov_policy *sugov_policy_alloc(struct cpufreq_policy *policy)$/;"	f	file:
sugov_policy_free	cpufreq_schedutil.c	/^static void sugov_policy_free(struct sugov_policy *sg_policy)$/;"	f	file:
sugov_register	cpufreq_schedutil.c	/^fs_initcall(sugov_register);$/;"	v
sugov_register	cpufreq_schedutil.c	/^static int __init sugov_register(void)$/;"	f	file:
sugov_should_update_freq	cpufreq_schedutil.c	/^static bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)$/;"	f	file:
sugov_start	cpufreq_schedutil.c	/^static int sugov_start(struct cpufreq_policy *policy)$/;"	f	file:
sugov_stop	cpufreq_schedutil.c	/^static void sugov_stop(struct cpufreq_policy *policy)$/;"	f	file:
sugov_tunables	cpufreq_schedutil.c	/^struct sugov_tunables {$/;"	s	file:
sugov_tunables_alloc	cpufreq_schedutil.c	/^static struct sugov_tunables *sugov_tunables_alloc(struct sugov_policy *sg_policy)$/;"	f	file:
sugov_tunables_free	cpufreq_schedutil.c	/^static void sugov_tunables_free(struct sugov_tunables *tunables)$/;"	f	file:
sugov_tunables_ktype	cpufreq_schedutil.c	/^static struct kobj_type sugov_tunables_ktype = {$/;"	v	typeref:struct:kobj_type	file:
sugov_update_next_freq	cpufreq_schedutil.c	/^static bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,$/;"	f	file:
sugov_update_shared	cpufreq_schedutil.c	/^sugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)$/;"	f	file:
sugov_update_single	cpufreq_schedutil.c	/^static void sugov_update_single(struct update_util_data *hook, u64 time,$/;"	f	file:
sugov_work	cpufreq_schedutil.c	/^static void sugov_work(struct kthread_work *work)$/;"	f	file:
sum_nr_running	fair.c	/^	unsigned int sum_nr_running; \/* Nr tasks running in the group *\/$/;"	m	struct:sg_lb_stats	file:
sum_weighted_load	fair.c	/^	unsigned long sum_weighted_load; \/* Weighted load of group's tasks *\/$/;"	m	struct:sg_lb_stats	file:
swake_up	swait.c	/^EXPORT_SYMBOL(swake_up);$/;"	v
swake_up	swait.c	/^void swake_up(struct swait_queue_head *q)$/;"	f
swake_up_all	swait.c	/^EXPORT_SYMBOL(swake_up_all);$/;"	v
swake_up_all	swait.c	/^void swake_up_all(struct swait_queue_head *q)$/;"	f
swake_up_locked	swait.c	/^EXPORT_SYMBOL(swake_up_locked);$/;"	v
swake_up_locked	swait.c	/^void swake_up_locked(struct swait_queue_head *q)$/;"	f
switched_from	sched.h	/^	void (*switched_from)(struct rq *this_rq, struct task_struct *task);$/;"	m	struct:sched_class
switched_from_dl	deadline.c	/^static void switched_from_dl(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_from_fair	fair.c	/^static void switched_from_fair(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_from_rt	rt.c	/^static void switched_from_rt(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_to	sched.h	/^	void (*switched_to)  (struct rq *this_rq, struct task_struct *task);$/;"	m	struct:sched_class
switched_to_dl	deadline.c	/^static void switched_to_dl(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_to_fair	fair.c	/^static void switched_to_fair(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_to_idle	idle.c	/^static void switched_to_idle(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_to_rt	rt.c	/^static void switched_to_rt(struct rq *rq, struct task_struct *p)$/;"	f	file:
switched_to_stop	stop_task.c	/^static void switched_to_stop(struct rq *rq, struct task_struct *p)$/;"	f	file:
sync	sched.h	/^	struct u64_stats_sync	sync;$/;"	m	struct:irqtime	typeref:struct:irqtime::u64_stats_sync
sync_entity_load_avg	fair.c	/^void sync_entity_load_avg(struct sched_entity *se)$/;"	f
sync_throttle	fair.c	/^static inline void sync_throttle(struct task_group *tg, int cpu) {}$/;"	f	file:
sync_throttle	fair.c	/^static void sync_throttle(struct task_group *tg, int cpu)$/;"	f	file:
sysctl_numa_balancing	core.c	/^int sysctl_numa_balancing(struct ctl_table *table, int write,$/;"	f
sysctl_numa_balancing_scan_delay	fair.c	/^unsigned int sysctl_numa_balancing_scan_delay = 1000;$/;"	v
sysctl_numa_balancing_scan_period_max	fair.c	/^unsigned int sysctl_numa_balancing_scan_period_max = 60000;$/;"	v
sysctl_numa_balancing_scan_period_min	fair.c	/^unsigned int sysctl_numa_balancing_scan_period_min = 1000;$/;"	v
sysctl_numa_balancing_scan_size	fair.c	/^unsigned int sysctl_numa_balancing_scan_size = 256;$/;"	v
sysctl_sched_autogroup_enabled	autogroup.c	/^unsigned int __read_mostly sysctl_sched_autogroup_enabled = 1;$/;"	v
sysctl_sched_cfs_bandwidth_slice	fair.c	/^unsigned int sysctl_sched_cfs_bandwidth_slice		= 5000UL;$/;"	v
sysctl_sched_features	core.c	/^const_debug unsigned int sysctl_sched_features =$/;"	v
sysctl_sched_features	sched.h	/^static const_debug __maybe_unused unsigned int sysctl_sched_features =$/;"	v
sysctl_sched_latency	fair.c	/^unsigned int sysctl_sched_latency			= 6000000ULL;$/;"	v
sysctl_sched_migration_cost	fair.c	/^const_debug unsigned int sysctl_sched_migration_cost	= 500000UL;$/;"	v
sysctl_sched_min_granularity	fair.c	/^unsigned int sysctl_sched_min_granularity		= 750000ULL;$/;"	v
sysctl_sched_nr_migrate	core.c	/^const_debug unsigned int sysctl_sched_nr_migrate = 32;$/;"	v
sysctl_sched_rr_timeslice	rt.c	/^int sysctl_sched_rr_timeslice = (MSEC_PER_SEC \/ HZ) * RR_TIMESLICE;$/;"	v
sysctl_sched_rt_period	core.c	/^unsigned int sysctl_sched_rt_period = 1000000;$/;"	v
sysctl_sched_rt_runtime	core.c	/^int sysctl_sched_rt_runtime = 950000;$/;"	v
sysctl_sched_time_avg	core.c	/^const_debug unsigned int sysctl_sched_time_avg = MSEC_PER_SEC;$/;"	v
sysctl_sched_tunable_scaling	fair.c	/^enum sched_tunable_scaling sysctl_sched_tunable_scaling = SCHED_TUNABLESCALING_LOG;$/;"	v	typeref:enum:sched_tunable_scaling
sysctl_sched_wakeup_granularity	fair.c	/^unsigned int sysctl_sched_wakeup_granularity		= 1000000UL;$/;"	v
sysctl_schedstats	core.c	/^int sysctl_schedstats(struct ctl_table *table, int write,$/;"	f
sysrq_sched_debug_show	debug.c	/^void sysrq_sched_debug_show(void)$/;"	f
target_load	fair.c	/^static unsigned long target_load(int cpu, int type)$/;"	f	file:
task	core.c	/^	struct task_struct *task;$/;"	m	struct:migration_arg	typeref:struct:migration_arg::task_struct	file:
task_ca	cpuacct.c	/^static inline struct cpuacct *task_ca(struct task_struct *tsk)$/;"	f	file:
task_can_attach	core.c	/^int task_can_attach(struct task_struct *p,$/;"	f
task_capacity	fair.c	/^	unsigned long task_capacity;$/;"	m	struct:numa_stats	file:
task_cfs_rq	fair.c	/^static inline struct cfs_rq *task_cfs_rq(struct task_struct *p)$/;"	f	file:
task_change_group	sched.h	/^	void (*task_change_group)(struct task_struct *p, int type);$/;"	m	struct:sched_class
task_change_group_fair	fair.c	/^static void task_change_group_fair(struct task_struct *p, int type)$/;"	f	file:
task_contending	deadline.c	/^static void task_contending(struct sched_dl_entity *dl_se, int flags)$/;"	f	file:
task_cputime	cputime.c	/^void task_cputime(struct task_struct *t, u64 *utime, u64 *stime)$/;"	f
task_cputime_adjusted	cputime.c	/^EXPORT_SYMBOL_GPL(task_cputime_adjusted);$/;"	v
task_cputime_adjusted	cputime.c	/^void task_cputime_adjusted(struct task_struct *p, u64 *ut, u64 *st)$/;"	f
task_curr	core.c	/^inline int task_curr(const struct task_struct *p)$/;"	f
task_current	sched.h	/^static inline int task_current(struct rq *rq, struct task_struct *p)$/;"	f
task_dead	sched.h	/^	void (*task_dead)(struct task_struct *p);$/;"	m	struct:sched_class
task_dead_fair	fair.c	/^static void task_dead_fair(struct task_struct *p)$/;"	f	file:
task_faults	fair.c	/^static inline unsigned long task_faults(struct task_struct *p, int nid)$/;"	f	file:
task_faults_idx	fair.c	/^static inline int task_faults_idx(enum numa_faults_stats s, int nid, int priv)$/;"	f	file:
task_fork	sched.h	/^	void (*task_fork)(struct task_struct *p);$/;"	m	struct:sched_class
task_fork_dl	deadline.c	/^static void task_fork_dl(struct task_struct *p)$/;"	f	file:
task_fork_fair	fair.c	/^static void task_fork_fair(struct task_struct *p)$/;"	f	file:
task_group	sched.h	/^static inline struct task_group *task_group(struct task_struct *p)$/;"	f
task_group	sched.h	/^struct task_group {$/;"	s
task_group_account_field	cputime.c	/^static inline void task_group_account_field(struct task_struct *p, int index,$/;"	f	file:
task_group_is_autogroup	autogroup.h	/^static inline bool task_group_is_autogroup(struct task_group *tg)$/;"	f
task_group_path	debug.c	/^static char *task_group_path(struct task_group *tg)$/;"	f	file:
task_groups	core.c	/^LIST_HEAD(task_groups);$/;"	v
task_gtime	cputime.c	/^u64 task_gtime(struct task_struct *t)$/;"	f
task_h_load	fair.c	/^static unsigned long task_h_load(struct task_struct *p)$/;"	f	file:
task_has_dl_policy	sched.h	/^static inline int task_has_dl_policy(struct task_struct *p)$/;"	f
task_has_rt_policy	sched.h	/^static inline int task_has_rt_policy(struct task_struct *p)$/;"	f
task_hot	fair.c	/^static int task_hot(struct task_struct *p, struct lb_env *env)$/;"	f	file:
task_move_group_fair	fair.c	/^static void task_move_group_fair(struct task_struct *p)$/;"	f	file:
task_non_contending	deadline.c	/^static void task_non_contending(struct task_struct *p)$/;"	f	file:
task_nr_scan_windows	fair.c	/^static unsigned int task_nr_scan_windows(struct task_struct *p)$/;"	f	file:
task_numa_assign	fair.c	/^static void task_numa_assign(struct task_numa_env *env,$/;"	f	file:
task_numa_compare	fair.c	/^static void task_numa_compare(struct task_numa_env *env,$/;"	f	file:
task_numa_env	fair.c	/^struct task_numa_env {$/;"	s	file:
task_numa_fault	fair.c	/^void task_numa_fault(int last_cpupid, int mem_node, int pages, int flags)$/;"	f
task_numa_find_cpu	fair.c	/^static void task_numa_find_cpu(struct task_numa_env *env,$/;"	f	file:
task_numa_free	fair.c	/^void task_numa_free(struct task_struct *p)$/;"	f
task_numa_group	fair.c	/^static void task_numa_group(struct task_struct *p, int cpupid, int flags,$/;"	f	file:
task_numa_group_id	fair.c	/^pid_t task_numa_group_id(struct task_struct *p)$/;"	f
task_numa_migrate	fair.c	/^static int task_numa_migrate(struct task_struct *p)$/;"	f	file:
task_numa_placement	fair.c	/^static void task_numa_placement(struct task_struct *p)$/;"	f	file:
task_numa_work	fair.c	/^void task_numa_work(struct callback_head *work)$/;"	f
task_of	fair.c	/^static inline struct task_struct *task_of(struct sched_entity *se)$/;"	f	file:
task_on_rq_migrating	sched.h	/^static inline int task_on_rq_migrating(struct task_struct *p)$/;"	f
task_on_rq_queued	sched.h	/^static inline int task_on_rq_queued(struct task_struct *p)$/;"	f
task_prio	core.c	/^int task_prio(const struct task_struct *p)$/;"	f
task_rq	sched.h	927;"	d
task_running	sched.h	/^static inline int task_running(struct rq *rq, struct task_struct *p)$/;"	f
task_scan_max	fair.c	/^static unsigned int task_scan_max(struct task_struct *p)$/;"	f	file:
task_scan_min	fair.c	/^static unsigned int task_scan_min(struct task_struct *p)$/;"	f	file:
task_scan_start	fair.c	/^static unsigned int task_scan_start(struct task_struct *p)$/;"	f	file:
task_sched_runtime	core.c	/^unsigned long long task_sched_runtime(struct task_struct *p)$/;"	f
task_set_group_fair	fair.c	/^static void task_set_group_fair(struct task_struct *p)$/;"	f	file:
task_tick	sched.h	/^	void (*task_tick)(struct rq *rq, struct task_struct *p, int queued);$/;"	m	struct:sched_class
task_tick_dl	deadline.c	/^static void task_tick_dl(struct rq *rq, struct task_struct *p, int queued)$/;"	f	file:
task_tick_fair	fair.c	/^static void task_tick_fair(struct rq *rq, struct task_struct *curr, int queued)$/;"	f	file:
task_tick_idle	idle.c	/^static void task_tick_idle(struct rq *rq, struct task_struct *curr, int queued)$/;"	f	file:
task_tick_numa	fair.c	/^static void task_tick_numa(struct rq *rq, struct task_struct *curr)$/;"	f	file:
task_tick_numa	fair.c	/^void task_tick_numa(struct rq *rq, struct task_struct *curr)$/;"	f
task_tick_rt	rt.c	/^static void task_tick_rt(struct rq *rq, struct task_struct *p, int queued)$/;"	f	file:
task_tick_stop	stop_task.c	/^static void task_tick_stop(struct rq *rq, struct task_struct *curr, int queued)$/;"	f	file:
task_util	fair.c	/^static inline unsigned long task_util(struct task_struct *p)$/;"	f	file:
task_util_est	fair.c	/^static inline unsigned long task_util_est(struct task_struct *p)$/;"	f	file:
task_wants_autogroup	autogroup.c	/^bool task_wants_autogroup(struct task_struct *p, struct task_group *tg)$/;"	f
task_weight	fair.c	/^static inline unsigned long task_weight(struct task_struct *p, int nid,$/;"	f	file:
task_woken	sched.h	/^	void (*task_woken)(struct rq *this_rq, struct task_struct *task);$/;"	m	struct:sched_class
task_woken_dl	deadline.c	/^static void task_woken_dl(struct rq *rq, struct task_struct *p)$/;"	f	file:
task_woken_rt	rt.c	/^static void task_woken_rt(struct rq *rq, struct task_struct *p)$/;"	f	file:
tasks	fair.c	/^	struct list_head	tasks;$/;"	m	struct:lb_env	typeref:struct:lb_env::list_head	file:
tasks_timeline	sched.h	/^	struct rb_root_cached	tasks_timeline;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::rb_root_cached
tell_cpu_to_push	rt.c	/^static void tell_cpu_to_push(struct rq *rq)$/;"	f	file:
test_idle_cores	fair.c	/^static inline bool test_idle_cores(int cpu, bool def)$/;"	f	file:
tg	autogroup.h	/^	struct task_group	*tg;$/;"	m	struct:autogroup	typeref:struct:autogroup::task_group
tg	core.c	/^	struct task_group *tg;$/;"	m	struct:cfs_schedulable_data	typeref:struct:cfs_schedulable_data::task_group	file:
tg	rt.c	/^	struct task_group *tg;$/;"	m	struct:rt_schedulable_data	typeref:struct:rt_schedulable_data::task_group	file:
tg	sched.h	/^	struct task_group	*tg;	\/* group that "owns" this runqueue *\/$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::task_group
tg	sched.h	/^	struct task_group	*tg;$/;"	m	struct:rt_rq	typeref:struct:rt_rq::task_group
tg_cfs_bandwidth	fair.c	/^static inline struct cfs_bandwidth *tg_cfs_bandwidth(struct task_group *tg)$/;"	f	file:
tg_cfs_schedulable_down	core.c	/^static int tg_cfs_schedulable_down(struct task_group *tg, void *data)$/;"	f	file:
tg_get_cfs_period	core.c	/^long tg_get_cfs_period(struct task_group *tg)$/;"	f
tg_get_cfs_quota	core.c	/^long tg_get_cfs_quota(struct task_group *tg)$/;"	f
tg_has_rt_tasks	rt.c	/^static inline int tg_has_rt_tasks(struct task_group *tg)$/;"	f	file:
tg_load_avg_contrib	sched.h	/^	unsigned long		tg_load_avg_contrib;$/;"	m	struct:cfs_rq
tg_nop	core.c	/^int tg_nop(struct task_group *tg, void *data)$/;"	f
tg_rt_schedulable	rt.c	/^static int tg_rt_schedulable(struct task_group *tg, void *data)$/;"	f	file:
tg_set_cfs_bandwidth	core.c	/^static int tg_set_cfs_bandwidth(struct task_group *tg, u64 period, u64 quota)$/;"	f	file:
tg_set_cfs_period	core.c	/^int tg_set_cfs_period(struct task_group *tg, long cfs_period_us)$/;"	f
tg_set_cfs_quota	core.c	/^int tg_set_cfs_quota(struct task_group *tg, long cfs_quota_us)$/;"	f
tg_set_rt_bandwidth	rt.c	/^static int tg_set_rt_bandwidth(struct task_group *tg,$/;"	f	file:
tg_throttle_down	fair.c	/^static int tg_throttle_down(struct task_group *tg, void *data)$/;"	f	file:
tg_unthrottle_up	fair.c	/^static int tg_unthrottle_up(struct task_group *tg, void *data)$/;"	f	file:
tg_visitor	sched.h	/^typedef int (*tg_visitor)(struct task_group *, void *);$/;"	t
this_bw	sched.h	/^	u64			this_bw;$/;"	m	struct:dl_rq
this_rq	sched.h	926;"	d
this_scd	clock.c	/^static inline struct sched_clock_data *this_scd(void)$/;"	f	file:
thread	cpufreq_schedutil.c	/^	struct task_struct	*thread;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::task_struct	file:
thread_group_cputime	cputime.c	/^void thread_group_cputime(struct task_struct *tsk, struct task_cputime *times)$/;"	f
thread_group_cputime_adjusted	cputime.c	/^void thread_group_cputime_adjusted(struct task_struct *p, u64 *ut, u64 *st)$/;"	f
throttle_cfs_rq	fair.c	/^static void throttle_cfs_rq(struct cfs_rq *cfs_rq)$/;"	f	file:
throttle_count	sched.h	/^	int			throttle_count;$/;"	m	struct:cfs_rq
throttled	sched.h	/^	int			throttled;$/;"	m	struct:cfs_rq
throttled_cfs_rq	sched.h	/^	struct list_head	throttled_cfs_rq;$/;"	m	struct:cfs_bandwidth	typeref:struct:cfs_bandwidth::list_head
throttled_clock	sched.h	/^	u64			throttled_clock;$/;"	m	struct:cfs_rq
throttled_clock_task	sched.h	/^	u64			throttled_clock_task;$/;"	m	struct:cfs_rq
throttled_clock_task_time	sched.h	/^	u64			throttled_clock_task_time;$/;"	m	struct:cfs_rq
throttled_hierarchy	fair.c	/^static inline int throttled_hierarchy(struct cfs_rq *cfs_rq)$/;"	f	file:
throttled_lb_pair	fair.c	/^static inline int throttled_lb_pair(struct task_group *tg,$/;"	f	file:
throttled_list	sched.h	/^	struct list_head	throttled_list;$/;"	m	struct:cfs_rq	typeref:struct:cfs_rq::list_head
throttled_time	sched.h	/^	u64			throttled_time;$/;"	m	struct:cfs_bandwidth
tick_delta	sched.h	/^	u64			tick_delta;$/;"	m	struct:irqtime
tick_gtod	clock.c	/^	u64			tick_gtod;$/;"	m	struct:sched_clock_data	file:
tick_raw	clock.c	/^	u64			tick_raw;$/;"	m	struct:sched_clock_data	file:
tick_work	core.c	/^struct tick_work {$/;"	s	file:
tick_work_cpu	core.c	/^static struct tick_work __percpu *tick_work_cpu;$/;"	v	typeref:struct:__percpu	file:
timer	idle.c	/^	struct hrtimer timer;$/;"	m	struct:idle_timer	typeref:struct:idle_timer::hrtimer	file:
tmp_alone_branch	sched.h	/^	struct list_head	*tmp_alone_branch;$/;"	m	struct:rq	typeref:struct:rq::list_head
to_ratio	core.c	/^unsigned long to_ratio(u64 period, u64 runtime)$/;"	f
to_sugov_tunables	cpufreq_schedutil.c	/^static inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)$/;"	f	file:
total	sched.h	/^	u64			total;$/;"	m	struct:irqtime
total_bw	sched.h	/^	u64			total_bw;$/;"	m	struct:dl_bw
total_capacity	fair.c	/^	unsigned long total_capacity;	\/* Total capacity of all groups in sd *\/$/;"	m	struct:sd_lb_stats	file:
total_faults	fair.c	/^	unsigned long total_faults;$/;"	m	struct:numa_group	file:
total_load	fair.c	/^	unsigned long total_load;	\/* Total load of all groups in sd *\/$/;"	m	struct:sd_lb_stats	file:
total_running	fair.c	/^	unsigned long total_running;$/;"	m	struct:sd_lb_stats	file:
trigger_load_balance	fair.c	/^void trigger_load_balance(struct rq *rq)$/;"	f
try_to_wake_up	core.c	/^try_to_wake_up(struct task_struct *p, unsigned int state, int wake_flags)$/;"	f	file:
try_to_wake_up_local	core.c	/^static void try_to_wake_up_local(struct task_struct *p, struct rq_flags *rf)$/;"	f	file:
try_wait_for_completion	completion.c	/^EXPORT_SYMBOL(try_wait_for_completion);$/;"	v
try_wait_for_completion	completion.c	/^bool try_wait_for_completion(struct completion *x)$/;"	f
ttwu_activate	core.c	/^static inline void ttwu_activate(struct rq *rq, struct task_struct *p, int en_flags)$/;"	f	file:
ttwu_count	sched.h	/^	unsigned int		ttwu_count;$/;"	m	struct:rq
ttwu_do_activate	core.c	/^ttwu_do_activate(struct rq *rq, struct task_struct *p, int wake_flags,$/;"	f	file:
ttwu_do_wakeup	core.c	/^static void ttwu_do_wakeup(struct rq *rq, struct task_struct *p, int wake_flags,$/;"	f	file:
ttwu_local	sched.h	/^	unsigned int		ttwu_local;$/;"	m	struct:rq
ttwu_queue	core.c	/^static void ttwu_queue(struct task_struct *p, int cpu, int wake_flags)$/;"	f	file:
ttwu_queue_remote	core.c	/^static void ttwu_queue_remote(struct task_struct *p, int cpu, int wake_flags)$/;"	f	file:
ttwu_remote	core.c	/^static int ttwu_remote(struct task_struct *p, int wake_flags)$/;"	f	file:
ttwu_stat	core.c	/^ttwu_stat(struct task_struct *p, int cpu, int wake_flags)$/;"	f	file:
tunables	cpufreq_schedutil.c	/^	struct sugov_tunables	*tunables;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::sugov_tunables	file:
tunables_hook	cpufreq_schedutil.c	/^	struct list_head	tunables_hook;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::list_head	file:
unregister_fair_sched_group	fair.c	/^void unregister_fair_sched_group(struct task_group *tg) { }$/;"	f
unregister_fair_sched_group	fair.c	/^void unregister_fair_sched_group(struct task_group *tg)$/;"	f
unregister_sched_domain_sysctl	debug.c	/^void unregister_sched_domain_sysctl(void)$/;"	f
unregister_sched_domain_sysctl	sched.h	/^static inline void unregister_sched_domain_sysctl(void)$/;"	f
unthrottle_cfs_rq	fair.c	/^void unthrottle_cfs_rq(struct cfs_rq *cfs_rq)$/;"	f
unthrottle_offline_cfs_rqs	fair.c	/^static inline void unthrottle_offline_cfs_rqs(struct rq *rq) {}$/;"	f	file:
unthrottle_offline_cfs_rqs	fair.c	/^static void __maybe_unused unthrottle_offline_cfs_rqs(struct rq *rq)$/;"	f	file:
update_avg	core.c	/^static void update_avg(u64 *avg, u64 sample)$/;"	f	file:
update_blocked_averages	fair.c	/^static inline void update_blocked_averages(int cpu)$/;"	f	file:
update_blocked_averages	fair.c	/^static void update_blocked_averages(int cpu)$/;"	f	file:
update_cfs_group	fair.c	/^static inline void update_cfs_group(struct sched_entity *se)$/;"	f	file:
update_cfs_group	fair.c	/^static void update_cfs_group(struct sched_entity *se)$/;"	f	file:
update_cfs_rq_h_load	fair.c	/^static void update_cfs_rq_h_load(struct cfs_rq *cfs_rq)$/;"	f	file:
update_cfs_rq_load_avg	fair.c	/^update_cfs_rq_load_avg(u64 now, struct cfs_rq *cfs_rq)$/;"	f	file:
update_cpu_capacity	fair.c	/^static void update_cpu_capacity(struct sched_domain *sd, int cpu)$/;"	f	file:
update_curr	fair.c	/^static void update_curr(struct cfs_rq *cfs_rq)$/;"	f	file:
update_curr	sched.h	/^	void (*update_curr)(struct rq *rq);$/;"	m	struct:sched_class
update_curr_dl	deadline.c	/^static void update_curr_dl(struct rq *rq)$/;"	f	file:
update_curr_fair	fair.c	/^static void update_curr_fair(struct rq *rq)$/;"	f	file:
update_curr_idle	idle.c	/^static void update_curr_idle(struct rq *rq)$/;"	f	file:
update_curr_rt	rt.c	/^static void update_curr_rt(struct rq *rq)$/;"	f	file:
update_curr_stop	stop_task.c	/^static void update_curr_stop(struct rq *rq)$/;"	f	file:
update_dl_entity	deadline.c	/^static void update_dl_entity(struct sched_dl_entity *dl_se,$/;"	f	file:
update_dl_migration	deadline.c	/^static void update_dl_migration(struct dl_rq *dl_rq)$/;"	f	file:
update_dl_revised_wakeup	deadline.c	/^update_dl_revised_wakeup(struct sched_dl_entity *dl_se, struct rq *rq)$/;"	f	file:
update_group_capacity	fair.c	/^void update_group_capacity(struct sched_domain *sd, int cpu)$/;"	f
update_idle_core	sched.h	/^static inline void update_idle_core(struct rq *rq) { }$/;"	f
update_idle_core	sched.h	/^static inline void update_idle_core(struct rq *rq)$/;"	f
update_load_add	fair.c	/^static inline void update_load_add(struct load_weight *lw, unsigned long inc)$/;"	f	file:
update_load_avg	fair.c	/^static inline void update_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)$/;"	f	file:
update_load_avg	fair.c	/^static inline void update_load_avg(struct cfs_rq *cfs_rq, struct sched_entity *se, int not_used1)$/;"	f	file:
update_load_set	fair.c	/^static inline void update_load_set(struct load_weight *lw, unsigned long w)$/;"	f	file:
update_load_sub	fair.c	/^static inline void update_load_sub(struct load_weight *lw, unsigned long dec)$/;"	f	file:
update_lock	cpufreq_schedutil.c	/^	raw_spinlock_t		update_lock;	\/* For shared policies *\/$/;"	m	struct:sugov_policy	file:
update_max_interval	fair.c	/^void update_max_interval(void)$/;"	f
update_min_vruntime	fair.c	/^static void update_min_vruntime(struct cfs_rq *cfs_rq)$/;"	f	file:
update_next_balance	fair.c	/^update_next_balance(struct sched_domain *sd, unsigned long *next_balance)$/;"	f	file:
update_nohz_stats	fair.c	/^static bool update_nohz_stats(struct rq *rq, bool force)$/;"	f	file:
update_numa_stats	fair.c	/^static void update_numa_stats(struct numa_stats *ns, int nid)$/;"	f	file:
update_rq_clock	core.c	/^void update_rq_clock(struct rq *rq)$/;"	f
update_rq_clock_task	core.c	/^static void update_rq_clock_task(struct rq *rq, s64 delta)$/;"	f	file:
update_rt_migration	rt.c	/^static void update_rt_migration(struct rt_rq *rt_rq)$/;"	f	file:
update_runtime_enabled	fair.c	/^static inline void update_runtime_enabled(struct rq *rq) {}$/;"	f	file:
update_runtime_enabled	fair.c	/^static void __maybe_unused update_runtime_enabled(struct rq *rq)$/;"	f	file:
update_sd_lb_stats	fair.c	/^static inline void update_sd_lb_stats(struct lb_env *env, struct sd_lb_stats *sds)$/;"	f	file:
update_sd_pick_busiest	fair.c	/^static bool update_sd_pick_busiest(struct lb_env *env,$/;"	f	file:
update_sg_lb_stats	fair.c	/^static inline void update_sg_lb_stats(struct lb_env *env,$/;"	f	file:
update_stats_curr_start	fair.c	/^update_stats_curr_start(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
update_stats_dequeue	fair.c	/^update_stats_dequeue(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)$/;"	f	file:
update_stats_enqueue	fair.c	/^update_stats_enqueue(struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)$/;"	f	file:
update_stats_enqueue_sleeper	fair.c	/^update_stats_enqueue_sleeper(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
update_stats_wait_end	fair.c	/^update_stats_wait_end(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
update_stats_wait_start	fair.c	/^update_stats_wait_start(struct cfs_rq *cfs_rq, struct sched_entity *se)$/;"	f	file:
update_sysctl	fair.c	/^static void update_sysctl(void)$/;"	f	file:
update_task_scan_period	fair.c	/^static void update_task_scan_period(struct task_struct *p,$/;"	f	file:
update_tg_cfs_runnable	fair.c	/^update_tg_cfs_runnable(struct cfs_rq *cfs_rq, struct sched_entity *se, struct cfs_rq *gcfs_rq)$/;"	f	file:
update_tg_cfs_util	fair.c	/^update_tg_cfs_util(struct cfs_rq *cfs_rq, struct sched_entity *se, struct cfs_rq *gcfs_rq)$/;"	f	file:
update_tg_load_avg	fair.c	/^static inline void update_tg_load_avg(struct cfs_rq *cfs_rq, int force) {}$/;"	f	file:
update_tg_load_avg	fair.c	/^static inline void update_tg_load_avg(struct cfs_rq *cfs_rq, int force)$/;"	f	file:
update_tg_load_avg	fair.c	/^static void update_tg_load_avg(struct cfs_rq *cfs_rq, int force)$/;"	f	file:
update_top_cache_domain	topology.c	/^static void update_top_cache_domain(int cpu)$/;"	f	file:
update_util	cpufreq_schedutil.c	/^	struct update_util_data	update_util;$/;"	m	struct:sugov_cpu	typeref:struct:sugov_cpu::update_util_data	file:
usages	cpuacct.c	/^	u64	usages[CPUACCT_STAT_NSTATS];$/;"	m	struct:cpuacct_usage	file:
util_avg	sched.h	/^		unsigned long	util_avg;$/;"	m	struct:cfs_rq::__anon2
util_cfs	cpufreq_schedutil.c	/^	unsigned long		util_cfs;$/;"	m	struct:sugov_cpu	file:
util_dl	cpufreq_schedutil.c	/^	unsigned long		util_dl;$/;"	m	struct:sugov_cpu	file:
util_est_dequeue	fair.c	/^util_est_dequeue(struct cfs_rq *cfs_rq, struct task_struct *p, bool task_sleep)$/;"	f	file:
util_est_dequeue	fair.c	/^util_est_dequeue(struct cfs_rq *cfs_rq, struct task_struct *p,$/;"	f	file:
util_est_enqueue	fair.c	/^static inline void util_est_enqueue(struct cfs_rq *cfs_rq,$/;"	f	file:
util_est_enqueue	fair.c	/^util_est_enqueue(struct cfs_rq *cfs_rq, struct task_struct *p) {}$/;"	f	file:
valid_policy	sched.h	/^static inline bool valid_policy(int policy)$/;"	f
var_wake_function	wait_bit.c	/^var_wake_function(struct wait_queue_entry *wq_entry, unsigned int mode,$/;"	f	file:
vruntime_normalized	fair.c	/^static inline bool vruntime_normalized(struct task_struct *p)$/;"	f	file:
vtime_account_guest	cputime.c	/^static void vtime_account_guest(struct task_struct *tsk,$/;"	f	file:
vtime_account_idle	cputime.c	/^void vtime_account_idle(struct task_struct *tsk)$/;"	f
vtime_account_irq_enter	cputime.c	/^EXPORT_SYMBOL_GPL(vtime_account_irq_enter);$/;"	v
vtime_account_irq_enter	cputime.c	/^void vtime_account_irq_enter(struct task_struct *tsk)$/;"	f
vtime_account_system	cputime.c	/^void vtime_account_system(struct task_struct *tsk)$/;"	f
vtime_common_task_switch	cputime.c	/^void vtime_common_task_switch(struct task_struct *prev)$/;"	f
vtime_delta	cputime.c	/^static u64 vtime_delta(struct vtime *vtime)$/;"	f	file:
vtime_guest_enter	cputime.c	/^EXPORT_SYMBOL_GPL(vtime_guest_enter);$/;"	v
vtime_guest_enter	cputime.c	/^void vtime_guest_enter(struct task_struct *tsk)$/;"	f
vtime_guest_exit	cputime.c	/^EXPORT_SYMBOL_GPL(vtime_guest_exit);$/;"	v
vtime_guest_exit	cputime.c	/^void vtime_guest_exit(struct task_struct *tsk)$/;"	f
vtime_init_idle	cputime.c	/^void vtime_init_idle(struct task_struct *t, int cpu)$/;"	f
vtime_user_enter	cputime.c	/^void vtime_user_enter(struct task_struct *tsk)$/;"	f
vtime_user_exit	cputime.c	/^void vtime_user_exit(struct task_struct *tsk)$/;"	f
wait_bit_init	wait_bit.c	/^void __init wait_bit_init(void)$/;"	f
wait_for_common	completion.c	/^wait_for_common(struct completion *x, long timeout, int state)$/;"	f	file:
wait_for_common_io	completion.c	/^wait_for_common_io(struct completion *x, long timeout, int state)$/;"	f	file:
wait_for_completion	completion.c	/^EXPORT_SYMBOL(wait_for_completion);$/;"	v
wait_for_completion	completion.c	/^void __sched wait_for_completion(struct completion *x)$/;"	f
wait_for_completion_interruptible	completion.c	/^EXPORT_SYMBOL(wait_for_completion_interruptible);$/;"	v
wait_for_completion_interruptible	completion.c	/^int __sched wait_for_completion_interruptible(struct completion *x)$/;"	f
wait_for_completion_interruptible_timeout	completion.c	/^EXPORT_SYMBOL(wait_for_completion_interruptible_timeout);$/;"	v
wait_for_completion_interruptible_timeout	completion.c	/^wait_for_completion_interruptible_timeout(struct completion *x,$/;"	f
wait_for_completion_io	completion.c	/^EXPORT_SYMBOL(wait_for_completion_io);$/;"	v
wait_for_completion_io	completion.c	/^void __sched wait_for_completion_io(struct completion *x)$/;"	f
wait_for_completion_io_timeout	completion.c	/^EXPORT_SYMBOL(wait_for_completion_io_timeout);$/;"	v
wait_for_completion_io_timeout	completion.c	/^wait_for_completion_io_timeout(struct completion *x, unsigned long timeout)$/;"	f
wait_for_completion_killable	completion.c	/^EXPORT_SYMBOL(wait_for_completion_killable);$/;"	v
wait_for_completion_killable	completion.c	/^int __sched wait_for_completion_killable(struct completion *x)$/;"	f
wait_for_completion_killable_timeout	completion.c	/^EXPORT_SYMBOL(wait_for_completion_killable_timeout);$/;"	v
wait_for_completion_killable_timeout	completion.c	/^wait_for_completion_killable_timeout(struct completion *x,$/;"	f
wait_for_completion_timeout	completion.c	/^EXPORT_SYMBOL(wait_for_completion_timeout);$/;"	v
wait_for_completion_timeout	completion.c	/^wait_for_completion_timeout(struct completion *x, unsigned long timeout)$/;"	f
wait_task_inactive	core.c	/^unsigned long wait_task_inactive(struct task_struct *p, long match_state)$/;"	f
wait_woken	wait.c	/^EXPORT_SYMBOL(wait_woken);$/;"	v
wait_woken	wait.c	/^long wait_woken(struct wait_queue_entry *wq_entry, unsigned mode, long timeout)$/;"	f
wake_affine	fair.c	/^static int wake_affine(struct sched_domain *sd, struct task_struct *p,$/;"	f	file:
wake_affine_idle	fair.c	/^wake_affine_idle(int this_cpu, int prev_cpu, int sync)$/;"	f	file:
wake_affine_weight	fair.c	/^wake_affine_weight(struct sched_domain *sd, struct task_struct *p,$/;"	f	file:
wake_bit_function	wait_bit.c	/^EXPORT_SYMBOL(wake_bit_function);$/;"	v
wake_bit_function	wait_bit.c	/^int wake_bit_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *arg)$/;"	f
wake_cap	fair.c	/^static int wake_cap(struct task_struct *p, int cpu, int prev_cpu)$/;"	f	file:
wake_list	sched.h	/^	struct llist_head	wake_list;$/;"	m	struct:rq	typeref:struct:rq::llist_head
wake_q_add	core.c	/^void wake_q_add(struct wake_q_head *head, struct task_struct *task)$/;"	f
wake_up_bit	wait_bit.c	/^EXPORT_SYMBOL(wake_up_bit);$/;"	v
wake_up_bit	wait_bit.c	/^void wake_up_bit(void *word, int bit)$/;"	f
wake_up_full_nohz_cpu	core.c	/^static bool wake_up_full_nohz_cpu(int cpu)$/;"	f	file:
wake_up_idle_cpu	core.c	/^static void wake_up_idle_cpu(int cpu)$/;"	f	file:
wake_up_if_idle	core.c	/^void wake_up_if_idle(int cpu)$/;"	f
wake_up_new_task	core.c	/^void wake_up_new_task(struct task_struct *p)$/;"	f
wake_up_nohz_cpu	core.c	/^void wake_up_nohz_cpu(int cpu)$/;"	f
wake_up_process	core.c	/^EXPORT_SYMBOL(wake_up_process);$/;"	v
wake_up_process	core.c	/^int wake_up_process(struct task_struct *p)$/;"	f
wake_up_q	core.c	/^void wake_up_q(struct wake_q_head *head)$/;"	f
wake_up_state	core.c	/^int wake_up_state(struct task_struct *p, unsigned int state)$/;"	f
wake_up_var	wait_bit.c	/^EXPORT_SYMBOL(wake_up_var);$/;"	v
wake_up_var	wait_bit.c	/^void wake_up_var(void *var)$/;"	f
wake_wide	fair.c	/^static int wake_wide(struct task_struct *p)$/;"	f	file:
wakeup_gran	fair.c	/^static unsigned long wakeup_gran(struct sched_entity *se)$/;"	f	file:
wakeup_preempt_entity	fair.c	/^wakeup_preempt_entity(struct sched_entity *curr, struct sched_entity *se)$/;"	f	file:
walk_tg_tree	sched.h	/^static inline int walk_tg_tree(tg_visitor down, tg_visitor up, void *data)$/;"	f
walk_tg_tree_from	core.c	/^int walk_tg_tree_from(struct task_group *from,$/;"	f
watchdog	rt.c	/^static inline void watchdog(struct rq *rq, struct task_struct *p) { }$/;"	f	file:
watchdog	rt.c	/^static void watchdog(struct rq *rq, struct task_struct *p)$/;"	f	file:
weighted_cpuload	fair.c	/^static unsigned long weighted_cpuload(struct rq *rq)$/;"	f	file:
within_margin	fair.c	/^static inline bool within_margin(int value, int margin)$/;"	f	file:
woken_wake_function	wait.c	/^EXPORT_SYMBOL(woken_wake_function);$/;"	v
woken_wake_function	wait.c	/^int woken_wake_function(struct wait_queue_entry *wq_entry, unsigned mode, int sync, void *key)$/;"	f
work	core.c	/^	struct delayed_work	work;$/;"	m	struct:tick_work	typeref:struct:tick_work::delayed_work	file:
work	cpufreq_schedutil.c	/^	struct			kthread_work work;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::kthread_work	file:
work_in_progress	cpufreq_schedutil.c	/^	bool			work_in_progress;$/;"	m	struct:sugov_policy	file:
work_lock	cpufreq_schedutil.c	/^	struct			mutex work_lock;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::mutex	file:
worker	cpufreq_schedutil.c	/^	struct			kthread_worker worker;$/;"	m	struct:sugov_policy	typeref:struct:sugov_policy::kthread_worker	file:
wrap_max	clock.c	/^static inline u64 wrap_max(u64 x, u64 y)$/;"	f	file:
wrap_min	clock.c	/^static inline u64 wrap_min(u64 x, u64 y)$/;"	f	file:
yield	core.c	/^EXPORT_SYMBOL(yield);$/;"	v
yield	core.c	/^void __sched yield(void)$/;"	f
yield_task	sched.h	/^	void (*yield_task)   (struct rq *rq);$/;"	m	struct:sched_class
yield_task_dl	deadline.c	/^static void yield_task_dl(struct rq *rq)$/;"	f	file:
yield_task_fair	fair.c	/^static void yield_task_fair(struct rq *rq)$/;"	f	file:
yield_task_rt	rt.c	/^static void yield_task_rt(struct rq *rq)$/;"	f	file:
yield_task_stop	stop_task.c	/^static void yield_task_stop(struct rq *rq)$/;"	f	file:
yield_to	core.c	/^EXPORT_SYMBOL_GPL(yield_to);$/;"	v
yield_to	core.c	/^int __sched yield_to(struct task_struct *p, bool preempt)$/;"	f
yield_to_task	sched.h	/^	bool (*yield_to_task)(struct rq *rq, struct task_struct *p, bool preempt);$/;"	m	struct:sched_class
yield_to_task_fair	fair.c	/^static bool yield_to_task_fair(struct rq *rq, struct task_struct *p, bool preempt)$/;"	f	file:
yld_count	sched.h	/^	unsigned int		yld_count;$/;"	m	struct:rq
